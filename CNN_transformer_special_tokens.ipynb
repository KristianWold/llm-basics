{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04010a08",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fa3d166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from src.tokenizer import TokenizerBPE, fuse_tokenized_corpus, chunk_corpus\n",
    "\n",
    "import os\n",
    "import time\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from tqdm.notebook import tqdm\n",
    "from src.transformer import *\n",
    "from src.data_handling import read_first_n, sample_batch\n",
    "\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2b59898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 2080 SUPER, compute capability 7.5\n"
     ]
    }
   ],
   "source": [
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "576256a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_tokenized_corpus(corpus, tokenizer):\n",
    "    SOS = tf.convert_to_tensor([[tokenizer.token_to_idx[\"<s>\"]]])\n",
    "    EOS = tf.convert_to_tensor([[tokenizer.token_to_idx[\"</s>\"]]])\n",
    "\n",
    "    corpus_list = [SOS]\n",
    "    for line in tqdm(corpus):\n",
    "        corpus_list.append(line)\n",
    "        corpus_list.append(EOS)\n",
    "        corpus_list.append(SOS)\n",
    "\n",
    "    corpus = tf.concat(corpus_list[:-1], axis=1)\n",
    "    return corpus\n",
    "\n",
    "\n",
    "def chunk_and_batch(corpus, chunk_size, batch_size, shuffle=True, repeat=False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(corpus)\n",
    "    ds = ds.batch(chunk_size, drop_remainder=True)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=100*chunk_size, reshuffle_each_iteration=True)\n",
    "        \n",
    "    ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    if repeat:\n",
    "        ds = ds.repeat()\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7afd4e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 512\n",
    "\n",
    "tokenizer = pkl.load(open(\"tokenizers/tokenizer_CNN16000_lowercase.pkl\", 'rb'))\n",
    "tokenizer.add_special_tokens([\"<s>\", \"</s>\"])\n",
    "tokenizer.create_hash()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8751dd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b889456e9b354108989930b1b6928845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4f9bcb51024840a5228e157c312b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18516 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(43)\n",
    "corpus = pkl.load(open('corpus/CNN_tokenized16000_lowercase.pkl', 'rb'))\n",
    "random.shuffle(corpus)\n",
    "length = len(corpus)\n",
    "train_corpus = corpus[:int(length*0.8)]\n",
    "train_corpus = fuse_tokenized_corpus(train_corpus, tokenizer)\n",
    "\n",
    "test_corpus = corpus[int(length*0.8):]\n",
    "test_corpus = fuse_tokenized_corpus(test_corpus, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e38fb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = chunk_and_batch(train_corpus[0], chunk_size=max_seq_len, batch_size=16, shuffle=True)\n",
    "ds_test = chunk_and_batch(test_corpus[0], chunk_size=max_seq_len, batch_size=8, repeat=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f830d881",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a564402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmUpThenDecay(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self,\n",
    "                 initial_learning_rate: float,\n",
    "                 warmup_steps: int,\n",
    "                 decay_schedule_fn: tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "        \"\"\"\n",
    "        initial_learning_rate: peak LR reached at end of warmup\n",
    "        warmup_steps:      # of steps to ramp from 0 â†’ initial_learning_rate\n",
    "        decay_schedule_fn: a tf.keras schedule to apply *after* warmup\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.initial_lr = initial_learning_rate\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.decay_schedule_fn = decay_schedule_fn\n",
    "\n",
    "    def __call__(self, step):\n",
    "        # Cast to float32 for safety in graph mode\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        warmup_steps = tf.cast(self.warmup_steps, tf.float32)\n",
    "\n",
    "        # compute linear warmup: lr = initial_lr * (step / warmup_steps)\n",
    "        warmup_lr = self.initial_lr * (step / warmup_steps)\n",
    "\n",
    "        # after warmup_steps, switch to decay schedule (shift step count)\n",
    "        decay_step = step - warmup_steps\n",
    "        decay_lr = self.decay_schedule_fn(decay_step)\n",
    "\n",
    "        # if step < warmup_steps, pick warmup_lr, else decay_lr\n",
    "        return tf.cond(step < warmup_steps,\n",
    "                       lambda: warmup_lr,\n",
    "                       lambda: decay_lr)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a5a33ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr = 1e-4\n",
    "decay_steps = 20000\n",
    "decay_rate = 0.5\n",
    "decay_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=initial_lr,\n",
    "    decay_steps=decay_steps,\n",
    "    decay_rate=decay_rate,\n",
    "    staircase=False)\n",
    "\n",
    "warmup_steps = 1000\n",
    "lr_schedule = WarmUpThenDecay(\n",
    "    initial_learning_rate=initial_lr,\n",
    "    warmup_steps=warmup_steps,\n",
    "    decay_schedule_fn=decay_schedule)\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "max_seq_len = 512\n",
    "embed_dim = 512\n",
    "tf_blocks = 8\n",
    "heads = 8\n",
    "ff_dim = 4*embed_dim\n",
    "weight_decay = 0.01\n",
    "dropout = 0.05\n",
    "\n",
    "unembed_dims = []\n",
    "\n",
    "model = Transformer(vocab_size=tokenizer.vocab_size,\n",
    "                    max_seq_len=max_seq_len,\n",
    "                    embed_dim=embed_dim,\n",
    "                    tf_blocks=tf_blocks,\n",
    "                    heads=heads,\n",
    "                    ff_dim = ff_dim,\n",
    "                    unembed_dims=unembed_dims,\n",
    "                    lr=lr_schedule,\n",
    "                    wd = weight_decay,\n",
    "                    dropout=dropout,\n",
    "                    )\n",
    "\n",
    "losses_train = []\n",
    "losses_test = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7970a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"model_16k_tokens_special_tokens\"\n",
    "\n",
    "\n",
    "ckpt = tf.train.Checkpoint(\n",
    "    optimizer=model.opt,\n",
    "    model=model\n",
    ")\n",
    "ckpt_manager = tf.train.CheckpointManager(\n",
    "    ckpt, \n",
    "    directory=\"checkpoints/\" + name,      # folder where ckpts are saved\n",
    "    max_to_keep=5                         # only keep 5 latest checkpoints\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88b34765",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "losses_train, losses_test = pkl.load(open(\"checkpoints/losses_\" + name + \".pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6527620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 33709768\n"
     ]
    }
   ],
   "source": [
    "total_params = 0\n",
    "for var in model.parameter_list:\n",
    "    shape = var.get_shape()\n",
    "    num_params = 1\n",
    "    for dim in shape:\n",
    "        num_params *= dim\n",
    "    total_params += num_params\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93977cd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m ax2\u001b[38;5;241m.\u001b[39mgrid(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     52\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[1;32m---> 53\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\pyplot.py:614\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    613\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 614\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_backend_mod()\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib_inline\\backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m figure_manager \u001b[38;5;129;01min\u001b[39;00m Gcf\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[1;32m---> 90\u001b[0m         \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fetch_figure_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     show\u001b[38;5;241m.\u001b[39m_to_draw \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\formatters.py:238\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    236\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\formatters.py:282\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 282\u001b[0m     r \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\formatters.py:402\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    404\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\pylabtools.py:170\u001b[0m, in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[0;32m    168\u001b[0m     FigureCanvasBase(fig)\n\u001b[1;32m--> 170\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mprint_figure(bytes_io, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    171\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\backend_bases.py:2184\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2181\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[0;32m   2182\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[0;32m   2183\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m-> 2184\u001b[0m         result \u001b[38;5;241m=\u001b[39m print_method(\n\u001b[0;32m   2185\u001b[0m             filename,\n\u001b[0;32m   2186\u001b[0m             facecolor\u001b[38;5;241m=\u001b[39mfacecolor,\n\u001b[0;32m   2187\u001b[0m             edgecolor\u001b[38;5;241m=\u001b[39medgecolor,\n\u001b[0;32m   2188\u001b[0m             orientation\u001b[38;5;241m=\u001b[39morientation,\n\u001b[0;32m   2189\u001b[0m             bbox_inches_restore\u001b[38;5;241m=\u001b[39m_bbox_inches_restore,\n\u001b[0;32m   2190\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2191\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\backend_bases.py:2040\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2036\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[0;32m   2037\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2038\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m   2039\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[1;32m-> 2040\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: meth(\n\u001b[0;32m   2041\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m skip}))\n\u001b[0;32m   2042\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[0;32m   2043\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:481\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    435\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 481\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:429\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[1;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_print_pil\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;124;03m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 429\u001b[0m     \u001b[43mFigureCanvasAgg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m     mpl\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave(\n\u001b[0;32m    431\u001b[0m         filename_or_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_rgba(), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mfmt, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    432\u001b[0m         dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi, metadata\u001b[38;5;241m=\u001b[39mmetadata, pil_kwargs\u001b[38;5;241m=\u001b[39mpil_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:382\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\u001b[38;5;241m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\n\u001b[0;32m    381\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[1;32m--> 382\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdraw()\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\artist.py:94\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 94\u001b[0m     result \u001b[38;5;241m=\u001b[39m draw(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[0;32m     96\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\artist.py:71\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\figure.py:3257\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3254\u001b[0m             \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   3256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> 3257\u001b[0m     \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3260\u001b[0m     renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3261\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\image.py:134\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 134\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\artist.py:71\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\axes\\_base.py:3210\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[0;32m   3208\u001b[0m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_figure(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), artists_rasterized, renderer)\n\u001b[1;32m-> 3210\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3213\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\image.py:134\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 134\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\artist.py:71\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\axis.py:1405\u001b[0m, in \u001b[0;36mAxis.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   1402\u001b[0m renderer\u001b[38;5;241m.\u001b[39mopen_group(\u001b[38;5;18m__name__\u001b[39m, gid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_gid())\n\u001b[0;32m   1404\u001b[0m ticks_to_draw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_ticks()\n\u001b[1;32m-> 1405\u001b[0m tlb1, tlb2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_ticklabel_bboxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticks_to_draw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks_to_draw:\n\u001b[0;32m   1408\u001b[0m     tick\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\axis.py:1332\u001b[0m, in \u001b[0;36mAxis._get_ticklabel_bboxes\u001b[1;34m(self, ticks, renderer)\u001b[0m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1331\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_figure(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[1;32m-> 1332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ([tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1333\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_visible()],\n\u001b[0;32m   1334\u001b[0m         [tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1335\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_visible()])\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\axis.py:1332\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1331\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_figure(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[1;32m-> 1332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ([\u001b[43mtick\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_window_extent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1333\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_visible()],\n\u001b[0;32m   1334\u001b[0m         [tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1335\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_visible()])\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\text.py:969\u001b[0m, in \u001b[0;36mText.get_window_extent\u001b[1;34m(self, renderer, dpi)\u001b[0m\n\u001b[0;32m    964\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get window extent of text w/o renderer. You likely \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    966\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwant to call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure.draw_without_rendering()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(fig, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m--> 969\u001b[0m     bbox, info, descent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_renderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    970\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_unitless_position()\n\u001b[0;32m    971\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_transform()\u001b[38;5;241m.\u001b[39mtransform((x, y))\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\text.py:382\u001b[0m, in \u001b[0;36mText._get_layout\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    380\u001b[0m clean_line, ismath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_math(line)\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clean_line:\n\u001b[1;32m--> 382\u001b[0m     w, h, d \u001b[38;5;241m=\u001b[39m \u001b[43m_get_text_metrics_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_line\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fontproperties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mismath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mismath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    386\u001b[0m     w \u001b[38;5;241m=\u001b[39m h \u001b[38;5;241m=\u001b[39m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\text.py:69\u001b[0m, in \u001b[0;36m_get_text_metrics_with_cache\u001b[1;34m(renderer, text, fontprop, ismath, dpi)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call ``renderer.get_text_width_height_descent``, caching the results.\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Cached based on a copy of fontprop so that later in-place mutations of\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# the passed-in argument do not mess up the cache.\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_text_metrics_with_cache_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfontprop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mismath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\text.py:77\u001b[0m, in \u001b[0;36m_get_text_metrics_with_cache_impl\u001b[1;34m(renderer_ref, text, fontprop, ismath, dpi)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache(\u001b[38;5;241m4096\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_text_metrics_with_cache_impl\u001b[39m(\n\u001b[0;32m     75\u001b[0m         renderer_ref, text, fontprop, ismath, dpi):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# dpi is unused, but participates in cache invalidation (via the renderer).\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrenderer_ref\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_text_width_height_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfontprop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mismath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:219\u001b[0m, in \u001b[0;36mRendererAgg.get_text_width_height_descent\u001b[1;34m(self, s, prop, ismath)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m width, height, descent\n\u001b[0;32m    218\u001b[0m font \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_font(prop)\n\u001b[1;32m--> 219\u001b[0m \u001b[43mfont\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_hinting_flag\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m w, h \u001b[38;5;241m=\u001b[39m font\u001b[38;5;241m.\u001b[39mget_width_height()  \u001b[38;5;66;03m# width and height of unrotated string\u001b[39;00m\n\u001b[0;32m    221\u001b[0m d \u001b[38;5;241m=\u001b[39m font\u001b[38;5;241m.\u001b[39mget_descent()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, (batch_train, batch_test) in enumerate(zip(ds_train, ds_test)):\n",
    "    \n",
    "\n",
    "    loss_train = model.train_step(batch_train).numpy()\n",
    "    losses_train.append(loss_train)\n",
    "    \n",
    "    loss_test = model.evaluate(batch_test).numpy()\n",
    "    losses_test.append(loss_test)\n",
    "\n",
    "    if (i+1) % 1000 == 0:\n",
    "        ckpt_manager.save()\n",
    "        pkl.dump([losses_train, losses_test], open(\"checkpoints/losses_\" + name + \".pkl\", 'wb'))\n",
    "\n",
    "\n",
    "    lr = model.opt.inner_optimizer._decayed_lr(tf.float32).numpy()\n",
    "    #\"\"\"\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # prepare x-axis for the last 400 steps\n",
    "    start = max(0, len(losses_train) - 1000)\n",
    "    x_zoom = np.arange(start, len(losses_train))\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(10, 8), sharex=False)\n",
    "\n",
    "    # Top subplot: zoom on last 400 steps\n",
    "    ax1 = axes[0]\n",
    "    ax1.plot(x_zoom, losses_test[-1000:], label=\"Test Loss\")\n",
    "    ax1.plot(x_zoom, losses_train[-1000:], label=\"Train Loss\")\n",
    "\n",
    "    _min = min(losses_train[-1000:] + losses_test[-1000:])\n",
    "    _max = max(losses_train[-1000:] + losses_test[-1000:])\n",
    "    delta = _max - _min\n",
    "    #ax1.set_ylim(_min - 0.1 * delta, _max + 0.1 * delta)\n",
    "\n",
    "    ax1.set_title(\"Training Loss (Last 1000 Steps)\")\n",
    "    ax1.set_xlabel(\"Step\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Bottom subplot: full series\n",
    "    ax2 = axes[1]\n",
    "    ax2.plot(losses_test[10:], label=\"Test Loss\")\n",
    "    ax2.plot(losses_train[10:], label=\"Train Loss, lr = {:.2e}\".format(lr))\n",
    "\n",
    "    ax2.set_title(\"Training Loss (Full Series)\")\n",
    "    ax2.set_xlabel(\"Step\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e216ce01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[16070]], shape=(1, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\n",
    "text = text.lower()\n",
    "SOS = tf.convert_to_tensor([[tokenizer.token_to_idx[\"<s>\"]]])\n",
    "indices = tf.cast(tokenizer.tokenize(text), tf.int32)\n",
    "indices = tf.concat([SOS, indices], axis=1)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74a017b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf70594ce7f64b3b803a8698112c6bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', disabled=True, layout=Layout(height='20em', width='80ch'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import textwrap\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "T = 0.5\n",
    "tf.random.set_seed(43)\n",
    "wrapper = textwrap.TextWrapper(width=80)\n",
    "\n",
    "# create a read-only text area\n",
    "ta = widgets.Textarea(\n",
    "    value=\"\",\n",
    "    layout=widgets.Layout(width='80ch', height='20em'),\n",
    "    disabled=True\n",
    ")\n",
    "display(ta)\n",
    "\n",
    "for i in range(512):\n",
    "    logits = model.call(indices)[0, -1:]\n",
    "    idx = tf.cast(\n",
    "        tf.random.categorical(logits / T, num_samples=1),\n",
    "        tf.int32\n",
    "    )\n",
    "    indices = tf.concat([indices, idx], axis=1)\n",
    "\n",
    "    text_pred = (\n",
    "        tokenizer\n",
    "        .detokenize(indices)\n",
    "        .numpy()[0]\n",
    "        .decode('utf-8')\n",
    "        .replace(\"\\n\", \" \")\n",
    "    )\n",
    "    ta.value = wrapper.fill(text_pred)  # this updates in-place\n",
    "\n",
    "    if idx[0, 0] == tokenizer.token_to_idx[\"</s>\"]:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "680d4eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[553]], shape=(1, 1), dtype=int32)\n",
      "obama are a of the the the of the a of the of the the of with the u by international the first\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5588\\3758968849.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m43\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtext_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krist\\Documents\\llm-basics\\src\\transformer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x, training, logits)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_blocks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munembed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krist\\Documents\\llm-basics\\src\\transformer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x_embeds, training)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_embeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mx_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_embeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mx_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mffnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_embeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx_embeds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krist\\Documents\\llm-basics\\src\\transformer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x_embeds, training)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_up\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_embeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_down\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdol3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mln2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx_embeds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 ):\n\u001b[1;32m-> 1097\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\layers\\normalization\\layer_normalization.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    283\u001b[0m                 \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"float32\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m             ):\n\u001b[0;32m    285\u001b[0m                 \u001b[1;31m# If mixed precision is used, cast inputs to float32 so that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m                 \u001b[1;31m# this is at least as numerically stable as the fused version.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"float32\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[1;31m# Calculate the moments on the last axis (layer activations).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, dtype, name)\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[1;31m# allows some conversions that cast() can't do, e.g. casting numbers to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m       \u001b[1;31m# strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1002\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1004\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Casting complex to real discards imaginary part.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, DstT, Truncate, name)\u001b[0m\n\u001b[0;32m   1997\u001b[0m         _ctx, \"Cast\", name, x, \"DstT\", DstT, \"Truncate\", Truncate)\n\u001b[0;32m   1998\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1999\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2000\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2001\u001b[1;33m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2002\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2003\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2004\u001b[0m       return cast_eager_fallback(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text = \"obama\"\n",
    "text = text.lower()\n",
    "\n",
    "indices = tf.cast(tokenizer.tokenize(text), tf.int32)\n",
    "print(indices)\n",
    "\n",
    "T = 0.5\n",
    "tf.random.set_seed(43)\n",
    "for i in range(128):\n",
    "    logits = model.call(indices)[0,-1:]\n",
    "    idx = tf.cast(tf.random.categorical(logits/T, num_samples=1), tf.int32)\n",
    "    indices = tf.concat([indices, idx], axis=1)\n",
    "    text_pred = tokenizer.detokenize(indices)\n",
    "    text_pred = text_pred.numpy()[0].decode('utf-8').replace(\"\\n\", \" \")\n",
    "    print(text_pred, end='\\r', flush=True)\n",
    "    #time.sleep(0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5256b899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[13602]], shape=(1, 1), dtype=int32)\n",
      "deepwater horizon disaster relief disaster.  the gulf oil spill in the gulf of mexico will be the largest in international waters in the gulf of mexico since the end of the year, according to the u.s. coast guard.  the oil is a major source of oil since the gulf of mexico oil disaster last year and the oil spill is expected\r"
     ]
    }
   ],
   "source": [
    "text = \"deepwater\"\n",
    "text = text.lower()\n",
    "\n",
    "indices = tf.cast(tokenizer.tokenizer.tokenize(text), tf.int32)\n",
    "indices = tokenize(indices, tokenizer.merge_list)\n",
    "print(indices)\n",
    "\n",
    "T = 0.5\n",
    "tf.random.set_seed(43)\n",
    "for i in range(128):\n",
    "    logits = model.call(indices)[0,-1:]\n",
    "    idx = tf.cast(tf.random.categorical(logits/T, num_samples=1), tf.int32)\n",
    "    indices = tf.concat([indices, idx], axis=1)\n",
    "    text_pred = tokenizer.detokenize(indices)\n",
    "    text_pred = text_pred.numpy()[0].decode('utf-8').replace(\"\\n\", \" \")\n",
    "    print(text_pred, end='\\r', flush=True)\n",
    "    #time.sleep(0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e77fb01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def cosine_similarity(embed_a, embed_b):\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between two vectors.\n",
    "    \"\"\"\n",
    "    embed_b_T = tf.transpose(embed_b)\n",
    "    dot_product = embed_a@embed_b_T\n",
    "    \n",
    "    norm_a = tf.linalg.norm(embed_a, axis=1, keepdims=True)\n",
    "    norm_b = tf.linalg.norm(embed_b_T, axis=0, keepdims=True)\n",
    "\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "\n",
    "def cluster(X, n_clusters, normalize=True):\n",
    "    if normalize:\n",
    "        X = X/np.linalg.norm(X, axis=1, keepdims=True)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "    inertia = kmeans.inertia_\n",
    "    labels = kmeans.labels_\n",
    "    clusters = kmeans.cluster_centers_\n",
    "\n",
    "    return inertia, labels, clusters\n",
    "\n",
    "\n",
    "class EmbeddingClustering:\n",
    "    def __init__(self, tokenizer, n_clusters=10):\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.n_clusters = n_clusters\n",
    "\n",
    "    def fit(self, word_embed, normalize=True):\n",
    "        inertia, labels, clusters = cluster(word_embed, self.n_clusters, normalize)\n",
    "        self.word_embed = word_embed\n",
    "        self.inertia = inertia\n",
    "        self.labels = labels\n",
    "        self.clusters = tf.convert_to_tensor(clusters, dtype=tf.float32)\n",
    "\n",
    "        cos_sim = cosine_similarity(self.clusters, word_embed, normalize)\n",
    "        self.idx_list =  tf.argsort(cos_sim, axis=-1, direction='DESCENDING', stable=False, name=None)\n",
    "\n",
    "    def print_clusters(self, n_words=10):\n",
    "        for idx in self.idx_list:\n",
    "            for i in idx[:n_words]:\n",
    "                word = self.tokenizer.detokenize(tf.expand_dims(tf.cast(i, tf.int32), axis=0))\n",
    "                word = word.numpy().decode('utf-8')\n",
    "                print(word)\n",
    "            print(\"\\n\")\n",
    "\n",
    "\n",
    "def cosine_similarity(embed_a, embed_b, normalize=True):\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between two vectors.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        embed_a = tf.nn.l2_normalize(embed_a, axis=1)\n",
    "        embed_b = tf.nn.l2_normalize(embed_b, axis=1)\n",
    "    dot_product = embed_a@tf.transpose(embed_b)\n",
    "\n",
    "\n",
    "    return dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48583bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debbie\n",
      "denise\n",
      "katherine\n",
      "stephanie\n",
      "randy\n",
      "jason\n",
      "patricia\n",
      "kathy\n",
      "jesse\n",
      "sergio\n",
      "\n",
      "\n",
      "deficits\n",
      "revenues\n",
      "reductions\n",
      "subsidies\n",
      "incentives\n",
      "loans\n",
      "exports\n",
      "budgets\n",
      "salaries\n",
      "bonuses\n",
      "\n",
      "\n",
      "attem\n",
      "theless\n",
      "occas\n",
      "ieval\n",
      "theastern\n",
      "enthusia\n",
      "negot\n",
      "lesterol\n",
      "subsequ\n",
      "fahren\n",
      "\n",
      "\n",
      "occas\n",
      "afgh\n",
      "negot\n",
      "includ\n",
      "delaw\n",
      "glary\n",
      "ifics\n",
      "theast\n",
      "salad\n",
      "patro\n",
      "\n",
      "\n",
      "theastern\n",
      "experi\n",
      "delaw\n",
      "theast\n",
      "lesterol\n",
      "dort\n",
      "semif\n",
      "attem\n",
      "surpris\n",
      "compon\n",
      "\n",
      "\n",
      "ffed\n",
      "strugg\n",
      "portra\n",
      "athle\n",
      "massachu\n",
      "ifics\n",
      "pered\n",
      "experi\n",
      "arct\n",
      "thered\n",
      "\n",
      "\n",
      "subsequ\n",
      "theast\n",
      "prede\n",
      "occas\n",
      "theastern\n",
      "ieval\n",
      "lesterol\n",
      "experi\n",
      "arct\n",
      "ailand\n",
      "\n",
      "\n",
      "pretty\n",
      "fairly\n",
      "reasonably\n",
      "utterly\n",
      "remarkably\n",
      "substantially\n",
      "fundamentally\n",
      "relatively\n",
      "totally\n",
      "unusually\n",
      "\n",
      "\n",
      "deal\n",
      "challenge\n",
      "talk\n",
      "question\n",
      "move\n",
      "answer\n",
      "appeal\n",
      "attempt\n",
      "approach\n",
      "decision\n",
      "\n",
      "\n",
      "sending\n",
      "helping\n",
      "letting\n",
      "handing\n",
      "putting\n",
      "taking\n",
      "giving\n",
      "bringing\n",
      "pulling\n",
      "throwing\n",
      "\n",
      "\n",
      "tens\n",
      "hundreds\n",
      "thousands\n",
      "dozens\n",
      "millions\n",
      "billions\n",
      "plenty\n",
      "sort\n",
      "there\n",
      "none\n",
      "\n",
      "\n",
      "uguay\n",
      "theid\n",
      "lesterol\n",
      "negot\n",
      "theastern\n",
      "delaw\n",
      "ailand\n",
      "occas\n",
      "guate\n",
      "arct\n",
      "\n",
      "\n",
      "convince\n",
      "impose\n",
      "abide\n",
      "eliminate\n",
      "undermine\n",
      "prohibit\n",
      "tolerate\n",
      "educate\n",
      "satisfy\n",
      "violate\n",
      "\n",
      "\n",
      "two\n",
      "three\n",
      "four\n",
      "the\n",
      "six\n",
      "a\n",
      "several\n",
      "some\n",
      "no\n",
      "more\n",
      "\n",
      "\n",
      "christop\n",
      "djok\n",
      "berdy\n",
      "tember\n",
      "benjam\n",
      "whate\n",
      "aragu\n",
      "petrole\n",
      "dono\n",
      "bundes\n",
      "\n",
      "\n",
      "gives\n",
      "helps\n",
      "provides\n",
      "encourages\n",
      "relies\n",
      "deserves\n",
      "refuses\n",
      "enjoys\n",
      "seeks\n",
      "tends\n",
      "\n",
      "\n",
      "renewable\n",
      "greenhouse\n",
      "geological\n",
      "tropical\n",
      "mountainous\n",
      "carbon\n",
      "saharan\n",
      "rugged\n",
      "atomic\n",
      "fukushima\n",
      "\n",
      "\n",
      "encouraged\n",
      "instructed\n",
      "persuaded\n",
      "refused\n",
      "urged\n",
      "subjected\n",
      "managed\n",
      "referred\n",
      "helped\n",
      "unable\n",
      "\n",
      "\n",
      "glary\n",
      "gbag\n",
      "strugg\n",
      "espion\n",
      "risings\n",
      "beliefs\n",
      "guate\n",
      "transparen\n",
      "athle\n",
      "usalem\n",
      "\n",
      "\n",
      "behavioral\n",
      "psychiatric\n",
      "reproductive\n",
      "cognitive\n",
      "bodily\n",
      "preventive\n",
      "genetic\n",
      "spinal\n",
      "traumatic\n",
      "infectious\n",
      "\n",
      "\n",
      "1972\n",
      "2002\n",
      "1992\n",
      "2001\n",
      "1993\n",
      "2003\n",
      "1969\n",
      "1995\n",
      "1990\n",
      "2005\n",
      "\n",
      "\n",
      "glary\n",
      "burglary\n",
      "interrogation\n",
      "gbag\n",
      "portra\n",
      "prede\n",
      "afgh\n",
      "fahren\n",
      "environ\n",
      "lesterol\n",
      "\n",
      "\n",
      "bolivia\n",
      "tunisia\n",
      "belarus\n",
      "croatia\n",
      "kazakhstan\n",
      "portugal\n",
      "serbia\n",
      "uzbek\n",
      "paraguay\n",
      "algeria\n",
      "\n",
      "\n",
      "indicted\n",
      "accuses\n",
      "sentenced\n",
      "pleaded\n",
      "criticized\n",
      "denounced\n",
      "denied\n",
      "hailed\n",
      "dismissed\n",
      "acquitted\n",
      "\n",
      "\n",
      "delicious\n",
      "magical\n",
      "exciting\n",
      "fascinating\n",
      "vibrant\n",
      "formidable\n",
      "thoughtful\n",
      "lovely\n",
      "beneficial\n",
      "profound\n",
      "\n",
      "\n",
      "nostal\n",
      "norwe\n",
      "twel\n",
      "archite\n",
      "aero\n",
      "nove\n",
      "reci\n",
      "engul\n",
      "whate\n",
      "anthro\n",
      "\n",
      "\n",
      "oldest\n",
      "longest\n",
      "lowest\n",
      "fastest\n",
      "tallest\n",
      "busiest\n",
      "hottest\n",
      "12th\n",
      "youngest\n",
      "16th\n",
      "\n",
      "\n",
      "unsure\n",
      "wondering\n",
      "convinced\n",
      "insisting\n",
      "wondered\n",
      "reminded\n",
      "complaining\n",
      "excited\n",
      "arguing\n",
      "hoping\n",
      "\n",
      "\n",
      "ag\n",
      " \n",
      "\n",
      "\n",
      "leng\n",
      "scand\n",
      "ig\n",
      "uc\n",
      "em\n",
      "ud\n",
      "mar\n",
      "\n",
      "\n",
      "inno\n",
      "spon\n",
      "mber\n",
      "lene\n",
      "resu\n",
      "mediterran\n",
      "uke\n",
      "tember\n",
      "bam\n",
      "kyr\n",
      "\n",
      "\n",
      "mo\n",
      "lo\n",
      "con\n",
      "mu\n",
      "de\n",
      "sha\n",
      "du\n",
      "su\n",
      "tu\n",
      "hu\n",
      "\n",
      "\n",
      "ailand\n",
      "zimbab\n",
      "occas\n",
      "immen\n",
      "includ\n",
      "delaw\n",
      "athle\n",
      "experi\n",
      "negot\n",
      "hrir\n",
      "\n",
      "\n",
      "grandmother\n",
      "roommate\n",
      "boyfriend\n",
      "girlfriend\n",
      "fiance\n",
      "aunt\n",
      "cousin\n",
      "fiancee\n",
      "nephew\n",
      "counselor\n",
      "\n",
      "\n",
      "ised\n",
      "ipped\n",
      "aded\n",
      "ered\n",
      "uted\n",
      "ized\n",
      "ilized\n",
      "oned\n",
      "ished\n",
      "aled\n",
      "\n",
      "\n",
      "28\n",
      "15\n",
      "36\n",
      "29\n",
      "25\n",
      "23\n",
      "39\n",
      "40\n",
      "27\n",
      "38\n",
      "\n",
      "\n",
      "popu\n",
      "magist\n",
      "nove\n",
      "theat\n",
      "injun\n",
      "frust\n",
      "juris\n",
      "convin\n",
      "immig\n",
      "anthro\n",
      "\n",
      "\n",
      "spacecraft\n",
      "telescope\n",
      "airliner\n",
      "dreamliner\n",
      "tanker\n",
      "delaw\n",
      "submarine\n",
      "airbus\n",
      "occas\n",
      "plane's\n",
      "\n",
      "\n",
      "theless\n",
      "lesterol\n",
      "occas\n",
      "subsequ\n",
      "assage\n",
      "fahren\n",
      "ailand\n",
      "secutive\n",
      "luscon\n",
      "theid\n",
      "\n",
      "\n",
      "atp\n",
      "paralympic\n",
      "tennis\n",
      "wta\n",
      "basketball\n",
      "rugby\n",
      "athletics\n",
      "wimbledon\n",
      "jazz\n",
      "players'\n",
      "\n",
      "\n",
      "civil\n",
      "foreign\n",
      "political\n",
      "supreme\n",
      "financial\n",
      "constitutional\n",
      "legislative\n",
      "social\n",
      "economic\n",
      "immigration\n",
      "\n",
      "\n",
      "i'd\n",
      "we'd\n",
      "you'd\n",
      "we'll\n",
      "we've\n",
      "i'll\n",
      "you've\n",
      "i've\n",
      "hasn't\n",
      "they'd\n",
      "\n",
      "\n",
      "investigators\n",
      "officials\n",
      "residents\n",
      "doctors\n",
      "firefighters\n",
      "authorities\n",
      "students\n",
      "experts\n",
      "activists\n",
      "attorneys\n",
      "\n",
      "\n",
      "uguay\n",
      "negot\n",
      "rouhani\n",
      "maduro\n",
      "athle\n",
      "occas\n",
      "guate\n",
      "gbag\n",
      "afgh\n",
      "theastern\n",
      "\n",
      "\n",
      "injunction\n",
      "rulings\n",
      "athle\n",
      "experi\n",
      "tribunal\n",
      "guate\n",
      "arct\n",
      "theastern\n",
      "itored\n",
      "gbag\n",
      "\n",
      "\n",
      "scrut\n",
      "inflam\n",
      "nutr\n",
      "reim\n",
      "symp\n",
      "sophist\n",
      "inef\n",
      "frust\n",
      "erad\n",
      "scand\n",
      "\n",
      "\n",
      "enthusia\n",
      "immen\n",
      "usalem\n",
      "surpris\n",
      "fahren\n",
      "delaw\n",
      "assage\n",
      "theless\n",
      "subsequ\n",
      "theid\n",
      "\n",
      "\n",
      "strategist\n",
      "coordinator\n",
      "commentator\n",
      "columnist\n",
      "chairwoman\n",
      "mogul\n",
      "grapher\n",
      "adviser\n",
      "contributor\n",
      "historian\n",
      "\n",
      "\n",
      "hosni\n",
      "christiane\n",
      "jethro\n",
      "cristiano\n",
      "elise\n",
      "kanye\n",
      "saad\n",
      "udad\n",
      "rory\n",
      "charac\n",
      "\n",
      "\n",
      "concerns\n",
      "doubts\n",
      "commitment\n",
      "distinction\n",
      "sympathy\n",
      "concern\n",
      "efforts\n",
      "frustration\n",
      "connections\n",
      "questions\n",
      "\n",
      "\n",
      "teed\n",
      "descended\n",
      "poured\n",
      "climbed\n",
      "bounced\n",
      "slipped\n",
      "tossed\n",
      "wiped\n",
      "ripped\n",
      "edged\n",
      "\n",
      "\n",
      "fbi's\n",
      "singer's\n",
      "tour's\n",
      "organization's\n",
      "military's\n",
      "couple's\n",
      "agency's\n",
      "minister's\n",
      "army's\n",
      "show's\n",
      "\n",
      "\n",
      "175\n",
      "450\n",
      "550\n",
      "650\n",
      "120\n",
      "250\n",
      "750\n",
      "260\n",
      "270\n",
      "240\n",
      "\n",
      "\n",
      "hampered\n",
      "governed\n",
      "enriched\n",
      "administered\n",
      "transmitted\n",
      "traced\n",
      "regulated\n",
      "renewable\n",
      "populated\n",
      "resistant\n",
      "\n",
      "\n",
      "involuntary\n",
      "impending\n",
      "lucrative\n",
      "immediate\n",
      "deepwater\n",
      "prolonged\n",
      "unnamed\n",
      "extensive\n",
      "broader\n",
      "lengthy\n",
      "\n",
      "\n",
      "photograp\n",
      "moroc\n",
      "leng\n",
      "reim\n",
      "resur\n",
      "refres\n",
      "phis\n",
      "inflam\n",
      "detro\n",
      "resor\n",
      "\n",
      "\n",
      "generated\n",
      "influenced\n",
      "benefited\n",
      "initiated\n",
      "supported\n",
      "supplied\n",
      "aided\n",
      "attracted\n",
      "reviewed\n",
      "acquired\n",
      "\n",
      "\n",
      "theless\n",
      "negot\n",
      "compon\n",
      "ivid\n",
      "enthusia\n",
      "assage\n",
      "immen\n",
      "usalem\n",
      "dort\n",
      "itored\n",
      "\n",
      "\n",
      "scrut\n",
      "fict\n",
      "confis\n",
      "insurg\n",
      "proxim\n",
      "accompan\n",
      "obst\n",
      "o'ne\n",
      "itored\n",
      "dys\n",
      "\n",
      "\n",
      "profound\n",
      "dense\n",
      "immense\n",
      "substantial\n",
      "vague\n",
      "fierce\n",
      "fragile\n",
      "tremendous\n",
      "neat\n",
      "enormous\n",
      "\n",
      "\n",
      "kansas\n",
      "connecticut\n",
      "illinois\n",
      "pennsylvania\n",
      "arkansas\n",
      "louisiana\n",
      "maryland\n",
      "missouri\n",
      "tampa\n",
      "wisconsin\n",
      "\n",
      "\n",
      "ley's\n",
      "er's\n",
      "i's\n",
      "e's\n",
      "an's\n",
      "ton's\n",
      "on's\n",
      "ie's\n",
      "es'\n",
      "ler's\n",
      "\n",
      "\n",
      "espion\n",
      "explos\n",
      "unbeliev\n",
      "mclaugh\n",
      "inevit\n",
      "gbag\n",
      "ieval\n",
      "strugg\n",
      "itored\n",
      "glary\n",
      "\n",
      "\n",
      "athle\n",
      "drivers'\n",
      "quarterfinals\n",
      "standings\n",
      "occas\n",
      "espion\n",
      "liga\n",
      "couver\n",
      "glary\n",
      "bundesliga\n",
      "\n",
      "\n",
      "higher\n",
      "better\n",
      "harder\n",
      "faster\n",
      "bigger\n",
      "deeper\n",
      "worse\n",
      "greater\n",
      "cheaper\n",
      "stronger\n",
      "\n",
      "\n",
      "whate\n",
      "cuis\n",
      "manh\n",
      "accompan\n",
      "espion\n",
      "demp\n",
      "delaw\n",
      "o'ne\n",
      "enthusia\n",
      "theid\n",
      "\n",
      "\n",
      "anbar\n",
      "fallu\n",
      "occas\n",
      "homs\n",
      "environ\n",
      "mosul\n",
      "daraa\n",
      "lesterol\n",
      "ttp\n",
      "ifics\n",
      "\n",
      "\n",
      "confis\n",
      "dort\n",
      "compon\n",
      "attem\n",
      "ieval\n",
      "enrich\n",
      "incre\n",
      "surpris\n",
      "includ\n",
      "subsequ\n",
      "\n",
      "\n",
      "bullied\n",
      "depressed\n",
      "ashamed\n",
      "raped\n",
      "saddened\n",
      "gbag\n",
      "charac\n",
      "obese\n",
      "terrified\n",
      "ifics\n",
      "\n",
      "\n",
      "rehear\n",
      "engul\n",
      "resur\n",
      "eclip\n",
      "reim\n",
      "glimp\n",
      "moroc\n",
      "suc\n",
      "spear\n",
      "popu\n",
      "\n",
      "\n",
      "year\n",
      "friday\n",
      "week\n",
      "month\n",
      "sunday\n",
      "thursday\n",
      "monday\n",
      "saturday\n",
      "tuesday\n",
      "wednesday\n",
      "\n",
      "\n",
      "rampage\n",
      "bombings\n",
      "clashes\n",
      "shootings\n",
      "killings\n",
      "massacre\n",
      "slayings\n",
      "explosions\n",
      "altercation\n",
      "siege\n",
      "\n",
      "\n",
      "requiring\n",
      "letting\n",
      "violating\n",
      "distributing\n",
      "implementing\n",
      "introducing\n",
      "reducing\n",
      "ordering\n",
      "enforcing\n",
      "eliminating\n",
      "\n",
      "\n",
      "odox\n",
      "athle\n",
      "ifics\n",
      "massachu\n",
      "secutive\n",
      "charac\n",
      "mbley\n",
      "anmen\n",
      "tournam\n",
      "hrir\n",
      "\n",
      "\n",
      "museum\n",
      "institution\n",
      "facility\n",
      "library\n",
      "institute\n",
      "corporation\n",
      "organization\n",
      "council\n",
      "foundation\n",
      "ministry\n",
      "\n",
      "\n",
      "dys\n",
      "distr\n",
      "retr\n",
      "desc\n",
      "contr\n",
      "cont\n",
      "extr\n",
      "appreh\n",
      "videot\n",
      "transc\n",
      "\n",
      "\n",
      "insisted\n",
      "explained\n",
      "argued\n",
      "cautioned\n",
      "replied\n",
      "joked\n",
      "testified\n",
      "acknowledged\n",
      "wondered\n",
      "vowed\n",
      "\n",
      "\n",
      "independents\n",
      "hispanics\n",
      "colleges\n",
      "economists\n",
      "liberals\n",
      "households\n",
      "respondents\n",
      "entrepreneurs\n",
      "conservatives\n",
      "governors\n",
      "\n",
      "\n",
      "scand\n",
      "traged\n",
      "dort\n",
      "strug\n",
      "yose\n",
      "jere\n",
      "compon\n",
      "surpris\n",
      "califor\n",
      "theless\n",
      "\n",
      "\n",
      "detonated\n",
      "stormed\n",
      "grabbed\n",
      "engulfed\n",
      "transported\n",
      "raided\n",
      "chased\n",
      "entered\n",
      "collided\n",
      "invaded\n",
      "\n",
      "\n",
      "albums\n",
      "singers\n",
      "festivals\n",
      "musicians\n",
      "novels\n",
      "uguay\n",
      "espion\n",
      "glary\n",
      "strugg\n",
      "oscars\n",
      "\n",
      "\n",
      "in\n",
      "at\n",
      "from\n",
      "by\n",
      "when\n",
      "during\n",
      "after\n",
      "for\n",
      "on\n",
      "with\n",
      "\n",
      "\n",
      "certainly\n",
      "probably\n",
      "definitely\n",
      "never\n",
      "obviously\n",
      "hardly\n",
      "surely\n",
      "actually\n",
      "always\n",
      "usually\n",
      "\n",
      "\n",
      "suites\n",
      "floors\n",
      "shelters\n",
      "beaches\n",
      "trees\n",
      "pools\n",
      "bottles\n",
      "shops\n",
      "delaw\n",
      "glary\n",
      "\n",
      "\n",
      "boko\n",
      "yemeni\n",
      "somali\n",
      "somalia's\n",
      "saudi\n",
      "lebanese\n",
      "bosnian\n",
      "sri\n",
      "sudanese\n",
      "transitional\n",
      "\n",
      "\n",
      "responses\n",
      "attempts\n",
      "lawsuits\n",
      "decisions\n",
      "statements\n",
      "inquiries\n",
      "agreements\n",
      "proposals\n",
      "accusations\n",
      "discussions\n",
      "\n",
      "\n",
      "islamists\n",
      "militias\n",
      "shiites\n",
      "gunmen\n",
      "kurds\n",
      "militants\n",
      "egyptians\n",
      "insurgents\n",
      "houthis\n",
      "sunnis\n",
      "\n",
      "\n",
      "couver\n",
      "ailand\n",
      "inals\n",
      "glary\n",
      "ences\n",
      "ivid\n",
      "espion\n",
      "hrir\n",
      "theid\n",
      "negot\n",
      "\n",
      "\n",
      "mashable\n",
      "android\n",
      "verizon\n",
      "itunes\n",
      "playstation\n",
      "samsung\n",
      "nintend\n",
      "nintendo\n",
      "silicon\n",
      "netflix\n",
      "\n",
      "\n",
      "rainfall\n",
      "floods\n",
      "diarrhea\n",
      "devastation\n",
      "outages\n",
      "rains\n",
      "earthquakes\n",
      "vomiting\n",
      "espion\n",
      "snowfall\n",
      "\n",
      "\n",
      "scrut\n",
      "testim\n",
      "rele\n",
      "nutr\n",
      "proto\n",
      "leng\n",
      "scand\n",
      "obst\n",
      "accompan\n",
      "whate\n",
      "\n",
      "\n",
      "f\n",
      "l\n",
      "g\n",
      "d\n",
      "r\n",
      "t\n",
      " \n",
      "v\n",
      "b\n",
      "k\n",
      "\n",
      "\n",
      "lebanon's\n",
      "london's\n",
      "yemen's\n",
      "football's\n",
      "ukraine's\n",
      "egypt's\n",
      "afghanistan's\n",
      "libya's\n",
      "somalia's\n",
      "greece's\n",
      "\n",
      "\n",
      "sectors\n",
      "technologies\n",
      "sensors\n",
      "industries\n",
      "providers\n",
      "environments\n",
      "techniques\n",
      "entities\n",
      "installations\n",
      "tasks\n",
      "\n",
      "\n",
      "hrir\n",
      "lesterol\n",
      "glary\n",
      "icting\n",
      "charac\n",
      "fahren\n",
      "mbley\n",
      "negot\n",
      "couver\n",
      "oking\n",
      "\n",
      "\n",
      "assumption\n",
      "acknowled\n",
      "reminder\n",
      "notion\n",
      "mechanism\n",
      "incentive\n",
      "espion\n",
      "strugg\n",
      "obstacle\n",
      "inevit\n",
      "\n",
      "\n",
      "promptly\n",
      "swiftly\n",
      "safely\n",
      "adequately\n",
      "broadly\n",
      "properly\n",
      "readily\n",
      "thoroughly\n",
      "instantly\n",
      "voluntarily\n",
      "\n",
      "\n",
      "give\n",
      "make\n",
      "bring\n",
      "get\n",
      "want\n",
      "take\n",
      "tell\n",
      "subscribe\n",
      "learn\n",
      "keep\n",
      "\n",
      "\n",
      "assage\n",
      "enthusia\n",
      "theid\n",
      "uguay\n",
      "usalem\n",
      "ieval\n",
      "negot\n",
      "espion\n",
      "moil\n",
      "performan\n",
      "\n",
      "\n",
      "confis\n",
      "compon\n",
      "surpris\n",
      "notor\n",
      "dort\n",
      "attem\n",
      "scrut\n",
      "insurg\n",
      "refres\n",
      "accompan\n",
      "\n",
      "\n",
      "went\n",
      "took\n",
      "brought\n",
      "came\n",
      "pulled\n",
      "turned\n",
      "moved\n",
      "gave\n",
      "jumped\n",
      "walked\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_embed = model.word_embed\n",
    "embedding_clustering = EmbeddingClustering(tokenizer, n_clusters=100)\n",
    "embedding_clustering.fit(word_embed, normalize=True)\n",
    "embedding_clustering.print_clusters(n_words=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc968e2d",
   "metadata": {},
   "source": [
    "# Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0de0e293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1602]], shape=(1, 1), dtype=int32)\n",
      "tf.Tensor([[3512]], shape=(1, 1), dtype=int32)\n",
      "tf.Tensor([[5393]], shape=(1, 1), dtype=int32)\n",
      "netanyahu\n",
      "russia\n",
      "israel\n",
      "hamas\n",
      "israelis\n",
      "jerusalem\n",
      "tehran\n",
      "kiev\n",
      "gaza\n",
      "palestinians\n",
      "democr\n",
      "beirut\n",
      "azer\n",
      "syria\n",
      "egypt\n",
      "idf\n",
      "iran\n",
      "britain\n",
      "palestinian\n",
      "abbas\n",
      "tunisia\n",
      "alger\n",
      "lebanon\n",
      "perpe\n",
      "israeli\n",
      "davos\n",
      "brahim\n",
      "controver\n",
      "hezbollah\n",
      "hagel\n",
      "jevich\n",
      "norway\n",
      "fah\n",
      "guinea\n",
      "khamenei\n",
      "cuba\n",
      "anbar\n",
      "utt\n",
      "khamene\n",
      "hezbol\n",
      "weren\n",
      "canada\n",
      "sunnis\n",
      "dipl\n",
      "stoke\n",
      "lavrov\n",
      "aviv\n",
      "karzai\n",
      "israel's\n",
      "arct\n",
      "cambodia\n",
      "zuckerberg\n",
      "yanukov\n",
      "yad\n",
      "ukraine\n",
      "pakistan\n",
      "carney\n",
      "netherlands\n",
      "cairo\n",
      "lieberman\n",
      "panetta\n",
      "homs\n",
      "zawah\n",
      "austria\n",
      "espion\n",
      "wawrink\n",
      "vinc\n",
      "libertar\n",
      "libya\n",
      "poland\n",
      "indonesia\n",
      "liby\n",
      "merkel\n",
      "pyongyang\n",
      "tik\n",
      "airstrikes\n",
      "ibrahimovic\n",
      "abe\n",
      "iran's\n",
      "yugo\n",
      "kass\n",
      "mosul\n",
      "galax\n",
      "yemen\n",
      "scotland\n",
      "settlements\n",
      "sudan\n",
      "nuri\n",
      "niger\n",
      "palestine\n",
      "tsvangira\n",
      "ieval\n",
      "iaea\n",
      "denmark\n",
      "hmer\n",
      "tahrir\n",
      "nusra\n",
      "sarkoz\n",
      "ukrain\n",
      "bolivia\n"
     ]
    }
   ],
   "source": [
    "word_embed = model.word_embed\n",
    "\n",
    "text = \"russia\"\n",
    "text = text.lower()\n",
    "\n",
    "idx = tf.cast(tokenizer.tokenizer.tokenize(text), tf.int32)\n",
    "idx = tokenize(idx, tokenizer.merge_list)\n",
    "print(idx)\n",
    "embed1 = tf.expand_dims(word_embed[idx[0][0]], axis=0)\n",
    "\n",
    "\n",
    "text = \"putin\"\n",
    "text = text.lower()\n",
    "\n",
    "idx = tf.cast(tokenizer.tokenizer.tokenize(text), tf.int32)\n",
    "idx = tokenize(idx, tokenizer.merge_list)\n",
    "print(idx)\n",
    "embed2 = tf.expand_dims(word_embed[idx[0][0]], axis=0)\n",
    "\n",
    "text = \"netanyahu\"\n",
    "text = text.lower()\n",
    "\n",
    "idx = tf.cast(tokenizer.tokenizer.tokenize(text), tf.int32)\n",
    "idx = tokenize(idx, tokenizer.merge_list)\n",
    "print(idx)\n",
    "embed3 = tf.expand_dims(word_embed[idx[0][0]], axis=0)\n",
    "\n",
    "embed = embed1 - embed2 + embed3\n",
    "\n",
    "cosine_sim = cosine_similarity(embed, word_embed, normalize=False)\n",
    "idx = tf.argsort(cosine_sim, axis=-1, \n",
    "                 direction='DESCENDING',\n",
    "                 #direction='ASCENDING', \n",
    "                 stable=False, name=None)[0]\n",
    "\n",
    "for i in idx[:100]:\n",
    "    i = tf.expand_dims(i, axis=0)\n",
    "    print(tokenizer.detokenize(i).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54734624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[553]], shape=(1, 1), dtype=int32)\n",
      "obama\n",
      "obama's\n",
      "clinton\n",
      "romney\n",
      "republicans\n",
      "bush\n",
      "boehner\n",
      "sen\n",
      "reagan\n",
      "democrats\n",
      "barack\n",
      "mccain\n",
      "congressional\n",
      "sarkozy\n",
      "pentagon\n",
      "putin\n",
      "u\n",
      "assad\n",
      "liberals\n",
      "afghans\n",
      "calderon\n",
      "washington\n",
      "bush's\n",
      "conservatives\n",
      "president\n",
      "obamacare\n",
      "iraqis\n",
      "panetta\n",
      "snowden\n",
      "mcconnell\n",
      "clinton's\n",
      "chavez\n",
      "gop\n",
      "palin\n",
      "americans\n",
      "senate\n",
      "christie\n",
      "isis\n",
      "veterans\n",
      "he\n",
      "voters\n",
      "petraeus\n",
      "pelosi\n",
      "secretary\n",
      "jindal\n",
      "george\n",
      "mandela\n",
      "republican\n",
      "kerry\n",
      "karzai\n",
      "biden\n",
      "gop's\n",
      "francis\n",
      "economists\n",
      "lawmakers\n",
      "jeb\n",
      "we've\n",
      "congressman\n",
      "rouhani\n",
      "navarrette\n",
      "congress\n",
      "netanyahu\n",
      "latinos\n",
      "nixon\n",
      "aides\n",
      "iraqi\n",
      "nra\n",
      "pelos\n",
      "richard\n",
      "white\n",
      "clint\n",
      "gov\n",
      "lincoln\n",
      "romney's\n",
      "gingrich\n",
      "taxpayers\n",
      "nato\n",
      "presidents\n",
      "vietnam\n",
      "nieto\n",
      "analysts\n",
      "president's\n",
      "ryan\n",
      "gupta\n",
      "senators\n",
      "cdc\n",
      "shinse\n",
      "brennan\n",
      "next\n",
      "capitol\n",
      "legislators\n",
      "ahmadinejad\n",
      "elect\n",
      "erdogan\n",
      "afghanistan\n",
      "iraq\n",
      "gadhafi\n",
      "roosevelt\n",
      "cheney\n",
      "santorum\n"
     ]
    }
   ],
   "source": [
    "word_embed = model.word_embed\n",
    "\n",
    "text = \"obama\"\n",
    "text = text.lower()\n",
    "\n",
    "idx = tf.cast(tokenizer.tokenize(text), tf.int32)\n",
    "print(idx)\n",
    "embed = tf.expand_dims(word_embed[idx[0][0]], axis=0)\n",
    "\n",
    "cosine_sim = embed@tf.transpose(word_embed)\n",
    "idx = tf.argsort(cosine_sim, axis=-1, \n",
    "                 direction='DESCENDING',\n",
    "                 #direction='ASCENDING', \n",
    "                 stable=False, name=None)[0]\n",
    "\n",
    "for i in idx[:100]:\n",
    "    i = tf.expand_dims(i, axis=0)\n",
    "    print(tokenizer.detokenize(i).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff23330f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[5393]], shape=(1, 1), dtype=int32)\n",
      "netanyahu\n",
      "abulary\n",
      "hagel\n",
      "maduro\n",
      "espion\n",
      "yingluck\n",
      "onsored\n",
      "nandez\n",
      "saleh\n",
      "natur\n",
      "ailand\n",
      "hezbol\n",
      "panetta\n",
      "biden\n",
      "shinse\n",
      "kerry\n",
      "gibbs\n",
      "sarkozy\n",
      "fundam\n",
      "hift\n",
      "patro\n",
      "signific\n",
      "anonymity\n",
      "putin\n",
      "mugabe\n",
      "lades\n",
      "boehner\n",
      "pelosi\n",
      "medvedev\n",
      "ahmadinejad\n",
      "warri\n",
      "thaksin\n",
      "landrieu\n",
      "shaba\n",
      "gbag\n",
      "accust\n",
      "charac\n",
      "fahren\n",
      "liby\n",
      "peninsu\n",
      "helicop\n",
      "zuma\n",
      "traged\n",
      "portugu\n",
      "morsy\n",
      "publ\n",
      "enjo\n",
      "ilight\n",
      "abbas\n",
      "erdogan\n",
      "ieval\n",
      "bachmann\n",
      "yanukovych\n",
      "leep\n",
      "confir\n",
      "rodrigue\n",
      "secutive\n",
      "provin\n",
      "mccain's\n",
      "moil\n",
      "subsequ\n",
      "abled\n",
      "juvent\n",
      "o'ne\n",
      "guardiola\n",
      "lieberman\n",
      "karzai\n",
      "catastro\n",
      "ouatt\n",
      "zardari\n",
      "possib\n",
      "toug\n",
      "theless\n",
      "burma\n",
      "carney\n",
      "ricul\n",
      "zhok\n",
      "barcelon\n",
      "dort\n",
      "sunnis\n",
      "lomb\n",
      "snowden\n",
      "avez\n",
      "diffic\n",
      "sess\n",
      "khamenei\n",
      "exer\n",
      "golese\n",
      "copen\n",
      "rouhani\n",
      "ipal\n",
      "transparen\n",
      "ultane\n",
      "mccain\n",
      "boeh\n",
      "diox\n",
      "citiz\n",
      "adjac\n",
      "nieto\n",
      "lavrov\n"
     ]
    }
   ],
   "source": [
    "word_embed = model.word_embed\n",
    "\n",
    "text = \"netanyahu\"\n",
    "text = text.lower()\n",
    "\n",
    "idx = tf.cast(tokenizer.tokenizer.tokenize(text), tf.int32)\n",
    "idx = tokenize(idx, tokenizer.merge_list)\n",
    "print(idx)\n",
    "embed = tf.expand_dims(word_embed[idx[0][0]], axis=0)\n",
    "\n",
    "cosine_sim = embed@tf.transpose(word_embed)\n",
    "idx = tf.argsort(cosine_sim, axis=-1, \n",
    "                 direction='DESCENDING',\n",
    "                 #direction='ASCENDING', \n",
    "                 stable=False, name=None)[0]\n",
    "\n",
    "for i in idx[:100]:\n",
    "    i = tf.expand_dims(i, axis=0)\n",
    "    print(tokenizer.detokenize(i).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ff28a5",
   "metadata": {},
   "source": [
    "## Mean Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b71e4c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 62)\n",
      " \n",
      ".\n",
      "-\n",
      "\"\n",
      ",\n",
      "a\n",
      "in\n",
      "\n",
      "\n",
      "and\n",
      "the\n",
      "on\n",
      "to\n",
      "at\n",
      "'\n",
      "an\n",
      "or\n",
      "u\n",
      "by\n",
      "that\n",
      ":\n",
      "as\n",
      "'s\n",
      "s\n",
      "al\n",
      "of\n",
      "it\n",
      "he\n",
      "for\n",
      "un\n",
      "over\n",
      "e\n",
      "about\n",
      "is\n",
      "with\n",
      "after\n",
      "up\n",
      "not\n",
      "last\n",
      "more\n",
      "may\n",
      "?\n",
      "re\n",
      "from\n",
      "ad\n",
      "(\n",
      "state\n",
      "be\n",
      "just\n",
      "so\n",
      "was\n",
      "one\n",
      "/\n",
      "ed\n",
      "no\n",
      "war\n",
      "while\n",
      "security\n",
      ";\n",
      "but\n",
      "1\n",
      "en\n",
      "n\n",
      "man\n",
      "house\n",
      "i\n",
      "north\n",
      "m\n",
      "first\n",
      "ar\n",
      "l\n",
      "f\n",
      "c\n",
      "er\n",
      "there\n",
      "out\n",
      "o\n",
      "do\n",
      "two\n",
      "when\n",
      "less\n",
      "had\n",
      "air\n",
      "k\n",
      "v\n",
      "h\n",
      "near\n",
      "they\n",
      "2\n",
      "his\n",
      "some\n",
      "de\n",
      "back\n",
      "we\n",
      "field\n",
      "fire\n",
      "if\n",
      "this\n",
      "under\n",
      "p\n",
      "right\n"
     ]
    }
   ],
   "source": [
    "word_embed = model.word_embed\n",
    "\n",
    "text = \"Obama's remarks came shortly after U.N. inspectors left Syria, carrying evidence that will determine whether chemical weapons were used in an attack early last week in a Damascus suburb.\"\n",
    "text = text.lower()\n",
    "\n",
    "idx = tf.cast(tokenizer.tokenizer.tokenize(text), tf.int32)\n",
    "idx = tokenize(idx, tokenizer.merge_list)\n",
    "print(idx.shape)\n",
    "embed_final = model.call(idx, logits=False)\n",
    "#embed_mean = embed_final[:,-1,:]\n",
    "embed_mean = tf.reduce_mean(embed_final, axis=1)\n",
    "embed_mean = tf.cast(embed_mean, dtype=tf.float32) \n",
    "\n",
    "cosine_sim = cosine_similarity(embed_mean, word_embed, normalize=False)\n",
    "#cosine_sim = cosine_similarity(embed_mean, word_embed, normalize=True)\n",
    "\n",
    "idx = tf.argsort(cosine_sim, axis=-1, \n",
    "                 direction='DESCENDING',\n",
    "                 #direction='ASCENDING', \n",
    "                 stable=False, name=None)[0]\n",
    "\n",
    "for i in idx[:100]:\n",
    "    i = tf.expand_dims(i, axis=0)\n",
    "    print(tokenizer.detokenize(i).numpy().decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d6f1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[553]], shape=(1, 1), dtype=int32)\n",
      "tf.Tensor(0.08745351, shape=(), dtype=float32)\n",
      "tf.Tensor([[    1    13    15 ... 15466  9736 15505]], shape=(1, 16070), dtype=int32)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m i \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(i, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "word_embed = model.word_embed\n",
    "\n",
    "text = \"Obama\"\n",
    "text = text.lower()\n",
    "\n",
    "idx = tf.cast(tokenizer.tokenizer.tokenize(text), tf.int32)\n",
    "idx = tokenize(idx, tokenizer.merge_list)\n",
    "print(idx)\n",
    "b = model.unembed_b[idx[0][0]]\n",
    "print(b)\n",
    "logits = model.call(idx, logits=True) \n",
    "#embed_mean = embed_final[:,-1,:]\n",
    "embed_mean = tf.reduce_mean(embed_final, axis=1)\n",
    "embed_mean = tf.cast(embed_mean, dtype=tf.float32)\n",
    "\n",
    "cosine_sim = cosine_similarity(embed_mean, word_embed, normalize=False)\n",
    "#cosine_sim = cosine_similarity(embed_mean, word_embed, normalize=True)\n",
    "\n",
    "idx = tf.argsort(logits, axis=-1, \n",
    "                 direction='DESCENDING',\n",
    "                 #direction='ASCENDING', \n",
    "                 stable=False, name=None)[0]\n",
    "\n",
    "for i in idx[:100]:\n",
    "    i = tf.expand_dims(i, axis=0)\n",
    "    print(i)\n",
    "    print(tokenizer.detokenize(i).numpy().decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a5f20b",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
