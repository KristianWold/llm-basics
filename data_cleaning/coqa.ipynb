{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04010a08",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fa3d166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src/')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tokenizer import TokenizerBPE\n",
    "from data_handling import normalize_to_ascii\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pickle as pkl\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "\n",
    "# disable gpu for testing purposes\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f199c71",
   "metadata": {},
   "source": [
    "## CoQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d3f6ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../corpus/coqa-train-v1.0.json', 'r', encoding='utf-8') as f:\n",
    "    coqa = json.load(f)\n",
    "\n",
    "data = coqa[\"data\"]\n",
    "length = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa0f3fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5607acbabfd4b499ab8170eff62ad5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context_list = []\n",
    "question_grouped = [[] for _ in range(length)]\n",
    "answer_grouped = [[] for _ in range(length)]\n",
    "\n",
    "\n",
    "for i, sample in tqdm(enumerate(data), total=length):\n",
    "    context_list.append(sample[\"story\"])\n",
    "    qa = sample[\"questions\"]\n",
    "    for question in qa:\n",
    "        question_grouped[i].append(question[\"input_text\"])\n",
    "    answers = sample[\"answers\"]\n",
    "    for answer in answers:\n",
    "        answer_grouped[i].append(answer[\"input_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27e078e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../')\n",
    "tokenizer = pkl.load(open(\"../tokenizers/tokenizer_superQA_24k.pkl\", \"rb\"))\n",
    "tokenizer.create_hash()\n",
    "tokenizer.add_special_tokens([\"<s>\", \"</s>\", \"<q>\", \"<a>\", \"<pad>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3d8bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fused_sqa(story_list, question_grouped_list, answer_grouped_list):\n",
    "    q =\"<q>\"\n",
    "    a = \"<a>\"\n",
    "    sos = \"<s>\"\n",
    "    eos = \"</s>\"\n",
    "\n",
    "    rcw = re.compile(r\"\\s+\")\n",
    "\n",
    "    corpus_list = []\n",
    "    for story, question_list, answer_list in tqdm(list(zip(story_list, question_grouped_list, answer_grouped_list))):\n",
    "        story = story.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "        story = rcw.sub(\" \", story).strip()\n",
    "        sqa = [sos, normalize_to_ascii(story).lower()]\n",
    "        for question, answer in zip(question_list, answer_list):\n",
    "            question = question.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "            question = rcw.sub(\" \", question).strip()\n",
    "            answer = answer.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "            answer = rcw.sub(\" \", answer).strip()\n",
    "            sqa.append(q)\n",
    "            sqa.append(normalize_to_ascii(question).lower())\n",
    "            sqa.append(a)\n",
    "            sqa.append(normalize_to_ascii(answer).lower())\n",
    "        sqa.append(eos)\n",
    "        corpus_list.append(\"\".join(sqa))\n",
    "        \n",
    "    return corpus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4530e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3586f73ae4f34d68bc7cf67100009c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5373793fd07544fc877da565ca7adbe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'corpus/corpus_clean/corpus_coqa_sqa_24k'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m fused \u001b[38;5;241m=\u001b[39m fused_sqa(context_list, question_grouped, answer_grouped)\n\u001b[0;32m      2\u001b[0m corpus_encoded \u001b[38;5;241m=\u001b[39m [tokenizer\u001b[38;5;241m.\u001b[39mencode(line\u001b[38;5;241m.\u001b[39mlower()) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m tqdm(fused)]\n\u001b[1;32m----> 4\u001b[0m pkl\u001b[38;5;241m.\u001b[39mdump(corpus_encoded, \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcorpus/corpus_clean/corpus_coqa_sqa_24k\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'corpus/corpus_clean/corpus_coqa_sqa_24k'"
     ]
    }
   ],
   "source": [
    "fused = fused_sqa(context_list, question_grouped, answer_grouped)\n",
    "corpus_encoded = [tokenizer.encode(line.lower()) for line in tqdm(fused)]\n",
    "\n",
    "pkl.dump(corpus_encoded, open('../corpus/corpus_clean/corpus_coqa_sqa_24k', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b1f01a",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebb373a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_corpus(corpus, max_length, tokenizer):\n",
    "    pad_token = tokenizer.token_to_idx[\"<pad>\"]\n",
    "    padded_corpus = []\n",
    "    for line in tqdm(corpus):\n",
    "        if line.shape[1] < max_length:\n",
    "            padding = tf.repeat(tf.constant([[pad_token]]), max_length - line.shape[1], axis=1)\n",
    "            padded_line = tf.concat([line, padding], axis=1)\n",
    "        else:\n",
    "            padded_line = line[:, :max_length]\n",
    "        padded_corpus.append(padded_line)\n",
    "    return tf.concat(padded_corpus, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ae2643a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df01bdc69bc04fda8f4f1a8eb7bd3e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus_encoded = pkl.load(open('../corpus/corpus_clean/corpus_coqa_sqa_24k', 'rb'))\n",
    "corpus_padded = pad_corpus(corpus_encoded, 768, tokenizer)\n",
    "pkl.dump(corpus_padded, open('../corpus/corpus_clean/corpus_coqa_sqa_24k_padded', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a5f20b",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
