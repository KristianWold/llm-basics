{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04010a08",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fa3d166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from src.tokenizer import TokenizerBPE, fuse_tokenized_corpus, chunk_corpus\n",
    "\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from tqdm.notebook import tqdm\n",
    "from src.transformer import Transformer, WarmUpThenDecay\n",
    "from src.data_handling import read_first_n, sample_batch\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2b59898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4080, compute capability 8.9\n"
     ]
    }
   ],
   "source": [
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "576256a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_and_batch(corpus, chunk_size, batch_size, ):\n",
    "    num_tokens = len(corpus)//chunk_size*chunk_size\n",
    "    num_chunks = num_tokens//chunk_size\n",
    "\n",
    "    steps_per_epoch = num_chunks//batch_size\n",
    "    \n",
    "    ds = tf.data.Dataset.from_tensor_slices(corpus)\n",
    "    ds = ds.repeat()\n",
    "    ds = ds.batch(chunk_size, drop_remainder=True)\n",
    "    ds = ds.shuffle(buffer_size=100*chunk_size, reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(batch_size, drop_remainder=True).repeat().prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return ds, steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7afd4e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 1024\n",
    "\n",
    "tokenizer = pkl.load(open(\"tokenizers/tokenizer_CNN16000_lowercase.pkl\", 'rb'))\n",
    "tokenizer.create_hash()\n",
    "tokenizer.pre_merge_list = []\n",
    "tokenizer.add_special_tokens([\"<s>\", \"</s>\"])\n",
    "tokenizer.create_hash()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e38fb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = 30235237//2\n",
    "\n",
    "train_corpus = pkl.load(open('corpus/CNN_train_fused.pkl', 'rb'))[0]\n",
    "test_corpus = pkl.load(open('corpus/CNN_test_fused.pkl', 'rb'))[0]\n",
    "\n",
    "train_corpus = tf.concat([train_corpus, test_corpus[:cut]], axis=0)\n",
    "test_corpus = test_corpus[cut:]\n",
    "\n",
    "ds_train, steps_per_epoch  = chunk_and_batch(train_corpus, chunk_size=max_seq_len, batch_size=3)\n",
    "ds_test, _ = chunk_and_batch(test_corpus, chunk_size=max_seq_len, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4caf3927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43881\n",
      "Train corpus size:  134803325\n",
      "Test corpus size:  15117619\n"
     ]
    }
   ],
   "source": [
    "print(steps_per_epoch)\n",
    "print(\"Train corpus size: \", len(train_corpus))\n",
    "print(\"Test corpus size: \", len(test_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f830d881",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d47b8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr = 1e-4\n",
    "decay_steps = 20000\n",
    "decay_rate = 0.5\n",
    "decay_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=initial_lr,\n",
    "    decay_steps=decay_steps,\n",
    "    decay_rate=decay_rate,\n",
    "    staircase=False)\n",
    "\n",
    "warmup_steps = 1000\n",
    "lr_schedule = WarmUpThenDecay(\n",
    "    initial_learning_rate=initial_lr,\n",
    "    warmup_steps=warmup_steps,\n",
    "    decay_schedule_fn=decay_schedule)\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "max_seq_len = 1024\n",
    "embed_dim = 896\n",
    "tf_blocks = 14\n",
    "heads = 14\n",
    "ff_dim = 4*embed_dim\n",
    "weight_decay = 0.01\n",
    "dropout = 0.1\n",
    "\n",
    "unembed_dims = []\n",
    "\n",
    "model = Transformer(vocab_size=tokenizer.vocab_size,\n",
    "                    max_seq_len=max_seq_len,\n",
    "                    embed_dim=embed_dim,\n",
    "                    tf_blocks=tf_blocks,\n",
    "                    heads=heads,\n",
    "                    ff_dim = ff_dim,\n",
    "                    unembed_dims=unembed_dims,\n",
    "                    tokenizer=tokenizer,\n",
    "                    lr=lr_schedule,\n",
    "                    wd = weight_decay,\n",
    "                    dropout=dropout,\n",
    "                    accum_steps=8,\n",
    "                    )\n",
    "\n",
    "losses_train = []\n",
    "losses_test = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7970a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"model_16k_CNN_yuge\"\n",
    "\n",
    "\n",
    "ckpt = tf.train.Checkpoint(\n",
    "    optimizer=model.opt,\n",
    "    model=model\n",
    ")\n",
    "ckpt_manager = tf.train.CheckpointManager(\n",
    "    ckpt, \n",
    "    directory=\"checkpoints/\" + name,      # folder where ckpts are saved\n",
    "    max_to_keep=5                         # only keep 5 latest checkpoints\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88b34765",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "losses_train, losses_test = pkl.load(open(\"checkpoints/losses_\" + name + \".pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6527620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 150320072\n"
     ]
    }
   ],
   "source": [
    "total_params = 0\n",
    "for var in model.parameter_list:\n",
    "    shape = var.get_shape()\n",
    "    num_params = 1\n",
    "    for dim in shape:\n",
    "        num_params *= dim\n",
    "    total_params += num_params\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8a0126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(iter_train, iter_test, steps_per_epoch, epochs):\n",
    "    for i in tqdm(range(steps_per_epoch*epochs)):\n",
    "        batch_train = next(iter_train)\n",
    "        batch_test = next(iter_test)\n",
    "        \n",
    "        loss_train = model.train_step(batch_train).numpy()\n",
    "        losses_train.append(loss_train)\n",
    "        \n",
    "        loss_test = model.evaluate(batch_test).numpy()\n",
    "        losses_test.append(loss_test)\n",
    "\n",
    "        if (i+1) % 1000 == 0:\n",
    "            ckpt_manager.save()\n",
    "            pkl.dump([losses_train, losses_test], open(\"checkpoints/losses_\" + name + \".pkl\", 'wb'))\n",
    "\n",
    "        lr = model.opt.inner_optimizer._decayed_lr(tf.float32).numpy()\n",
    "        print(loss_train, loss_test, lr)\n",
    "    return losses_train, losses_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25d60938",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_train = iter(ds_train)\n",
    "iter_test = iter(iter_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1858201f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ec57be2ef8478298a1fca3c12c54cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131643 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Tracing train_step; token shape: (None, None)\n",
      "ðŸ”„ Tracing train_step; token shape: (None, None)\n",
      "14.840654 15.037684 0.0\n",
      "15.282411 15.195937 0.0\n",
      "14.748656 15.193868 0.0\n",
      "15.23812 15.18248 0.0\n",
      "14.950511 15.320613 0.0\n",
      "14.940202 15.165252 0.0\n",
      "15.045801 15.271885 0.0\n",
      "14.8310995 15.014384 1e-07\n",
      "14.93185 15.091758 1e-07\n",
      "14.965809 15.020949 1e-07\n",
      "14.92372 15.052412 1e-07\n",
      "15.09752 15.209582 1e-07\n",
      "15.02003 15.01228 1e-07\n",
      "14.835074 15.148035 1e-07\n",
      "14.778823 14.962587 1e-07\n",
      "14.756562 14.986536 2e-07\n",
      "14.84562 14.915182 2e-07\n",
      "15.029774 15.166984 2e-07\n",
      "14.779714 15.064875 2e-07\n",
      "14.993303 14.939669 2e-07\n",
      "14.919806 15.122841 2e-07\n",
      "14.877339 14.987004 2e-07\n",
      "14.787253 15.022153 2e-07\n",
      "14.941588 14.894953 2.9999998e-07\n",
      "14.52015 15.092296 2.9999998e-07\n",
      "14.946495 14.92852 2.9999998e-07\n",
      "14.807931 15.01278 2.9999998e-07\n",
      "14.775293 14.711388 2.9999998e-07\n",
      "14.853199 15.175444 2.9999998e-07\n",
      "14.717681 15.051641 2.9999998e-07\n",
      "15.2193775 14.866321 2.9999998e-07\n",
      "14.832954 14.936388 4e-07\n",
      "14.96298 14.803876 4e-07\n",
      "14.729811 14.603473 4e-07\n",
      "14.599838 14.686596 4e-07\n",
      "14.590589 15.052454 4e-07\n",
      "14.51699 14.912386 4e-07\n",
      "14.859258 14.680151 4e-07\n",
      "14.474706 14.843207 4e-07\n",
      "14.965239 14.492065 5e-07\n",
      "14.650732 14.485191 5e-07\n",
      "14.48949 14.601438 5e-07\n",
      "14.618655 14.528448 5e-07\n",
      "14.468317 14.631291 5e-07\n",
      "14.445283 14.352744 5e-07\n",
      "14.409324 14.535368 5e-07\n",
      "14.527283 14.597969 5e-07\n",
      "14.348626 13.79859 5.9999996e-07\n",
      "14.048833 14.2777405 5.9999996e-07\n",
      "14.204539 14.166433 5.9999996e-07\n",
      "14.193562 14.275841 5.9999996e-07\n",
      "14.355791 13.993176 5.9999996e-07\n",
      "14.003876 14.215906 5.9999996e-07\n",
      "13.898062 14.3909025 5.9999996e-07\n",
      "14.14304 14.540119 5.9999996e-07\n",
      "14.05869 13.964343 7e-07\n",
      "13.705171 13.78047 7e-07\n",
      "13.997022 13.673388 7e-07\n",
      "13.888837 13.924847 7e-07\n",
      "13.831073 13.779612 7e-07\n",
      "13.945912 13.853828 7e-07\n",
      "13.979088 13.723523 7e-07\n",
      "13.696069 13.64403 7e-07\n",
      "13.744964 13.451703 8e-07\n",
      "13.1839905 13.046343 8e-07\n",
      "13.544292 13.265989 8e-07\n",
      "13.704537 13.176367 8e-07\n",
      "13.19519 13.441741 8e-07\n",
      "13.421693 13.061078 8e-07\n",
      "13.2370615 13.258539 8e-07\n",
      "13.293458 13.417977 8e-07\n",
      "13.494752 12.817012 8.999999e-07\n",
      "12.851809 12.712249 8.999999e-07\n",
      "12.90123 12.553249 8.999999e-07\n",
      "13.058983 12.564515 8.999999e-07\n",
      "12.878776 12.654934 8.999999e-07\n",
      "12.9609785 12.544764 8.999999e-07\n",
      "13.140408 12.886123 8.999999e-07\n",
      "13.03863 12.6029625 8.999999e-07\n",
      "12.809994 11.97672 1e-06\n",
      "12.321678 11.954794 1e-06\n",
      "12.292241 11.778575 1e-06\n",
      "12.12627 12.031479 1e-06\n",
      "12.117703 11.775157 1e-06\n",
      "12.078752 12.13125 1e-06\n",
      "12.123922 12.129866 1e-06\n",
      "12.3061905 11.869755 1e-06\n",
      "12.427833 11.3937845 1.1e-06\n",
      "11.9318 11.512496 1.1e-06\n",
      "11.552429 11.264011 1.1e-06\n",
      "11.866504 11.405147 1.1e-06\n",
      "11.665934 11.240537 1.1e-06\n",
      "11.646816 11.433806 1.1e-06\n",
      "11.480347 11.404409 1.1e-06\n",
      "11.843741 11.314519 1.1e-06\n",
      "11.644015 10.587326 1.1999999e-06\n",
      "10.867081 10.643705 1.1999999e-06\n",
      "11.311474 10.400394 1.1999999e-06\n",
      "10.999061 10.565437 1.1999999e-06\n",
      "10.904583 10.358882 1.1999999e-06\n",
      "10.932289 10.468993 1.1999999e-06\n",
      "11.100031 10.778024 1.1999999e-06\n",
      "10.763485 10.5720005 1.1999999e-06\n",
      "11.002666 9.772218 1.3e-06\n",
      "9.919068 9.872356 1.3e-06\n",
      "10.422747 9.605557 1.3e-06\n",
      "10.40411 9.726567 1.3e-06\n",
      "10.218532 9.408598 1.3e-06\n",
      "9.944881 9.666922 1.3e-06\n",
      "9.757458 9.671057 1.3e-06\n",
      "10.065157 9.723514 1.3e-06\n",
      "10.121673 10.119277 1.4e-06\n",
      "9.958978 9.740404 1.4e-06\n",
      "10.137361 9.808088 1.4e-06\n",
      "10.312841 9.399168 1.4e-06\n",
      "10.198028 9.707181 1.4e-06\n",
      "10.793429 9.821314 1.4e-06\n",
      "10.211713 9.949501 1.4e-06\n",
      "10.01028 9.641429 1.4e-06\n",
      "10.348177 8.933499 1.4999999e-06\n",
      "9.492908 8.940402 1.4999999e-06\n",
      "8.991681 8.870584 1.4999999e-06\n",
      "9.1761875 8.681665 1.4999999e-06\n",
      "9.157123 8.972562 1.4999999e-06\n",
      "9.455534 8.967798 1.4999999e-06\n",
      "9.793673 9.040601 1.4999999e-06\n",
      "9.400513 8.998608 1.4999999e-06\n",
      "9.388642 8.596999 1.6e-06\n",
      "8.84486 8.797821 1.6e-06\n",
      "8.7863035 8.7945175 1.6e-06\n",
      "8.8533535 8.801115 1.6e-06\n",
      "8.974877 8.61249 1.6e-06\n",
      "8.66172 8.824817 1.6e-06\n",
      "9.049466 8.95065 1.6e-06\n",
      "8.967319 8.884051 1.6e-06\n",
      "8.884454 9.145523 1.7000001e-06\n",
      "9.016416 9.668 1.7000001e-06\n",
      "9.126747 9.314438 1.7000001e-06\n",
      "9.127903 9.376097 1.7000001e-06\n",
      "9.008383 9.525505 1.7000001e-06\n",
      "9.140805 9.372808 1.7000001e-06\n",
      "9.060856 9.516564 1.7000001e-06\n",
      "8.6204195 9.8495455 1.7000001e-06\n",
      "8.8590975 9.938227 1.7999998e-06\n",
      "9.42734 10.0684595 1.7999998e-06\n",
      "9.279285 9.987278 1.7999998e-06\n",
      "9.662096 9.95951 1.7999998e-06\n",
      "9.420345 9.848663 1.7999998e-06\n",
      "9.277114 9.675918 1.7999998e-06\n",
      "9.270818 10.351644 1.7999998e-06\n",
      "9.794673 9.74844 1.7999998e-06\n",
      "9.313825 10.994583 1.8999999e-06\n",
      "9.910209 10.487859 1.8999999e-06\n",
      "10.169161 10.964122 1.8999999e-06\n",
      "9.718468 11.08871 1.8999999e-06\n",
      "9.907848 10.682369 1.8999999e-06\n",
      "9.891278 11.022182 1.8999999e-06\n",
      "9.984705 10.474797 1.8999999e-06\n",
      "9.919472 10.580187 1.8999999e-06\n",
      "9.952635 10.9249735 2e-06\n",
      "9.61263 10.775956 2e-06\n",
      "10.002197 10.828525 2e-06\n",
      "9.921243 10.729276 2e-06\n",
      "10.130916 11.176442 2e-06\n",
      "10.06302 11.135358 2e-06\n",
      "10.232168 10.841404 2e-06\n",
      "10.32216 10.53405 2e-06\n",
      "9.968431 10.735295 2.0999998e-06\n",
      "9.791915 10.558759 2.0999998e-06\n",
      "9.930144 10.83102 2.0999998e-06\n",
      "9.792288 10.842215 2.0999998e-06\n",
      "9.59848 10.754656 2.0999998e-06\n",
      "9.990852 10.494634 2.0999998e-06\n",
      "10.000931 10.922677 2.0999998e-06\n",
      "10.507502 10.635028 2.0999998e-06\n",
      "9.66955 10.638652 2.2e-06\n",
      "9.7635975 10.351575 2.2e-06\n",
      "10.006648 10.790265 2.2e-06\n",
      "9.76239 10.9053955 2.2e-06\n",
      "9.711333 9.907007 2.2e-06\n",
      "9.804608 10.495705 2.2e-06\n",
      "9.870406 10.603538 2.2e-06\n",
      "10.366525 10.159398 2.2e-06\n",
      "9.679137 9.845235 2.3e-06\n",
      "9.195915 9.433499 2.3e-06\n",
      "9.3880415 9.92815 2.3e-06\n",
      "9.48725 9.866968 2.3e-06\n",
      "9.213863 9.641489 2.3e-06\n",
      "9.399098 9.839844 2.3e-06\n",
      "9.584056 10.352855 2.3e-06\n",
      "9.383319 9.991131 2.3e-06\n",
      "9.2324915 9.563251 2.3999999e-06\n",
      "8.985205 9.210625 2.3999999e-06\n",
      "8.885484 9.221793 2.3999999e-06\n",
      "8.601056 9.081559 2.3999999e-06\n",
      "8.698659 9.420775 2.3999999e-06\n",
      "8.610664 9.269933 2.3999999e-06\n",
      "8.713401 8.981598 2.3999999e-06\n",
      "9.012482 9.599937 2.3999999e-06\n",
      "8.395415 8.322351 2.5e-06\n",
      "8.149628 8.207113 2.5e-06\n",
      "7.914877 8.551147 2.5e-06\n",
      "8.047403 8.123572 2.5e-06\n",
      "8.006566 8.411055 2.5e-06\n",
      "7.8540087 8.590478 2.5e-06\n",
      "8.056712 8.240695 2.5e-06\n",
      "8.334475 8.440332 2.5e-06\n",
      "8.0217495 7.756826 2.6e-06\n",
      "7.6712794 7.635447 2.6e-06\n",
      "7.8562346 7.599276 2.6e-06\n",
      "7.867905 7.4782906 2.6e-06\n",
      "7.5385704 7.64053 2.6e-06\n",
      "7.7772584 7.658323 2.6e-06\n",
      "7.949399 7.553584 2.6e-06\n",
      "7.601897 7.697251 2.6e-06\n",
      "7.641321 7.5188565 2.7e-06\n",
      "7.8014436 7.229704 2.7e-06\n",
      "7.890073 7.6855893 2.7e-06\n",
      "8.014951 7.315551 2.7e-06\n",
      "7.637755 7.604249 2.7e-06\n",
      "8.000475 7.3907146 2.7e-06\n",
      "7.8152122 7.425249 2.7e-06\n",
      "7.9609714 7.7709084 2.7e-06\n",
      "7.866743 7.9018497 2.8e-06\n",
      "8.568387 7.737525 2.8e-06\n",
      "8.052592 7.823451 2.8e-06\n",
      "8.042182 7.6765027 2.8e-06\n",
      "8.294377 7.6711125 2.8e-06\n",
      "8.141558 7.681337 2.8e-06\n",
      "8.36614 7.7328978 2.8e-06\n",
      "8.115665 7.6971707 2.8e-06\n",
      "8.344125 7.923107 2.8999998e-06\n",
      "8.148212 7.6998534 2.8999998e-06\n",
      "8.476118 7.7154083 2.8999998e-06\n",
      "8.188368 8.028219 2.8999998e-06\n",
      "8.086107 7.9717793 2.8999998e-06\n",
      "8.272161 7.936034 2.8999998e-06\n",
      "8.271882 7.964899 2.8999998e-06\n",
      "8.12619 7.78717 2.8999998e-06\n",
      "8.091812 7.75159 2.9999999e-06\n",
      "8.087748 7.9347258 2.9999999e-06\n",
      "8.335539 7.7007456 2.9999999e-06\n",
      "8.212594 8.038438 2.9999999e-06\n",
      "8.248265 7.8748174 2.9999999e-06\n",
      "8.460669 7.9069853 2.9999999e-06\n",
      "8.209856 7.896998 2.9999999e-06\n",
      "8.222145 8.173814 2.9999999e-06\n",
      "8.192431 7.65353 3.1e-06\n",
      "8.102925 7.8822365 3.1e-06\n",
      "8.195534 7.5502415 3.1e-06\n",
      "7.950192 7.7467275 3.1e-06\n",
      "8.140241 7.6431317 3.1e-06\n",
      "7.7015643 7.655265 3.1e-06\n",
      "8.123457 7.644279 3.1e-06\n",
      "7.8254733 7.552245 3.1e-06\n",
      "8.031808 7.3034983 3.2e-06\n",
      "7.576947 7.0774198 3.2e-06\n",
      "7.375898 7.1666374 3.2e-06\n",
      "7.5381656 7.752311 3.2e-06\n",
      "7.517261 7.1726017 3.2e-06\n",
      "7.8204947 7.3039665 3.2e-06\n",
      "7.518042 7.123924 3.2e-06\n",
      "7.477979 7.217455 3.2e-06\n",
      "7.535837 6.9323864 3.3e-06\n",
      "7.2639475 6.9555593 3.3e-06\n",
      "7.2011623 7.0149884 3.3e-06\n",
      "7.0762596 7.1258173 3.3e-06\n",
      "7.0892377 7.1832323 3.3e-06\n",
      "7.2479076 7.0879855 3.3e-06\n",
      "7.106222 7.166666 3.3e-06\n",
      "7.154368 7.0660753 3.3e-06\n",
      "7.1232386 7.4755883 3.4000002e-06\n",
      "7.0970044 7.5870743 3.4000002e-06\n",
      "7.040376 7.431525 3.4000002e-06\n",
      "7.3310676 7.163916 3.4000002e-06\n",
      "7.1121135 7.346312 3.4000002e-06\n",
      "7.277083 7.439463 3.4000002e-06\n",
      "7.089381 7.469478 3.4000002e-06\n",
      "7.4115696 7.606621 3.4000002e-06\n",
      "7.0872803 7.6636558 3.4999998e-06\n",
      "7.5385847 7.374367 3.4999998e-06\n",
      "7.18158 7.5285697 3.4999998e-06\n",
      "7.216963 7.70241 3.4999998e-06\n",
      "7.594229 7.2655287 3.4999998e-06\n",
      "7.574143 8.038151 3.4999998e-06\n",
      "7.6663985 7.832786 3.4999998e-06\n",
      "7.549831 7.81374 3.4999998e-06\n",
      "7.644618 8.297583 3.5999997e-06\n",
      "7.333277 7.686503 3.5999997e-06\n",
      "7.544047 8.027001 3.5999997e-06\n",
      "7.7677474 8.077169 3.5999997e-06\n",
      "7.6536927 8.017268 3.5999997e-06\n",
      "7.468457 7.8048096 3.5999997e-06\n",
      "7.313343 8.024236 3.5999997e-06\n",
      "7.43435 8.171803 3.5999997e-06\n",
      "7.691052 7.3578415 3.7e-06\n",
      "7.5004873 7.6321254 3.7e-06\n",
      "7.332465 7.457465 3.7e-06\n",
      "7.5837617 7.661448 3.7e-06\n",
      "7.0293202 8.05901 3.7e-06\n",
      "7.267106 7.323005 3.7e-06\n",
      "7.192892 7.6548023 3.7e-06\n",
      "7.261859 7.7861185 3.7e-06\n",
      "7.6214986 7.3841724 3.7999998e-06\n",
      "7.2178807 7.3656735 3.7999998e-06\n",
      "7.0603466 7.4490247 3.7999998e-06\n",
      "7.31396 7.5747604 3.7999998e-06\n",
      "7.270303 7.117764 3.7999998e-06\n",
      "7.2037373 7.05381 3.7999998e-06\n",
      "7.235845 7.408264 3.7999998e-06\n",
      "6.9881954 7.158857 3.7999998e-06\n",
      "7.0451484 6.806447 3.9e-06\n",
      "6.894524 6.8214593 3.9e-06\n",
      "6.7843122 6.926108 3.9e-06\n",
      "7.4018116 6.814525 3.9e-06\n",
      "7.1297245 6.6843715 3.9e-06\n",
      "6.9995456 6.7597003 3.9e-06\n",
      "6.765058 6.76719 3.9e-06\n",
      "6.9379463 7.063053 3.9e-06\n",
      "6.9057307 6.649537 4e-06\n",
      "7.1149144 6.561184 4e-06\n",
      "7.0785484 6.5737987 4e-06\n",
      "7.0464096 6.7902145 4e-06\n",
      "7.0064445 6.630682 4e-06\n",
      "7.0423007 6.52526 4e-06\n",
      "6.9285526 6.544941 4e-06\n",
      "6.9041805 6.5643783 4e-06\n",
      "7.046833 6.77715 4.1e-06\n",
      "7.1848264 6.5288577 4.1e-06\n",
      "7.008244 6.5051537 4.1e-06\n",
      "7.093159 6.725973 4.1e-06\n",
      "6.9331512 6.63352 4.1e-06\n",
      "6.847961 6.4811153 4.1e-06\n",
      "7.0451217 6.541889 4.1e-06\n",
      "6.96085 6.3381357 4.1e-06\n",
      "6.9375815 6.5136533 4.1999997e-06\n",
      "6.7563496 6.350385 4.1999997e-06\n",
      "6.9014893 6.4995494 4.1999997e-06\n",
      "6.7588944 6.463476 4.1999997e-06\n",
      "6.597702 6.5287275 4.1999997e-06\n",
      "6.705455 6.415953 4.1999997e-06\n",
      "6.813591 6.6150208 4.1999997e-06\n",
      "7.072835 6.618702 4.1999997e-06\n",
      "7.087457 6.455463 4.3e-06\n",
      "6.892902 6.5859723 4.3e-06\n",
      "6.6817145 6.536731 4.3e-06\n",
      "6.674519 6.157363 4.3e-06\n",
      "6.932394 6.4001245 4.3e-06\n",
      "6.465801 6.5603986 4.3e-06\n",
      "6.8513 6.477242 4.3e-06\n",
      "6.677888 6.303483 4.3e-06\n",
      "6.474741 6.7801776 4.4e-06\n",
      "6.8190837 6.728445 4.4e-06\n",
      "6.601388 6.5705743 4.4e-06\n",
      "6.981591 6.6771655 4.4e-06\n",
      "6.524421 6.8477697 4.4e-06\n",
      "6.799038 6.6373525 4.4e-06\n",
      "6.739715 6.8695564 4.4e-06\n",
      "6.705204 6.8504043 4.4e-06\n",
      "6.7392073 7.090838 4.5e-06\n",
      "6.915726 7.366309 4.5e-06\n",
      "6.7248073 7.0045547 4.5e-06\n",
      "6.527662 6.9891124 4.5e-06\n",
      "6.8980227 6.8855486 4.5e-06\n",
      "6.6504955 6.8278613 4.5e-06\n",
      "6.6745586 6.865181 4.5e-06\n",
      "6.600562 7.0602274 4.5e-06\n",
      "7.013727 6.646868 4.6e-06\n",
      "6.723554 6.633646 4.6e-06\n",
      "6.4653883 6.7151093 4.6e-06\n",
      "6.476509 6.5685053 4.6e-06\n",
      "6.876927 6.903656 4.6e-06\n",
      "6.6349144 6.91834 4.6e-06\n",
      "6.9025054 6.84553 4.6e-06\n",
      "7.0231314 6.714633 4.6e-06\n",
      "6.5554256 6.346626 4.7e-06\n",
      "6.7905064 6.5232944 4.7e-06\n",
      "6.524246 6.714191 4.7e-06\n",
      "6.579743 6.551356 4.7e-06\n",
      "6.5584316 6.450012 4.7e-06\n",
      "6.702056 6.643571 4.7e-06\n",
      "6.5719094 6.580453 4.7e-06\n",
      "6.7067437 6.4167624 4.7e-06\n",
      "6.6529717 6.560612 4.7999997e-06\n",
      "6.7628984 6.2612815 4.7999997e-06\n",
      "6.79643 6.297729 4.7999997e-06\n",
      "6.6984334 6.218849 4.7999997e-06\n",
      "6.4271007 6.28265 4.7999997e-06\n",
      "6.7109256 6.578307 4.7999997e-06\n",
      "6.8019605 6.302756 4.7999997e-06\n",
      "6.875881 6.46425 4.7999997e-06\n",
      "6.622822 6.480724 4.8999996e-06\n",
      "6.888866 6.458777 4.8999996e-06\n",
      "6.8331347 6.327619 4.8999996e-06\n",
      "6.5082192 6.4819922 4.8999996e-06\n",
      "6.552169 6.345899 4.8999996e-06\n",
      "7.013219 6.087231 4.8999996e-06\n",
      "6.3728724 6.1778774 4.8999996e-06\n",
      "6.7642393 6.4612355 4.8999996e-06\n",
      "6.607859 6.1964326 5e-06\n",
      "6.6699405 6.1228065 5e-06\n",
      "6.5274906 6.262419 5e-06\n",
      "6.614684 6.150752 5e-06\n",
      "6.4952474 6.4431267 5e-06\n",
      "6.38554 6.226096 5e-06\n",
      "6.5015874 6.192636 5e-06\n",
      "6.6036234 6.5622864 5e-06\n",
      "6.446393 6.0643578 5.0999997e-06\n",
      "6.5915046 5.959118 5.0999997e-06\n",
      "6.431094 6.1057954 5.0999997e-06\n",
      "6.5868783 6.2085814 5.0999997e-06\n",
      "6.3583674 5.972542 5.0999997e-06\n",
      "6.6285186 6.096469 5.0999997e-06\n",
      "6.4260926 6.220173 5.0999997e-06\n",
      "6.3767653 6.0433125 5.0999997e-06\n",
      "6.37654 6.30219 5.2e-06\n",
      "6.503787 6.2919784 5.2e-06\n",
      "6.705934 6.586108 5.2e-06\n",
      "6.593653 6.5280232 5.2e-06\n",
      "6.5929837 6.5641465 5.2e-06\n",
      "6.491838 6.538074 5.2e-06\n",
      "6.35219 6.376761 5.2e-06\n",
      "6.471646 6.3326583 5.2e-06\n",
      "6.6035137 6.892333 5.3e-06\n",
      "6.652686 6.675757 5.3e-06\n",
      "6.8287673 6.778568 5.3e-06\n",
      "6.5879664 6.7242675 5.3e-06\n",
      "6.5743513 6.58416 5.3e-06\n",
      "6.4446926 6.9108353 5.3e-06\n",
      "6.414648 6.4268885 5.3e-06\n",
      "6.5601273 6.6919637 5.3e-06\n",
      "6.3289623 6.581765 5.4e-06\n",
      "6.6411967 6.560669 5.4e-06\n",
      "6.6374583 6.3664722 5.4e-06\n",
      "6.4302926 6.421692 5.4e-06\n",
      "6.740185 6.2936063 5.4e-06\n",
      "6.5561385 6.33861 5.4e-06\n",
      "6.4559355 6.485597 5.4e-06\n",
      "6.5020885 6.366383 5.4e-06\n",
      "6.691633 6.0368094 5.5e-06\n",
      "6.454765 6.051724 5.5e-06\n",
      "6.103209 6.168957 5.5e-06\n",
      "6.3205824 5.9926953 5.5e-06\n",
      "6.2150626 6.2591796 5.5e-06\n",
      "6.2031493 6.1781654 5.5e-06\n",
      "6.400668 6.20098 5.5e-06\n",
      "6.2892 6.0532594 5.5e-06\n",
      "6.443397 5.9650183 5.6e-06\n",
      "6.2178216 6.000084 5.6e-06\n",
      "6.4298663 6.029542 5.6e-06\n",
      "6.385895 5.7428303 5.6e-06\n",
      "6.393654 6.102414 5.6e-06\n",
      "6.381177 6.0298157 5.6e-06\n",
      "6.465002 6.0568733 5.6e-06\n",
      "6.503332 5.833078 5.6e-06\n",
      "6.3198824 6.116042 5.6999997e-06\n",
      "6.5441995 5.993137 5.6999997e-06\n",
      "6.571122 6.107177 5.6999997e-06\n",
      "6.3355303 6.1846666 5.6999997e-06\n",
      "6.6247473 6.0192513 5.6999997e-06\n",
      "6.642481 6.305587 5.6999997e-06\n",
      "6.4890575 6.2896123 5.6999997e-06\n",
      "6.6039505 5.938595 5.6999997e-06\n",
      "6.4773955 6.076551 5.7999996e-06\n",
      "6.285341 6.0518575 5.7999996e-06\n",
      "6.22922 6.0102825 5.7999996e-06\n",
      "6.2054944 5.9659867 5.7999996e-06\n",
      "6.545704 6.031933 5.7999996e-06\n",
      "6.3194447 5.91935 5.7999996e-06\n",
      "6.509596 5.940479 5.7999996e-06\n",
      "6.3934135 5.9684367 5.7999996e-06\n",
      "6.4359818 6.0855403 5.9e-06\n",
      "6.264883 5.9730277 5.9e-06\n",
      "6.1743345 5.796109 5.9e-06\n",
      "6.0729423 5.9845023 5.9e-06\n",
      "6.238062 5.9949207 5.9e-06\n",
      "6.2486625 5.938284 5.9e-06\n",
      "6.3005376 6.0460024 5.9e-06\n",
      "6.217546 5.8391995 5.9e-06\n",
      "6.179447 6.263402 5.9999998e-06\n",
      "6.2943835 6.2897687 5.9999998e-06\n",
      "6.525199 6.353756 5.9999998e-06\n",
      "6.521042 6.4693236 5.9999998e-06\n",
      "6.6889877 6.270027 5.9999998e-06\n",
      "6.3962197 6.4251866 5.9999998e-06\n",
      "6.4649124 6.6007004 5.9999998e-06\n",
      "6.2899113 6.5918603 5.9999998e-06\n",
      "6.344337 6.481521 6.1e-06\n",
      "6.3293643 7.283897 6.1e-06\n",
      "6.6718235 6.2963743 6.1e-06\n",
      "6.3573084 6.7179384 6.1e-06\n",
      "6.4942226 6.5832295 6.1e-06\n",
      "6.632038 6.3008347 6.1e-06\n",
      "6.3910193 6.5206704 6.1e-06\n",
      "6.693698 6.781631 6.1e-06\n",
      "6.420417 6.507263 6.2e-06\n",
      "6.421207 6.417499 6.2e-06\n",
      "6.4688096 6.3373866 6.2e-06\n",
      "6.2282457 6.57155 6.2e-06\n",
      "6.468938 6.446897 6.2e-06\n",
      "6.3031754 6.3369203 6.2e-06\n",
      "6.488833 6.351429 6.2e-06\n",
      "6.454357 6.747305 6.2e-06\n",
      "6.474743 5.8178816 6.2999998e-06\n",
      "6.324673 5.812409 6.2999998e-06\n",
      "6.2487717 5.8726554 6.2999998e-06\n",
      "6.1162047 5.8906784 6.2999998e-06\n",
      "5.929416 5.8086677 6.2999998e-06\n",
      "6.0541835 5.9182954 6.2999998e-06\n",
      "6.1216245 5.9598308 6.2999998e-06\n",
      "6.015986 5.7774043 6.2999998e-06\n",
      "6.13104 6.025712 6.4e-06\n",
      "6.1942363 5.877889 6.4e-06\n",
      "6.289829 5.824397 6.4e-06\n",
      "6.2435884 5.8936305 6.4e-06\n",
      "6.3826833 6.0354056 6.4e-06\n",
      "6.380435 5.8640018 6.4e-06\n",
      "6.0984707 5.8668456 6.4e-06\n",
      "6.4441004 5.9513264 6.4e-06\n",
      "6.410516 6.308156 6.4999995e-06\n",
      "6.44719 6.1298175 6.4999995e-06\n",
      "6.3126106 6.0506725 6.4999995e-06\n",
      "6.5465136 6.0622926 6.4999995e-06\n",
      "6.523536 6.3070726 6.4999995e-06\n",
      "6.634394 6.2557964 6.4999995e-06\n",
      "6.4345922 6.0858827 6.4999995e-06\n",
      "6.7179594 6.1320386 6.4999995e-06\n",
      "6.5471015 6.119365 6.6e-06\n",
      "6.2565947 6.043784 6.6e-06\n",
      "6.418999 5.925661 6.6e-06\n",
      "6.4999747 5.994789 6.6e-06\n",
      "6.482753 5.9708176 6.6e-06\n",
      "6.3187594 6.045076 6.6e-06\n",
      "6.3582993 6.1588664 6.6e-06\n",
      "6.6263328 6.0725093 6.6e-06\n",
      "6.20553 5.77469 6.7e-06\n",
      "6.082262 5.787431 6.7e-06\n",
      "6.2016172 5.702571 6.7e-06\n",
      "6.24008 5.691497 6.7e-06\n",
      "6.142696 5.6984644 6.7e-06\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43miter_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miter_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(iter_train, iter_test, steps_per_epoch, epochs)\u001b[0m\n\u001b[0;32m      3\u001b[0m batch_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iter_train)\n\u001b[0;32m      4\u001b[0m batch_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iter_test)\n\u001b[1;32m----> 6\u001b[0m loss_train \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      7\u001b[0m losses_train\u001b[38;5;241m.\u001b[39mappend(loss_train)\n\u001b[0;32m      9\u001b[0m loss_test \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(batch_test)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loop(iter_train, iter_test, steps_per_epoch, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eeef46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26b4a567cd0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAS9tJREFUeJzt3Qd4U1UDBuAvSTfQsvfeS/YGQQTZiKgoS1kKMmSIqCAg/qAMcSJLNsoQEBCQvffee++9WtrStEnu/5yTZnVAC21um/u9zxOS3NzcnEva5OuZOkVRFBARERG5id5dL0REREQkMHwQERGRWzF8EBERkVsxfBAREZFbMXwQERGRWzF8EBERkVsxfBAREZFbMXwQERGRW3khhbFYLLh58ybSpUsHnU6ndnGIiIgoAcScpU+ePEHOnDmh1+tTV/gQwSNPnjxqF4OIiIhewLVr15A7d+7UFT5EjYet8IGBgWoXh4iIiBIgJCREVh7YvsdTVfiwNbWI4MHwQURElLokpMsEO5wSERGRWzF8EBERkVsxfBAREZFbMXwQERGRWzF8EBERkVsxfBAREZFbMXwQERGRWzF8EBERkVsxfBAREZFbMXwQERGRWzF8EBERkVsxfBAREZFbaSp8/Hv4Bjadvqt2MYiIiDQtxa1qm1xuPn6KPvMPy9uXRzVVuzhERESapZmaj4dhkWoXgYiIiLQUPhRF7RIQERGRtsIHmD6IiIhSAu2ED2YPIiKiFEE74UPtAhAREZHGwgerPoiIiFIE7YQPtQtAREREGgsfTB9EREQpgmbCB+s+iIiIUgbNhA/WfBAREaUM2gkfaheAiIiItBU+iIiIKGXQTPhgswsREVHKoKHwwfRBRESUEmgnfKhdACIiItJY+GD6ICIiShG0Ez5Y90FERJQiaCZ8MHsQERGlDJoJH0aTxX47IsqsalmIiIi0TDPhIyQiyn471GhStSxERERappnwYTI72l0MOp2qZSEiItIyzYQPs9NwF72e4YOIiEgtmgkfFotT+GD2ICIiUo1mwofJKXzo2OxCRESkGs2ED7NT+CAiIiL1aDJ8cJ0XIiIi9WgmfFgYOIiIiFIEL2hEkL83CuluwAhvtYtCRESkaZoJH40K+aKV7wB5OwTt1S4OERGRZmmm2cU37IbaRSAiIiIthQ8iIiJKpeFj69ataN68OXLmzCnny1i6dKnL42IkydChQ5EjRw74+/ujfv36OHfuHFT39JH9pi78vqpFISIi0rJEh4+wsDCULVsW48ePj/PxMWPG4LfffsOkSZOwZ88epEmTBg0bNkRERATUpLM4VrVVnG4TERFRCu9w2rhxY3mJi6j1+OWXXzB48GC0aNFCbps9ezayZcsma0hat2798iUmIiKiVC1J+3xcunQJt2/flk0tNkFBQahatSp27doV53OMRiNCQkJcLsnCeUp1zvlBRETkGeFDBA9B1HQ4E/dtj8U0cuRIGVBslzx58iDZMXsQERFpd7TLwIEDERwcbL9cu3YtWV6Hi8kRERF5YPjInj27vL5z547LdnHf9lhMvr6+CAwMdLkkP1Z9EBEReUT4KFCggAwZGzZssG8TfTjEqJfq1atDVU41H1xYjoiIKBWNdgkNDcX58+ddOpkePnwYGTNmRN68edG3b1+MGDECRYoUkWFkyJAhck6Qt956C2piowsREVEqDR/79+9H3bp17fc/++wzed2hQwfMnDkTX3zxhZwLpGvXrnj8+DFq1aqF1atXw8/PD6p6+tjpDms+iIiI1KJTUlgbhGimEaNeROfTpOz/Yd47FYaV/eXt4O5HEJQtf5Idm4iISOtCEvH9rfpoF3fROTW8KJYUlbeIiIg0RTPhw2WSMSIiIlKNdsKHC9Z8EBERqUVD4YPTqxMREaUEGgofTtgEQ0REpBrthA8uLEdERJQiaCd8uEwzxvBBRESkFr0mKz4sFjWLQkREpGmaCR+uWPNBRESkFoYPIiIicivNhA+dznGqjB5ERETq0Uz4cMHRLkRERKrRTvjg3B5EREQpgnbChzNWfBAREalGQ+GDk4wRERGlBBptdmH4ICIiUotGZzglIiIitWgnfKTJbL9p9kuvalGIiIi0TDvhg2u7EBERpQgaCh9ERESUEmgnfBR41XGbFR9ERESq0U748PJ1usP0QUREpBbthA8iIiJKETQZPljvQUREpB5Nhg8dZzglIiJSjSbDBxEREamH4YOIiIjcSlPhw6JYJxpjqwsREZF6NBU+iIiISH0MH0RERORWmgofttYWhYNtiYiIVKOp8GHHTh9ERESq0Wb4ICIiItVoKnwosI52ISIiIvVoKnzYKGx2ISIiUo0mwwcRERGpR1Phg80uRERE6tNU+LDhUFsiIiL1aDJ8EBERkXoYPoiIiMittDnDKUe7EBERqUZT4cNGx/BBRESkGk2GDyIiIlKPxsIHh9oSERGpTWPhw4p9PoiIiNSjyfBBRERE6tFU+OAMp0REROrTVPhwYLMLERGRWjQaPoiIiEgtmgofrO8gIiJSn6bChw0HuxAREalHk+GD6YOIiEg9mgofHO1CRESkPk2FDyIiIlKfJsOHwq6nREREqtFU+PDXRcprrmpLRESkHk2FDxufOwfULgIREZFmaTJ86COC1S4CERGRZmkzfDx9qHYRiIiINEuT4SPo4Hi1i0BERKRZmgwfOkuU2kUgIiLSLE2GD85wSkRE5EHhw2w2Y8iQIShQoAD8/f1RqFAhDB8+HAq/8ImIiAiAV1IfcPTo0Zg4cSJmzZqFUqVKYf/+/ejUqROCgoLQu3dvpAwMQkRERB4TPnbu3IkWLVqgadOm8n7+/Pkxb9487N27FylFRPbK8Fe7EERERBqV5M0uNWrUwIYNG3D27Fl5/8iRI9i+fTsaN24c5/5GoxEhISEul+SmePkl+2sQERGRm2o+vvrqKxkgihcvDoPBIPuAfPfdd2jXrl2c+48cORLffvst3IvNLkRERB5T87FgwQLMmTMHc+fOxcGDB2Xfj7Fjx8rruAwcOBDBwcH2y7Vr15K6SEREROTJNR8DBgyQtR+tW7eW91955RVcuXJF1nB06NAh1v6+vr7y4lYceUNEROQ5NR/h4eHQ610PK5pfLBYLUg6GDyIiIo+p+WjevLns45E3b1451PbQoUP46aef0LlzZ6QUvnePqF0EIiIizUry8DFu3Dg5yViPHj1w9+5d5MyZE926dcPQoUORUhgin6hdBCIiIs3SKSls6lExUkZMSCY6nwYGBibtwYcFyavI9IXg0/dg0h6biIhIw0IS8f2tybVdogLzql0EIiIizdJk+GCHUyIiIvVoNHwQERGRWrQZPlJWNxciIiJN0Wb4ICIiItUwfBAREZFbMXwQERGRW2kyfOgjQ9UuAhERkWZpMnz43zmgdhGIiIg0S5Phg4iIiNTD8EFERERuxfBBREREbsXwQURERG7F8EFERERupcnwEanzUbsIREREmqWp8GFRdPJ6VZaP1C4KERGRZmkqfGywlJfXoboAtYtCRESkWZoKH4C15uPY9cdqF4SIiEizNBU+lOhrnf0WERERuZvGwoe15sP6LxEREalBo+GDNR9ERERq0Vj4sGL4ICIiUo/GwgcbXIiIiNSmqfCRW3dPXmfWBatdFCIiIs3SVPgoo78kr/t6LVa7KERERJqlqfBBRERE6mP4ICIiIrdi+CAiIiK3YvggIiIit2L4ICIiIrdi+CAiIiK3YvggIiIit2L4ICIiIrdi+CAiIiK3YvggIiIit2L4ICIiIrdi+CAiIiK3YvggIiIit2L4ICIiIrfSVPiYbmokr7eYy6hdFCIiIs3SVPgIh6+8Lqy/oXZRiIiINEtT4aOX17/yOpfugdpFISIi0ixNhQ8iIiJSH8MHERERuRXDBxEREbkVwwcRERG5FcMHERERuRXDBxEREbkVwwcRERG5FcMHERERuRXDBxEREbkVwwcRERG5FcMHERERuZWmwscFSw61i0BERKR5mgofKyzV1C4CERGR5mkqfBAREZH6NBU+fL00dbpEREQpkqa+jY0mi9pFICIi0jxNhQ8DGD6IiIjUpqnwoUCndhGIiIg0T1Ph46CliP22xWRStSxERERapanw8RS+9tuKKULVshAREWlVsoSPGzduoH379siUKRP8/f3xyiuvYP/+/VCbWXE63XPr1CwKERGRZnkl9QEfPXqEmjVrom7duli1ahWyZMmCc+fOIUOGDFCbxanPh6Kw8ykREZFHhI/Ro0cjT548mDFjhn1bgQIFkBLc1Gd33FEUNYtCRESkWUne7LJs2TJUqlQJrVq1QtasWVG+fHlMmTIl3v2NRiNCQkJcLsnFJyC9/bbCYbdERESeET4uXryIiRMnokiRIlizZg26d++O3r17Y9asWXHuP3LkSAQFBdkvotYkuZTK7Rw+OOyWiIhIDTpFSdr2Bx8fH1nzsXPnTvs2ET727duHXbt2xVnzIS42ouZDBJDg4GAEBgYmZdHw7+EbaLG0pLxtKvEWvN6POxARERFR4ojvb1GJkJDv7ySv+ciRIwdKlrR+wduUKFECV69ejXN/X19fWUjnS3LxNjhO1+vU0mR7HSIiIopfkocPMdLlzJkzLtvOnj2LfPnyQW2V8qs/4oaIiEjrkjx89OvXD7t378b333+P8+fPY+7cufjjjz/Qs2dPqC3Qz1vtIhAREWlekoePypUrY8mSJZg3bx5Kly6N4cOH45dffkG7du2S+qWIiIgoFUryeT6EZs2ayUtKo9dxhAsREZHaNLW2C7MHERGR+rQVPtQuABEREWksfLDqg4iISHWaCh96Zg8iIiLVaSp8sOaDiIhIfZoKH7GYTWqXgIiISHO0HT4UrmxLRETkbgwfRERE5FbaDh/X96ldAiIiIs3RdvjY8D+1S0BERKQ52g4f1/eqXQIiIiLN0Xb4ICIiIrdj+CAiIiK30lz4uGTJ5rohMlytohAREWmS5sLHCaWA64Y1A9UqChERkSZpLnyMMb3vuuHUcrWKQkREpEmaCx/XlSyuG8IfqFUUIiIiTdJc+LCAi8sRERGpSXPhAwwfREREqtJg+CAiIiI1MXwQERGRWzF8CJzrg4iIyG00Fz5Gvv1K7I3f51CjKERERJqkufDRpDSDBhERkZo0Fz6CArzxc9Q7sR94ckeN4hAREWmO5sKHMMPcKPbGH4uqURQiIiLN0WT4CEFA3A9c3g4oSvxPfHTl2Y8TERHRc2kyfMQ70djMpsC5dXE/tncK8GsZ4L/+yVoyIiIiT6fR8PEMc1vFvX39MOv1/mluLQ4REZGnYfiIy9PHgMWsdimIiIg8EsNHXEbnA6Y1iLGRa8IQERElBc2Gj5tKxmfvcGO/630dwwcREVFS0GT4WN6rFmoaf3v+jjt+BR5eir7D8EFERJQUNBk+XskdBCUhp75uKDCxhjuKREREpBmaDB+JEsVF54iIiJISw0dCsdWFiIgoSWg6fCww1UnE3kwfRERESUHT4WO+ua7aRSAiItIczYaPBd2qQw9Lwp/AobZERERJQrPho0qBjAhG2kQ8g+GDiIgoKWg2fAjnlNwYHdVa7WIQERFpiqbDhzDR/CZmmBo+f0c2uxARESUJTYePbrULyuvRpiSs/YgIAcIfJt3xiIiIPIymw0fX6PARAd8E7J3Amo9ReYAxBQBj6MsVjoiIyENpOnxkTONjv/2HqWnSNrs8sq0JQ0RERM40HT50Oh12D6wnb080NY9/x4tbEn9wRXmJkhEREXkuTYcPIXuQn7x+hMD4d5r9pvsKRERE5OE0Hz4SLOye4/bV3cCiLsCdk894Ams+iIiI4sLwAeDX1uUS94TpDYHji4CJ1YHdkwBTZHIVjYiIyOMwfABoUS6XvL6uZE78k1d/Cez6PfZ29vkgIiKKE8OHk06RX7zYE6/vT+qiEBEReSyGDycXlRwv9sQz/wGXt8fYyJoPIiKiuDB8ODHD8OJPntkUOLfeZdOBKw9x4Mqjly8YERGRB2H4iDbmnTIvf5A579hvRkSZ8c7EXXhn4k48jTS//LGJiIg8BMNHtPJ50yfp8YwPriIDQuTt8EhTkh770NVHuPH4aZIek4iIyF0YPqJli55sLKkELeuEQ36fJHnvjzO3n6DlhJ2oOWpjEh6ViIjIfRg+ogX6ecvrusYfk/S4l/3awnDzYOxhuBbLCx3v8DX2ISEiotSN4SOGS0oOrDJXTtJjZpjbCMHHVjk2zGkFTKgKmKMSfSxOH0JERKkdw4eTvBkD5PXQqE5Jfuygf1oD59YBqwcC59cB988C+6cDkeGJOo6F4YOIiFI5hg8niz6pLq/vIWk7n9rNeRfYPcFxf9UXiV60zsKqDyIiSuUYPpxkDXR0Oi0cMds9L3p9n+v9h5cAY2i8uzN6EBFRapfs4WPUqFHQ6XTo27cvUhMTvBCm+Lr3RfdOAX4rB4y0rjUTF4U1H0RElMola/jYt28fJk+ejDJlkmACLzepWyyL/XYp4wy3ve6dkAhg5eeODWfXAqsHWTulRkXYN1vY6YOIiFK5ZAsfoaGhaNeuHaZMmYIMGTIgtSiRI9Dtr/n7hF9Q9fsNrhvntgJ2jweGZwa+ywZc2Sk3M3oQEVFql2zho2fPnmjatCnq16+P1OTT14u43B8e1T7ZX7PX3W/kfCDPtHawvEruio//jt7C2TtPkvdFiIhI07yS46Dz58/HwYMHZbPL8xiNRnmxCQmxTkmuFn8fA7rUKoBp2y/J+9PMTXBdyYzJPr8gJRB9PvSwoLTukrVJxmCdHC0p7Dh/Hz3nWidEuzyqaZIdl4iIKFlrPq5du4Y+ffpgzpw58PN7/pTlI0eORFBQkP2SJ08eqC3mcNY1liqoEDEJqrpxAKbRBaGE3sdCn2+xzHcIsCJpO/EevxGcpMcjIiKKi05J4uETS5cuRcuWLWEwOJanN5vNcsSLXq+XtRzOj8VV8yECSHBwMAID3d//wvYl3Gzc9ljbn9s0ooYmY4GsJfE0ZzVZa/MyJm+5gJGrTsvbrPkgIqLEEN/fohIhId/fSV7zUa9ePRw7dgyHDx+2XypVqiQ7n4rbzsFD8PX1lYV0vqitdK4g7B1UD685jXwR1pkryOvJphT0xSxGyMxsghJDV2PL2XvWbXv+AA7MBEyRapeOiIgo+cNHunTpULp0aZdLmjRpkClTJnk7NU04Nql9RVQrmNG+rVvUZ6hl/AUjTe2Q0lTUncGof/cDofeAVQOA5X2AEVmAu9aajISIswrs6WNgfDVg86ikLC4REWkYZzh9Bj9vA4a3cAQmC/S4rmSVt98xfoOU5B/fbzE+/AsgMsZIlS0vGRr2TAbunQI2j3y54xARESXnaJeYNm/eDE+Ycr1pmRxyKKpwQCmGAhF/4ZJf8g/FTaiCylXgt/KuG1+2S48l8SvvEhERqR4+UrMgf2+s7Vcbvl565MuUBl1qPcLbE2wTfukx3dQInb1WI+VSXIPIk9tAYA41C0RERBrHZpcEKJotnQweQoW8GdCmimM48P9MH6Ke8Qf8ZaqHZsYRKBkxHcvM1tVxUwTnmo91Q4CfigP7pqpZIiIi0jiGjxcw8u0ysjbE5oKSC4NNXXBcKYhw+OGSkh0pxcV7T3Dk2mPrnZ3jrNdrrLOlJowuWcpFRETaxfDxErUhfesXwevFs2LrgLpoUS4npnxYST42ydQcC02OcKKmc3eeoMX4HTH6fnCFGCIiUg/7fLyEvvWL2m//2tra0fPU/xph7+WH6DDdDyeU/BjmPVtuF00xbxp2ub2MafAUTfS7gTG9HBuTdl45IiKiRGH4SGJiltE6RbNgVucq6DAduKxkR0vDdgyJ6oQvoz6GET646MYRMrUMJ+QFT502Wkxue30iIqKY2OySTEQA+a5laeiKvIHv/PojRNZB+Mm5Qpabq6lbOMVsnQGViIhIBQwfyahd1XyY0akK9gyqZ98m+oj8aGoF1YkZUONsfmGTDBERJS82u7iBWFRvdd9XseTQDfSoUxhXHhZBud/TIpfuAerpD2KKuQlO+XV2e7mifiwJ764bAS9f60VRMN9nBCIUH8BUH7h7yu1lIiIiz5fkq9q6c1U8T9B+6h5sP3/fvmLuPSUIw6M+QHuvdaiiP+PGkujwls8kLI3sZr2btzpwNUYH2WHBbiwPERGlJon5/mbNh8pmd66Cyw/C8PHPnyG/7jammJvJ7TsjS2Gxz1Dk1UevVJvsFIQ8eQL4Rt+NGTyIiIiSCMOHyvR6HQJ8vLDOYp0jZN7H1fAwLBLVC2VCoF9r9B8yED/6THJLWTb6fu6W1yEiIm1jh9MUINDfkQEr5ssgF7DLmMYHXgY9Rgz7Hvkj5uLTwmtwu9gHqpbTvGsSlPMbHRuu7QOOLXJrGR6HRyKFtRQSEVEisc9HCnHiZjD0Oh1K5HjGOUeG48iKCdh08AT6ei2GakTfD2MoMDKX9X6j0UBkKFCrH6A3PP/5Yfet12kyu24/PA/IVBjIUznOp+04fx/tpu7BuxVzY2yrsi99GkREpM73N2s+UohSOYOeHTwEnwCUfftz3M3XHGq6uH+tI3gIq78ENg4HNvzv+U82GYEfClkv5qjobZHAos7A0k+AafXjfeqvG87J60UHrr/8SRARkWoYPlKhz9s2w8B036OBcTRuKJnc/voFV8QzT8mOX3B92Yi45w8xm4DtPwPn1jm2RYZFP+9X4Pg/cCtRnv/6AyeXufd1iYiIHU5TI9EfZGT/npiz5wpqLcmFIIThsF/0EFmV5T74A06c2YZbtUdDOTwPYaXa4K1a5YADM4D1w1x31umBx9eATSNe6LWuPwqX/xeiw26i7ZsC7JtqvXAIMRGRW7HmI5XPoLrus9fwGOmQkpQK2436q+rgjVuTkGVND+vGuydj7yjCx7iKsTZfeRBdI/IM5++GotboTag5yqkDbDyOXQ/Gaz9swurjt60bIkKA1V8l5FSIiCgZMHykcoWzpsORbxqglvFXpEQ1DScQZjTBZLbEflCnA8zGWJvr/LAZF+6Fxt7d6fbmM3fl9aPw6H4jz/Dx7P24/CAcn/x1wLrh2p5EnQMRESUtNrt4gEA/L1xXsiCl0o3JDy/zk9gPfJ8z3ufsOncbhVb0QVT2suhysS6qlizg8viI/xI+9fvTKHPiCkxERMmKNR8esnZMv/pFsbRgjD4VKURAXMHjGXSwoNTq94Er2+G9Zzxm33sXa9f+F2u/lvptWObzNRD87NEvooLF2dOoOGphYjo0x3ohIhchEc+vbXwhYgi+JQG/m+QRGD48RJ/6RfDWh/2ArlvQ3PhiHThTirO+HVBef95l2xyf75HZbG1qsfnZZyLK6C/BtDK6/4YYZXN+A7DgQ+uQ3mgxsgcWHXQNK9cehrvuIPqE/NvDehG3iUj6ed1ZlBm2FsuP3EzaA1/ebh1+v0DdiRTJfRg+PE3Ocvj72+5Izbx1sZtJ0uoiMP7uh/J2Id0NDPb60/6Y15nlwMl/gR+LAX+9bb09v501OMxshnaKa62J6P/h7NUxm7Bw/zXHBlOE47Y5MsHlFvP1TdpyAdvPRU+iRuRhbHPtDPn3eNIeeOc46/XpFUl7XEqx2OfDA73Q0NNUwrb6byyitsPZ+XXA/LbA5W34HNswD1XxAEHyIUWJWRcCjNt4Hq0q5Xmpsm08fRejVp22lnNUU8cDokZmw7dAjnJAqbde6jWIiDwBaz481NvGYVhjroRaxl+gWZe32W8e8OuOd/RbgWFB6B3yg8tuXjDFfwwRHI7MB+5EDxUOvWedoCwOsZpvbM6utk6wtrADktKm03cxb+/VJD0mEZE7MHx4qEHdOmBKzuG4rmTF8Kh2uK1kwHUlxloqGmNbHTi95bHL9paG7fE/adtYYEk3YGJ1mG+fAMYWBqbWi3MWV9HxNxaxBk7onXgPP27DOczaeRlY0AGY8571uFERwKnlz+1v0mnmPgxcfAxn7ySuQy8RkdoYPjxUpfwZsah7DaTxMWCauSmqGX9HK+M3ahcrRepiWIVFYR2xcd5PsiZh8pYLjgf3WAOLMG3CSOuNW4eBMQWgHJ4rv/jNlnjWZnxwwboGzvI+8daU/LjuLEYuOwicXAqcWyNH7txZ2Bf4u7212SgB7obEniuFKDmlrOVIKTVi+PBwO756HT4G8TbrcAuZsM5cQe0ipTjF9deQVfcYr5/5FsuWzsfeHU7rzzjxtzx13Hn6CLql3dH/l5lYNb4vsGu8y5DejbNHQJlYM/ZBohzHCIu0Nt/oobgMY8x4ZkGsZiNh5/n7eG/SLpy/y5oOIkrdGD48XPoAH5TO5Vgt9+Oo/vbbEYq3SqVKueb5fIdpPj/G+dgHXutjbVvuOxjNHswE1gzCnStnUE9/AIEIxesXf4DO5BRWbL7Lbl3PJnpRvXQIRyvDFvvDV+LrNwKg7dQ92Hv5Ibr+GT1Ta1w1LWuHAKHRQ5I3fQ8cdIwKSpVkn5u/gXtn1S4JESUhzx0WQXZdahXEwbkHUbdYFmw6cw8fRH6FvLq7mGOuj2FeM9HRa63aRfQIA06/B/gAY6PiWfXX5pfS8ipT5f445ucadPznt4K33jHU+MnFfUh3aj7w2iD7tov3wvDT2jP2+4qt5mRKXSAiGLh5CMhcFNg/zbq9QgqbO0F02g2+BuRKQC3ciSXAkq7W21wAUDUHrjzC4WuufaWIXgbDhwY0LZMDpXO9hlzp/VH461XYZiljf2y46QOGjyT2uffCBO2XZV/sGpbCetfJm9LNru+Y/RHv2bf/tvE82ho2IBBhOHajGF4tksUaPITr+2I12dg9vgqcXw+UbQt4+7k+Fv7Qeh2QEclKdNoVPtoI5I69sKCL6/uTtyyUIO9M3Kl2EcjDMHxoRL5MaeT13kH1EB5pxtEbweg97xDMMKBgxF94XX8ImXQheKSkxR8+P6tdXIrJaVVgMclaf6+FaGLYK+9/vDYnQo6uR2Bck6QJj69i1TVvOQ/JmLONoIsKx60r5/CHT3t83qAYAnwM0FlMshOt8KDfDWQKSmsdYixqUGw1FKK/yr5pQLHGQKZCjuOL2WQXdwUK1QUqdkz4OV3e+vzwQRSDWKjyxM0QVMqXAXp9HCPMKFVg+NCYrIHWv3bzZQpAwcxpMHnrRTlV8nqL40ugTeTXsu8DpSD3z2KTTz+k14Uhg851xd8pPj8B0ZUWcfrlFcyJHIj7ShB0vtY+JemPTsViYzm8sfcjRBkCULXPX7DVg0z/bSgGtG1uHWIs9DoAHF8EbPvJugrx2q9dm0AOz7GO1hGX6PDxMCxSrjzcuHQO+N/cBSzuBjT7CSja0PG8fdOtNTDpsrmWV4SZW0eAXOJn0mlYxcXNQP7agJ5d1TxPwkNE2ym7ceR6MIY1L4mONV0XnKTUg7/FGiXmpCidKwj/e7OU7AvyQbV8qJLfWt0epsSojqcUoYD+TqzgkVB/+YzEat+vHH1LdJE44tcVNQwnUQf7sf3MDftjA8zTgD+dZmL9vSKweaQ1eNg4Dx92mo9ETDEvtJ+6B58tOIK+fx8CZjYFQq4Dcx3NRlLwVWBWs9iF/ecjYNobwOZRrttntwD2TbVO8vYSYz3/PXwD4ze5rh2UaGL+lkN/AWEPsGDfNfSccxBGk+eunuyDKFTSnYYBZpf32d0iTRYZPOJaoyk+apWVno3hQ+MypPHBjE5VMPyt0ljwSXX82aUKjqEgNqZ7E08VH/t+X0R9rGo5KXmVW9UycU84MBNY9aWjliLahlPWkTbnblmrYtaciDHB2vUYI3Xun429kumpZdbrXeNjh4z9060LkCVwDpQDVx7iw+l7cf6uI7T1mX8YP6w5g+M3nGpv4iImetvzR9yPrfwc+LenDGlf/HMU/x27JUNISmEyJ+3qsGO9J2GR7//whdd8JAvRSToBhq9wND8mJFP8sOY0ao3ehAehnAsnpWH4IBei4+L575ri9f5/wn/QRfv2beYyaGr8DqcseXHWksu+3fk2pV6ZdS+weu+eSVD+6QKcWGzftOH0XTy9chDn/D7Eap8vYz9n6uuxt8W3kmlUGHB4ruu2e6eAiMfAmZXWcPL08TO/hd6ZuAtbz97Dx7P3WzvbHlsEPaxfzA/CnrNooJjobdUAx9T6MUfhCLeP2jeFRDim3Re1ID3mHEC7qbvxNDIZa0RErdP+GdEdksVCiCasXvonKg7+B/suP0yi1wjGm4Zd8mY3L9dFGpNM6O0E7fbn7iuJOuz4TRdw4/FTTNl26QULRsmFfT4oFkM8nbhOKAXQOFJUhSuopDuDC0pOPEIg3jdswmjvKW4vJ6lPJ2oHnIw8Wgs46pi8Ld6FAJ2JlUzNUYAhjnlnjM+onVgzyHop1gRoM09uungvVC4SKIaFVs6fAenxBGHwx83HT2XfF6GNobMcZp7g6viwe0iskStPY+Ux6xfqjJ2X0OO16BE+zxvZ45MWd/zyY8R/p9Chej45U3GcRG3Rf58BB2ZY74vrblvlcgCNDo9EDu+C6LcoCzZ+/hpemliXKJV71nstakUypfVN/EFX9AN8A4E3vn25wmkUaz4oft5pgMBcsPhnxqgO9bGkRw05Y6roHLZfKS6Dh/C3+TUsN1eTt5sZR8gLUWJEHZwLmCKxYMLQxD9Z1IIoCkwrv8TsCcOx5NANtH08GZ8fexOH/brJWhhnYojySp+BOLJmNj4YvxaLD1ibS07eDMH7Py3HymXzY9SmxPHFJcJStCI6a9+DSlemAJNrA8Yn9gX/RC3Lk7A4JpsT6/dYzI4mh1H5rGsGTaiK2X9Ok53A351krW34df05NP1tG0KNTgsaXtjgCB6CrekruqaorP6iy4y7L+XpI3iqsWvOoOKI9Zi7J5ELND68aG0C3PGL431MZreDIzBg4REci+7zIvq/nL4dkmr7tLDmg+InRhX0OSqn/67j9Ffpun61sf7UXZTPmx6t/9gtw8inUb3lxUrBHFM9pNU9RQsD5weg5/P+rzfwX2+nmUwSRzmzCl57J2EYgBv6AHzstdLl8WJwVNeX0ltvl3w4XF4vWVoTV3LOQq9xS2VTkc9BM8JvTEGA/eBxfLgrji+cdb5fIH/EXFS9HL0O0NrBWGtYhZu6TCigv4V0ojtDw7OAl4+js+rofECmIkD3HcAfrrUTA+4NwnhENzeF3MSWDStwQimKObuvoFud6CHOtjldYnJKHPoXTR/n1gNbxwAtxgOZi3j0Qi6/R3c8HrbsBNpWzZvwJ5qcm+zcM9z3swWHsfPCAyw8cB2XRzXFrxPH4eatW6jesifeq5wHqQ3DBz2bIfaPSJFs6eRFaFAyG9aejLlqqw5fm7rIW0EIw2uGIzhuyY93I7/Bab9Obik2aYtufhvXoccxLPOKo/9JtJaGHcDkwtjoVPMecMcxuZl531ScuXoXxU+Mhb70u0D4g1jH+MFrkktn3Hw6IJ8h+vdCVFg8OG+dMyXyCSDW/BHzqoj+K7a+I7EoaG9YD/zUFot9gRmmhoiKGiwXHsSeyXFOBLfrwgMUCTMh8zPCR3ikCcdvhKBivgxxN6+GPQDmvGO9vbAT0H07oCRt59WkkpSZyD5LcEKIWqvVjpFj7nLOqdO0MODBUDmjcqftlRg+SHt+b1tBVv0VyJxGNkOn9fPChlN37OuP9InqiXcs27DMXAMReIF2VSKVGU6vQEnRL0XY/H2c+7Ty2vrsg6z6wto59s4x1+2iw24czvp+CB+do3alk9caYPsa4HQx4L5jan1nv02bhnk+juGnIntcuh+G2bsuo1vtQsge5IeOM/Zh76WHGNi4uLUW5ckda5Cx1WyOc5ryPjy6E2tivpgFcZ7X9gCF6sX5x0uCiaD1cynr7aEPAb3hhQ/1UjlFjOy6vB2o9w2QPg+w63fg4ibH40nWvvVs8b1KeiV1TnvP8EEvxcdLjzK507tsa1AqOw4Mri8XtRN/XUWaWqH70yj4+xiA0IMYPGUhdgVnRA39CQz3nqla2YncJr7p7uPhHDxcxBM8hJgTA565HYy3J+zAo/AoHLtyDws7lsLpS9eghz+MO8YDQZWApd2tOw+5bx02LUYS2Ty5ZQ0nopkoDv8cuI7w22fROvcDeJd51/olLKojRJOSzSc7gOzWtYxss5MOWHQEzUsEovGF7/G4QFPMeVIOPeN6gZVfOG5f2AgUecPlYcVdtSi2OW2OLQQ6rwUeuY6cMVkUeBmSPoBsPnNXzuTa47VCcl6meCX2P0K8nwYfRzOgShg+KFk49x4XASVLuuj7voUw4quvZGeph7evAFNnwqh4w1fn6MBHRC9vpc8gNA4fifK681h0/xtgLHDUD1hnrog3Ig8AS6MXHhSmNwRuxLFa8o9FY2066dsJy03V0X9hV+topn2i48xHQJd1sGz72XUUw6SaONjpEgL9feSsypO2XJCjgIqd+h2NvRYj/YnF+CFiLno6zWu47vAFDFl2BjN9rqO4baMIRgkhOgLrvWLVRvyx9SJCnoRiVMVgIG8NwMfeo0fKh1vWFaDLtrE2q3n7A36O1cDtDs6OVQXR9YeZmC6WYKrQMXGz74besw4xzm4dhRWTqKUSSuYIRN3iWeOtYCn6aDMeffcDgtrPhj5f1ecPzR6VB0iXE+h/Cmpi+CBViECSPXcBlI6YinD4yWXlh2TciEb3P4UBFlxVsmKfb48Xm3+CiFBCfxU7fHsjUnH9mH/DEEfIiCt4xCNAZ8T7XpvlxcW0N+IcPpl7enl0jvwcJ5X8WBYwAgW9M+Gp4vjjJOZw7DeWVkAtxQcnwvM7jcd8zp/3kWHWdYfWDbHef3sKUOY95MI9PEQ6PIUfSh0bBZxab328zd9AsUbypg4WbPD5DFgWXduzyVqDtKdwP1RtG308G5kAXMsyPaIfIFrlfNICBeoAvmkBH+taWglaYLHHbiBrCTkHjWzieXc6kDarfbfrYpj4M3T3Wg6Iv91mNHBd9mDvFODALKD9P44lDG4etF4/cV3AUg0cakuqCkUALGJAYrkPkLb/QWwf2QlbRnbBlgH10NzoWo1cOWICtptLoW9kD5SMmK5amYlSi1y6B3JafjVl1T3GCt/BWOQzDKUtp2UHX+U5I0TE9P/5dE4Tj/3dHutGt0EAIuRKzkJaS6h1ZI6Ybn9KPUfwEBZ/DNw7gx1+fbDNt6/c9IFXdPAQ5r0PXNqG0rqL+NV7vGN7dPAQqp7/GThinT/G5k5olHVa/bicW2etKfo+5/Nrap46DV++stPR/0c0z4nlBZxG08ihtBtHoLtpjkuTzHOJWXjvHMPu6f3R/a8DuH3nFrB5NFIK1nyQqn5sVRYL9l/DwCYlYvU+v4VMmGB6Ez28lqFnZG/cQ3oseWUibj4MR+TVR5hlegMdvNahesQ4+ddNBf05LohHlEJV0DvW02nnteG5+2eJUev5xtOVOOlnHUL9j7kWXg05DcyxdYqNw/gq8krUnubVxRHAZjXDiuf1gRdT6Du5ePoossXX71V0srU5+S9QuD6wvDeQtSRQvj2w/lsgd2VrB9/NTusWhT8EHlxw3L+0BebRBQFMRm7dPVQ7Pgy4sQRiycZlujI4qBRFxxl7cTmuJbiW9gCylQK8HCdW7dFy7LjrC69LWwFzAkKLm+iUFDZDSUhICIKCghAcHIzAwDja3EgTRC/9umOt1br+iJDVpse/bYi0vta8/Dg8EtcePsUruYPw976r+PIf6yiC+GbUzB8xB36IdBnqG6F4Y5SpDYZ5z3bLORGRRmQrjah0ueF9fvULH6JExHSc8usca/sic228a3jO6KqEcG6iUeH7m80ulCJlD3TE+kW96+PSyCb24CGIkTQieAjvV84Lf2/rnyM7zNFD85xsM4ve9jo51Pe2ksG+vbxxMmaare2+gllxz5A5IvJwd46/VPAQ4goeQpIEDyFE3X4frPmgFOvukwh46fXImOb5Q8L2XHyAXvMO4cGTp8iIJ+jotRq9vP5FlFc67GyxBZkyZkazcduRE/fRxLAHf5vr4kn0HJa22pIHeRsiOGM5ZD0yHoeK98erp7hmAxF5JrNfRhi+uqTa9zfDB3kM8aPc7+/DWHr4JqZ/WB6vB90CspexT6AkZncsOXSNHLoWFmlCmNGMtyvkQovL36HU3eXAx5uAXI5JlgZ/3RcjvGfYm20u+7WzP9Y7sieWWWrIGVzbGjbiS+9kWmqciCi5JHHTC8MH0XOIH3v7xD3iV0AM1RND5JxYTq2A/m9r4BBrd9hqSAZEdcVCs+t6HMd8uyCd7tlD4oiIUpRh6oUP9vkgTXKZMVDcjhE8BH3xpvjN9BY+iuwv75/IUA/3lEAUfLUtBjctgf9618IbJa3j5/8yi1mGrE5bEr7OwtCoDi93IkREqRCH2hLFR6fDTybHOqul+iyGYjahu9N6FVM+rITVx28ju09JmLfdx/+ulMKsyNdRR38E7TKeQYPQpfZ9d5pLoobhpLw91/Q6ppkb44KSE0+UAPzsM9HNJ0dEpB6GD6Jn2Pd1fVT+bj2+aFRM3tfFsVBWo9LZrTeKrkbXx08RsPsKutSqj8xpfbFy6jdocv0X7LUUQ9uor3HZYG3GeQpfXFByydtLLK9iTURlOdOrmG3xkl97d54iEZHbsc8HUTIym814d/A4nFLyyqG+XQ3L5VC51pFD8BDWn+9/utfAOxOtsxzO6lwFdeZGT7vsZLO5rDzGAvNreKikwxG/rnJ7Q+Mo3FXS45DfJ/Z9xcRseXV30cyw223nSUSp0DD2+SDySAaDATVfa4zyBXPK+3+Ym6NB5A/24CGUz+NYFThXen/rSqAl3sTWiuMwPm0v3Cr4LvZUn4gjxfrhkpIDwXCsG/F391ex8LNmLq85xtQavaJ6x9mvZFBUFxSJmI2tZsdiVuFO62wQEbkDm12IktnnDa1NNmIY8JJDN+RkaaFGk/1x576vvl56IGNp4P0/URtA7ebW7V9GPz5zxyUMW35S1oSk1z1Budwlkd5pJc1FWXqiafoc+O/YLdQz/oAMeIL9SnE5r0kR3XUcVwrICdc+jBqILFGP0M1rBeaY6+OBEojNvv2QUWddPn2mqQE6eq11y/8PEWkPaz6I3OTbFqUwoGExOUom5sibLxsVR7c6BZEno+tS3zF1rCnCA9Ax6gu8FTncvoR3m8iv8X1UG1wt/CHGt7POVSL6lIjgIRjhg8YNGuPMiMaoX8K6YuY9ZEDgWz/I2pQQpEH7yEFyNM/Fat/htpLxhc5RDEkeb3rzhZ5LRNrB8EHkJoF+3uhZtzDyZUqD7q8VktvEkF1B3B/Y2HVxvWcT1SWOKpNdllKySSedv4+jBkWEkip57fvULpIFvl4GTO1QGZdHNZVT1r9XyTEsWCx5Xtk4ETnrdcdHtWP3O7EJVfyip6x3dchifc5kU3R1DRFRPBg+iFTwRcNi2PnV6/joVbF65cv7vuUrqFc8Kz6onk/eX9uvNr5qXBxfR89HMvmDiva1cOKc6wTA68WzYu+g+vDzNiBz7Y9hTmvtp2ILFiJ0CH2jeuKDqEFyltenimPq+yFRYt1NyFqUUhHT0ClygOxfctZiHdUj7En3RoLPqVjETHSM/CLex8VkbzZzTPVQ2/gzNpnL2reNjWqV4NciIvdi+CBSgfjizyk6l76AYtnSyevaRbPYt7WtmhfTOlaWwUEQtSuf1Ckk+5eUyhmEhqWihwPH4f3o2o9BTUogq21BP//0eND1gH2fdeYK2PruYTzqdx3rLRXltmWWmihhnInb3U/LUTfHFUeQypo5M3xLNIaPjy8+iepn3Vi8Gap+MgmKj7X8ziGhmXGEy6J/g6M6oUWlgthsKSebcqyXOThuyQ+Toke1iHFyllkRUApHzMbXpi64qmTDF06B5Hdzy1jnKpZij2mKqckz/reJKDlwqC1RKnM3JEJ2XBVNJhkSsOheQkREme3BxUashfPON3/gNf0RBNT5FJ82sDa1rD95B6tP3MarRTLDbFHwdoXcGLbsBGbuvGx/btncQfi3Vy3cDzWi0oj1cpto6pHMJmBCNeDBOXlXBIt8mQJw5UEYJnv/jBy6B7I/y8VRzZH/q/9ildUAM8xwLauzIZVMmHngAa4p2exT4gtdIvtjg6UCOhlW4xvvP+3bnafOTwoDo7pgpPe0JDsekScOtU3y0S4jR47E4sWLcfr0afj7+6NGjRoYPXo0ihWz9vgnopcjaie61bH2GUkqMYOHEODjhW+7toZO1xqV8zs6oNYvmU1enA17s5RL+Pjp/XLyWky0tqBbdQT4OB1fTtTm+jdPlrS+uPIgHN2iPot+TGev5Tlz54lsOmr623a57VnBo2K+DOjybg280yQSK47eQqWlE5Fbdw+HlUL2Y84wN8abeY0of2sBfo56x+X5otNuO8MG5NPfxYuaZ67H8EH0HEkePrZs2YKePXuicuXKMJlMGDRoEBo0aICTJ08iTRrH/ARElPJVKZDwUS8iIJy8GYJ3K+Z26U8S5zECcwEPztvvunY/cdxZ/mktPAyLRPag6OYgJxkCvPEoPEre7v9GUfR6vbD9ddMH+KB9tXwYt/EcDoe49nXJmMYH5T+eDDz4HJ0C8qPKrSfAX7D3V6kfORaZEIz5PiNwRCkkm3LM0GOZzxCU1F+R+92p9ys2HTmH/12vgPr6g6hrOISWhh0JrhkxKt7yLL10ZoQpfvjdZ1ys/cQaQTstpdDZa7W8H6b4Io3OmKDXINJcn4/Vq1ejY8eOKFWqFMqWLYuZM2fi6tWrOHDA0X5MRJ5H9C1pVSlPrI6scXprAq5kfk0OEW5dOQ8GNLQOCfbSW58b6Gf9u8jHS28PHpXzO/qECAOblEAaHwM61siPT+sVifN1KznV2DiHDzlEOUsxpE/ji5qFMwPNfwNKtcQ/5tqIghduIxPqRf0I/bvT4B+QBiZ4oUXkcCw118DRyqOR7dWOaN3rOzkl/jJLDbk+j7O3jcPwj/lVl21LzDVlp1hRM7LYUhuGCm3l/CsrLNVRMmI6/hf1AdpGDrLv/6TOt9A51RA1ihyFohGz8DJaGYdihqmhfL2YZpue3xnYNqKJKMVPMibafoSMGeP+C8poNMqLc5sREXm4oNzI23Mpvn8QjnwZA6DX63D824bw9zZg4+m7KJvHtbZCmNCuIv7cfQW/bThnnw326LCGMEQHlrjE9UiDGE1GUsUO8jK+5G2M33QeP79fDgWzWFc6bl42p+x7IkLJ0So/okWTZw+JXtevNo7fLIsahbrj4vVj8D8yCzmaDcbN/aG4uuZMnM8RIWa6ubFscrIE5oI+6ikqv9YCYcf+Ax5b97lryIFIkwVlIqbAGyb4IRJLfYcgi871M7Nj5ADU0h/HR16rYr3OPqU49pmsQc+ZqImZZW6AD73WxXtexyz58W7kNzjv96EMRf0jP8FX3nOx3FzDXjvzMqaaGscqsxgpVVR/46WPTbHdVwKRGR462sVisaBv376oWbMmSpeOPS+ArY+I6KBiu+TJk/DlyIko9RI1FQUyp5HBQxAjc0SQeKNkNmRNF7uZJUs6X3z2RlHH80X3kWcED8ToWSIWCfy1dTn0qV8k3v0blMouO8ragofN9I6V5NDlIc1KuNSwfPtmqVjHKJItHVqWz41sgX4oWLIycrT5HUiXXc7xIiaZE7Km85WjkWKa37U69H2OAv3PyL4x1doPhVnnhY1pmsg1gGxNQ3/1aYYbcIx2cjb6q8/jDF3PIkKFmJSuZdDf+F+uyZhkao6RUW2wL28X+z6dIwfI/jbmz87izvur8I+ltpwX5n+mD/FpZC+X4zU1fpfIEgAjTB/E2rbSUjXe/f8zV8F5i2M4+POMiXofE+OZg6ZrZPSILPH/q7zYKLThUdZFI1OLMab3VX39ZA0fou/H8ePHMX/+/Hj3GThwoKwdsV2uXbuWnEUiIg/hZUjcx5cILy3K5ZITrSXW68WzybAQs2mnQ4382DOoHj7o1NO6IU3cgcCma+2C+L1teazobQ04Z0Y0wr89a8p5WmZ2qoxqBTNZO+R6WUcx+WXOD8Pg23h9wDyUzhWEjf3rYMWntWSwEc5YHH+smSp0QXDHLfKxehVj1878WW6uvdYnu21IdbRH6a0h6tVSBTD049bI3HIUGnT9HpXbDIl1HK/ArMhWooZL3dJySw2MiXoPEYo30G0bar1az96Mc9hSEKYPV9if3yvy01jHFM1vJXPEHh2xylwl3v/L60oWvB35bZyPifWMXjP+aL8vmpommFtgtKlNrH3FY9cU66y/QjnjFJe1j+ILMksLOwLWN1EdMM0cPZorBdlhLuXSlKeJZpdevXphxYoV2Lp1K3Lnzh3vfr6+vvJCRJQQnWrmx8V7YaiUz7UPSFyqFciI/47eStbyyCAQWBfougXIaJ3+Pj7eBj2alXH8tS6CUNk86eUlXgZv+01bjYyYIaF0rkBMMH2JmoU2QlflI3hlfwW2xqr8TQcApsvAicX259asWQcfZEkLi0WBRcywMDz6gXQ5sbRbTey++AANSlrngxGdhqWnj5/ZhOVsgvktTDK/iYs5yqDK4zvosbUddltK4PevP4M+TQYcb3sA+688xq/1KgKnKyNy7bdYcj8PlOq9MLFuHVnzhSllYHxyH+UfjEAQwnALmeJ9vW2WMrIWyOaiJTvy6+7gD3MzzDY3dNn3zXp18O0a620RLGobjmG7uRTaR31t3+frqM64oWSCBXp0iRqACt53MctnNPwi7sVxri1w/tVMQHSf6VnRr/dISYsMulBZc/SJ1/J4yz4yqg0Ges/Di1hrrogGhth9KMWcN1l0wbJjsm2V615Rn+IRAtHYOBILfP6HdLqn9v2/6iNGlnlQ+BC/FJ9++imWLFmCzZs3o0CBZ/8yEhElxjfNYzd1xKdt1XxyyLDzUOFkk9M6vNgdRA3Msp7WCdN0+haxd/AJAFrNAKLCgbOr8Th/E3twEc1cehEluqwDNn0HNBolh0Q7hyI7veMromzeTHjvNeu6QfH56+Pq1qfpdHI9oZWWajJ4CKWLFkZpW6tZyRbwKdkCsSr+u26Br2LBUehlzZb4PjGfXYCIY8uwyacO/th1GzeVzCiguyX7rwiio24rw2a5NtEDBKFI1rTAXesCif9WnIGmac8hU+1uOF9bj/P3QrH+YFYcO7kUk++XwfC3SmPI0uN4p0JuzDlY316MQtkz4Ot368B3/yHg8BzcUdKjkXEUFvgMxxBTJ2RK4wMvL0cotGlgHI36ARfwbpfuMF0pC6/NI+QEen3LG1D5xHAE6cLlfucKdwauxA4fh/WlUM5ywmVbn8geaG3YLEdehSgBmGOuhwYGx2R6NkZ4y9ogoXzEJATAKIOHcErJh3LGP9DdsEyOoDqh5MeZrAlvskoVk4z16NEDc+fOxb///usyt4fozyHm/XgeTjJGRJRETEbg2l4gT1V7U06ibRgOmCOBBraqEivnCeByBvlh84C6cnSSIDrGvj1xh2xKGfOuY8r7lyFqbA5ffyxrSFYdu413KuaSQ7u7/mmtBfi8gRhuXQRGkxnLj9ySk+DZmqfiIsooyismyhN9h2zn07J8LtnhWDI+gXHfbPx+qzjGHYhwGTF18Ot6OD22Ho6GpMMXpm5yxuG2VfKiUWnHbMJ3g8PlyCp7Hybxfui9oOj02D37a1S/NN6lTErjMdCtcl1SQISe00peOWR976WH1m36vcipe4ChMSbLSwz7pH9JKDHf30kePuIbZjdjxgw5BPd5GD6IiFI+25e1GBZ9cMgbie6Dk9TlmPphpViT373IcVzCR4zw89Xio1iw/7rsaCz6+4ivz2+Xn5QjtJb3qoWggNi1Ic8SZjSh95Q1GPZ4EHK9/jH0ooktOnysqzEHSzbvkbVHInBtGfAa5u29irFrz8rHDwyuj0xjs8YKH183KYHvVp5ymW1YdFY+diMYLSfsTDHhI1maXYiISBt8vQ2qBQ/hy0bFcfxGMOoWd3wRJwfRXDXq7TLo8ZpYmTrA/se2mN33m+YlEza/TQxpfL0wrZcIAdFBYPck+2Ov12+K3tu8AIsZr+QKQqa0vrJmR1ziI2pHPq5dEB+9WkAOSxc1RKPfKRPr/RGjtzx+ng8iIvI849qUx/crT2Fie+tCg2rp/lrSLjXwvACSP3PsmbpfJHjEqVwbYOc4oMgbsilIzPA7Z88VdE/gcgq2keeiPB9Wzy8v8Y3eUhvDBxERJZqYfE1cPIXodPrPwetyOLRq/IKAvsesM/ACKJw17bM7WNcfBqwfZr8rOvrGJ64lCtTE8EFERJo3tlUZjHirNPydF0FUgz4RTVi1+gHZy6DptNPyrpwnJh45gvzlXDKB/onrl5JckrzD6ctih1MiIqKEu/ogHFvP3cN7lfLYRxypQdUOp0REROQ+eTMFoH2mfEhN1ItIREREpEkMH0RERORWDB9ERETkVgwfRERE5FYMH0RERORWDB9ERETkVgwfRERE5FYMH0RERORWDB9ERETkVgwfRERE5FYMH0RERORWDB9ERETkVgwfRERE5FYpblVbRVHsS/MSERFR6mD73rZ9j6eq8PHkyRN5nSdPHrWLQkRERC/wPR4UFPTMfXRKQiKKG1ksFty8eRPp0qWDTqdL8lQmQs21a9cQGBgIrdDieWvxnAWeN89bC7R43iGp4JxFnBDBI2fOnNDr9amr5kMUOHfu3Mn6GuKNS6lvXnLS4nlr8ZwFnre28Ly1IzCFn/Pzajxs2OGUiIiI3Irhg4iIiNxKU+HD19cX33zzjbzWEi2etxbPWeB587y1QIvn7eth55ziOpwSERGRZ9NUzQcRERGpj+GDiIiI3Irhg4iIiNyK4YOIiIjcSjPhY/z48cifPz/8/PxQtWpV7N27FynV1q1b0bx5czlLnJjldenSpS6Piz7CQ4cORY4cOeDv74/69evj3LlzLvs8fPgQ7dq1k5PRpE+fHl26dEFoaKjLPkePHsWrr74q/0/EzHljxoyJVZaFCxeiePHicp9XXnkFK1euTKazBkaOHInKlSvL2W2zZs2Kt956C2fOnHHZJyIiAj179kSmTJmQNm1avPPOO7hz547LPlevXkXTpk0REBAgjzNgwACYTCaXfTZv3owKFSrInuOFCxfGzJkzVfmZmThxIsqUKWOfOKh69epYtWqVx55vfEaNGiV/1vv27evR5z5s2DB5ns4X8fvlyedsc+PGDbRv316em/jcEp8n+/fv9+jPNfH/G/P9FpeePXt6/Pv9XIoGzJ8/X/Hx8VGmT5+unDhxQvn444+V9OnTK3fu3FFSopUrVypff/21snjxYjESSVmyZInL46NGjVKCgoKUpUuXKkeOHFHefPNNpUCBAsrTp0/t+zRq1EgpW7assnv3bmXbtm1K4cKFlTZt2tgfDw4OVrJly6a0a9dOOX78uDJv3jzF399fmTx5sn2fHTt2KAaDQRkzZoxy8uRJZfDgwYq3t7dy7NixZDnvhg0bKjNmzJDlOXz4sNKkSRMlb968SmhoqH2fTz75RMmTJ4+yYcMGZf/+/Uq1atWUGjVq2B83mUxK6dKllfr16yuHDh2S/5eZM2dWBg4caN/n4sWLSkBAgPLZZ5/J8xo3bpw8z9WrV7v9Z2bZsmXKf//9p5w9e1Y5c+aMMmjQIPl/LP4PPPF847J3714lf/78SpkyZZQ+ffrYt3viuX/zzTdKqVKllFu3btkv9+7d8+hzFh4+fKjky5dP6dixo7Jnzx5ZxjVr1ijnz5/36M+1u3fvurzX69atk5/pmzZt8uj3OyE0ET6qVKmi9OzZ037fbDYrOXPmVEaOHKmkdDHDh8ViUbJnz6788MMP9m2PHz9WfH195S+aIH4AxfP27dtn32fVqlWKTqdTbty4Ie9PmDBByZAhg2I0Gu37fPnll0qxYsXs99977z2ladOmLuWpWrWq0q1bN8UdxC+uOI8tW7bYz1N8SCxcuNC+z6lTp+Q+u3btkvfFL6der1du375t32fixIlKYGCg/Vy/+OIL+QXg7P3335fhJyX8zIj3ZerUqZo43ydPnihFihSRH8p16tSxhw9PPXcRPsSXZ1w89Zxtny21atWK93GtfK6Jn+9ChQrJ8/Xk9zshPL7ZJTIyEgcOHJBVeM7rx4j7u3btQmpz6dIl3L592+V8xFz6ohrNdj7iWlRJVqpUyb6P2F+c9549e+z71K5dGz4+PvZ9GjZsKJs5Hj16ZN/H+XVs+7jr/y04OFheZ8yYUV6L9zEqKsqlTKLqNG/evC7nLqpRs2XL5lJmsSjTiRMnEnReav3MmM1mzJ8/H2FhYbL5xdPPVxBVzqJKOWb5PPncRVOCaFItWLCgbEIQ1eqefs7Lli2Tn0etWrWSTQfly5fHlClTNPW5Jv7f//rrL3Tu3Fk2vXjy+50QHh8+7t+/Lz/Und88QdwXP+ypja3MzzofcS1+wZ15eXnJL3HnfeI6hvNrxLePO/7fxOrGov2/Zs2aKF26tL084kNFfADFV6aXOS/xC/306VO3/8wcO3ZMtveK9tpPPvkES5YsQcmSJT32fG1E0Dp48KDs6xOTp567+DIV7fGrV6+W/X3El67onyBWAvXUcxYuXrwoz7dIkSJYs2YNunfvjt69e2PWrFma+VwTffceP36Mjh072svhqe93QqS4VW2JbH8RHz9+HNu3b4enK1asGA4fPixrehYtWoQOHTpgy5Yt8GRiWfA+ffpg3bp1sgOcVjRu3Nh+W3Q0FmEkX758WLBggexk6anEHxOixuL777+X90XNh/j9njRpkvx514Jp06bJ91/UepEGaj4yZ84Mg8EQqwexuJ89e3akNrYyP+t8xPXdu3ddHhe9o0VPced94jqG82vEt09y/7/16tULK1aswKZNm5A7d277dvG6ogpR/PUQX5le5rxED3rxBeDunxnx14/ooV6xYkVZC1C2bFn8+uuvHnu+gqgGFj+jooe++OtVXETg+u233+Rt8VeZp567M/FXb9GiRXH+/HmPfr/FCBZRm+esRIkS9iYnT/9cu3LlCtavX4+PPvrIvi27B7/fCeHx4UN8sIsP9Q0bNrikcHFftKunNgUKFJA/MM7nI6rXRJun7XzEtfiBFh/wNhs3bpTnLf7Ssu0jhvSKNkcb8Veo+Cs8Q4YM9n2cX8e2T3L9v4n+tSJ4iGYHUV5xrs7E++jt7e1SJtGWKz7AnM9dNGM4f0iJMotfRNuH3/POS+2fGfFaRqPRo8+3Xr16styixsd2EX8Ziz4Qttueeu7OxDDRCxcuyC9nT36/RfNpzGHzZ8+elbU+nv65JsyYMUM2GYn+TTYVPfj9ThBFA8QwI9FreubMmbLHdNeuXeUwI+cexCmJGAEghlWJi3iLfvrpJ3n7ypUr9iFpovz//vuvcvToUaVFixZxDkkrX768HNa2fft2OaLAeUia6GkthqR98MEHckia+D8Sw7ViDknz8vJSxo4dK3thi576yTnUtnv37nKo3ebNm12Gp4WHh9v3EUPTxPDbjRs3yqFp1atXl5eYQ9MaNGggh+uK4WZZsmSJc2jagAED5HmNHz8+zqFp7viZ+eqrr+RonkuXLsn3UtwXvffXrl3rkef7LM6jXTz13Pv37y9/vsX7LX6/xBBKMXRSjOzy1HO2DacWnyXfffedcu7cOWXOnDmyjH/99Zd9H0/9XBMjS8R7KkbdxPSJh77fCaGJ8CGIsc/iTRZjncWwIzFOPKUSY8BF6Ih56dChg3xcDNMaMmSI/CUTP1D16tWTc0Q4e/DggfylTJs2rRyW1alTJxlqnImx9GL4mzhGrly55C9/TAsWLFCKFi0q/9/EcC4xJ0VyieucxUXM/WEjPoh69Oghh9OJX7iWLVvKgOLs8uXLSuPGjeX4fvHBLj7wo6KiYv0flytXTp5XwYIFXV7DnT8znTt3lvMfiNcQHyrivbQFD08838SED088dzEEMkeOHPJ1xO+cuO8814UnnrPN8uXL5Rep+LwpXry48scff7g87qmfa2I+E/E5FvNcPP39fh6d+Ee9ehciIiLSGo/v80FEREQpC8MHERERuRXDBxEREbkVwwcRERG5FcMHERERuRXDBxEREbkVwwcRERG5FcMHERERuRXDBxEREbkVwwcRERG5FcMHERERuRXDBxEREcGd/g9QPakFFrpGuQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses_test[100:], label=\"Test Loss\")\n",
    "plt.plot(losses_train[100:], label=\"Train Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e216ce01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02015d1bcb6548d09e61b0f0af43ad6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[16070]], shape=(1, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\n",
    "text = text.lower()\n",
    "SOS = tf.convert_to_tensor([[tokenizer.token_to_idx[\"<s>\"]]])\n",
    "indices = tf.cast(tokenizer.encode(text), tf.int32)\n",
    "indices = tf.concat([SOS, indices], axis=1)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a017b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374758e0faf349d3bf9351e5544a1a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', disabled=True, layout=Layout(height='20em', width='80ch'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x0000026B0C44E050>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2761, in while_loop\n",
      "    while cond(*loop_vars):  File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2753, in <lambda>\n",
      "    body = lambda i, lv: (i + 1, orig_body(*lv))  File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py\", line 655, in compute\n",
      "    return (next_i, flat_a_out, tas)  File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py\", line 650, in <listcomp>\n",
      "    tas = [ta.write(i, value) for (ta, value) in zip(tas, flat_a_out)]  File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 243, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x0000026B4CC4A140>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2761, in while_loop\n",
      "    while cond(*loop_vars):  File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2753, in <lambda>\n",
      "    body = lambda i, lv: (i + 1, orig_body(*lv))  File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py\", line 655, in compute\n",
      "    return (next_i, flat_a_out, tas)  File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py\", line 650, in <listcomp>\n",
      "    tas = [ta.write(i, value) for (ta, value) in zip(tas, flat_a_out)]  File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 243, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x0000026B4A5EFC40>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2761, in while_loop\n",
      "    while cond(*loop_vars):  File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2753, in <lambda>\n",
      "    body = lambda i, lv: (i + 1, orig_body(*lv))  File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py\", line 655, in compute\n",
      "    return (next_i, flat_a_out, tas)  File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py\", line 650, in <listcomp>\n",
      "    tas = [ta.write(i, value) for (ta, value) in zip(tas, flat_a_out)]  File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 243, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "T = 1\n",
    "tf.random.set_seed(42)\n",
    "wrapper = textwrap.TextWrapper(width=80)\n",
    "\n",
    "# create a read-only text area\n",
    "ta = widgets.Textarea(\n",
    "    value=\"\",\n",
    "    layout=widgets.Layout(width='80ch', height='20em'),\n",
    "    disabled=True\n",
    ")\n",
    "display(ta)\n",
    "\n",
    "for i in range(1024):\n",
    "    logits = model.call(indices)[0, -1:]\n",
    "    idx = tf.cast(\n",
    "        tf.random.categorical(logits / T, num_samples=1),\n",
    "        tf.int32\n",
    "    ) \n",
    "    indices = tf.concat([indices, idx], axis=1)\n",
    "\n",
    "    text_pred = (\n",
    "        tokenizer\n",
    "        .decode(indices)\n",
    "        .numpy()[0]\n",
    "        .decode('utf-8')\n",
    "        .replace(\"\\n\", \" \")\n",
    "    )\n",
    "    ta.value = wrapper.fill(text_pred)  # this updates in-place\n",
    "\n",
    "    if idx[0, 0] == tokenizer.token_to_idx[\"</s>\"]:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a5f20b",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
