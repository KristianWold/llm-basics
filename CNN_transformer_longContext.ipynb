{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04010a08",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fa3d166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from src.tokenizer import TokenizerBPE, fuse_tokenized_corpus, chunk_corpus\n",
    "\n",
    "import os\n",
    "import time\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from tqdm.notebook import tqdm\n",
    "from src.transformer import *\n",
    "from src.data_handling import read_first_n, sample_batch\n",
    "\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2b59898",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "576256a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_tokenized_corpus(corpus, tokenizer):\n",
    "    SOS = tf.convert_to_tensor([[tokenizer.token_to_idx[\"<s>\"]]])\n",
    "    EOS = tf.convert_to_tensor([[tokenizer.token_to_idx[\"</s>\"]]])\n",
    "\n",
    "    corpus_list = [SOS]\n",
    "    for line in tqdm(corpus):\n",
    "        corpus_list.append(line)\n",
    "        corpus_list.append(EOS)\n",
    "        corpus_list.append(SOS)\n",
    "\n",
    "    corpus = tf.concat(corpus_list[:-1], axis=1)\n",
    "    return corpus\n",
    "\n",
    "\n",
    "def chunk_and_batch(corpus, chunk_size, batch_size, shuffle=True, repeat=False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(corpus)\n",
    "    ds = ds.batch(chunk_size, drop_remainder=True)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=100*chunk_size, reshuffle_each_iteration=True)\n",
    "        \n",
    "    ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    if repeat:\n",
    "        ds = ds.repeat()\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7afd4e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 512\n",
    "\n",
    "tokenizer = pkl.load(open(\"tokenizers/tokenizer_CNN16000_lowercase.pkl\", 'rb'))\n",
    "tokenizer.add_special_tokens([\"<s>\", \"</s>\"])\n",
    "tokenizer.create_hash()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8751dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.seed(43)\n",
    "#corpus = pkl.load(open('corpus/CNN_tokenized16000_lowercase.pkl', 'rb'))\n",
    "#random.shuffle(corpus)\n",
    "#length = len(corpus)\n",
    "#train_corpus = corpus[:int(length*0.8)]\n",
    "#train_corpus = fuse_tokenized_corpus(train_corpus, tokenizer)\n",
    "\n",
    "#test_corpus = corpus[int(length*0.8):]\n",
    "#test_corpus = fuse_tokenized_corpus(test_corpus, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f472fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pkl.dump(train_corpus, open('corpus/CNN_train_fused.pkl', 'wb'))\n",
    "#pkl.dump(test_corpus, open('corpus/CNN_test_fused.pkl', 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e38fb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = pkl.load(open('corpus/CNN_train_fused.pkl', 'rb'))\n",
    "test_corpus = pkl.load(open('corpus/CNN_test_fused.pkl', 'rb'))\n",
    "\n",
    "ds_train = chunk_and_batch(train_corpus[0], chunk_size=max_seq_len, batch_size=16, shuffle=True, repeat=True)\n",
    "ds_test = chunk_and_batch(test_corpus[0], chunk_size=max_seq_len, batch_size=8, shuffle=True, repeat=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f830d881",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d47b8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr = 1e-4\n",
    "decay_steps = 20000\n",
    "decay_rate = 0.5\n",
    "decay_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=initial_lr,\n",
    "    decay_steps=decay_steps,\n",
    "    decay_rate=decay_rate,\n",
    "    staircase=False)\n",
    "\n",
    "warmup_steps = 1000\n",
    "lr_schedule = WarmUpThenDecay(\n",
    "    initial_learning_rate=initial_lr,\n",
    "    warmup_steps=warmup_steps,\n",
    "    decay_schedule_fn=decay_schedule)\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "embed_dim = 768\n",
    "tf_blocks = 12\n",
    "heads = 12\n",
    "ff_dim = 4*embed_dim\n",
    "weight_decay = 0.01\n",
    "dropout = 0.1\n",
    "\n",
    "unembed_dims = []\n",
    "\n",
    "model = Transformer(vocab_size=tokenizer.vocab_size,\n",
    "                    max_seq_len=max_seq_len,\n",
    "                    embed_dim=embed_dim,\n",
    "                    tf_blocks=tf_blocks,\n",
    "                    heads=heads,\n",
    "                    ff_dim = ff_dim,\n",
    "                    unembed_dims=unembed_dims,\n",
    "                    tokenizer=tokenizer,\n",
    "                    lr=lr_schedule,\n",
    "                    wd = weight_decay,\n",
    "                    dropout=dropout,\n",
    "                    )\n",
    "\n",
    "losses_train = []\n",
    "losses_test = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7970a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"model_16k_tokens_longContext\"\n",
    "\n",
    "\n",
    "ckpt = tf.train.Checkpoint(\n",
    "    optimizer=model.opt,\n",
    "    model=model\n",
    ")\n",
    "ckpt_manager = tf.train.CheckpointManager(\n",
    "    ckpt, \n",
    "    directory=\"checkpoints/\" + name,      # folder where ckpts are saved\n",
    "    max_to_keep=5                         # only keep 5 latest checkpoints\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88b34765",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "losses_train, losses_test = pkl.load(open(\"checkpoints/losses_\" + name + \".pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6527620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 70487872\n"
     ]
    }
   ],
   "source": [
    "total_params = 0\n",
    "for var in model.parameter_list:\n",
    "    shape = var.get_shape()\n",
    "    num_params = 1\n",
    "    for dim in shape:\n",
    "        num_params *= dim\n",
    "    total_params += num_params\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93977cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68717d7f9d604ff0b9c4328ba4c67b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'Softmax_8' defined at (most recent call last):\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\krist\\AppData\\Local\\Temp\\ipykernel_29908\\1332175022.py\", line 3, in <module>\n      loss_train = model.train_step(batch_train).numpy()\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 915, in __call__\n      result = self._call(*args, **kwds)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 980, in _call\n      return self._stateless_fn(*args, **kwds)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2495, in __call__\n      filtered_flat_args) = self._maybe_define_function(args, kwargs)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2760, in _maybe_define_function\n      graph_function = self._create_graph_function(args, kwargs)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2670, in _create_graph_function\n      func_graph_module.func_graph_from_py_func(\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1247, in func_graph_from_py_func\n      func_outputs = python_func(*func_args, **func_kwargs)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 677, in wrapped_fn\n      out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3317, in bound_method_wrapper\n      return wrapped_fn(*args, **kwargs)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1222, in autograph_handler\n      return autograph.converted_call(\n    File \"c:\\Users\\krist\\Documents\\llm-basics\\src\\transformer.py\", line 316, in train_step\n      loss = self.evaluate(tokens, training=True)\n    File \"c:\\Users\\krist\\Documents\\llm-basics\\src\\transformer.py\", line 336, in evaluate\n      logits = self.call(tokens[:, :-1], training)\n    File \"c:\\Users\\krist\\Documents\\llm-basics\\src\\transformer.py\", line 280, in call\n      for block in self.tf_blocks:\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 463, in for_stmt\n      _py_for_stmt(iter_, extra_test, body, None, None)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 512, in _py_for_stmt\n      body(target)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 478, in protected_body\n      original_body(protected_iter)\n    File \"c:\\Users\\krist\\Documents\\llm-basics\\src\\transformer.py\", line 281, in call\n      x = block.call(x, tokens, training)\n    File \"c:\\Users\\krist\\Documents\\llm-basics\\src\\transformer.py\", line 145, in call\n      x_embeds = self.attention(x_embeds, tokens, training)\n    File \"c:\\Users\\krist\\Documents\\llm-basics\\src\\transformer.py\", line 176, in attention\n      WA = tf.nn.softmax(inner_masked / dk, axis=-1)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 1176, in op_dispatch_handler\n      return dispatch_target(*args, **kwargs)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 3898, in softmax_v2\n      return _wrap_2d_function(logits, gen_nn_ops.softmax, axis, name)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 3816, in _wrap_2d_function\n      return compute_op(inputs, name=name)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 11127, in softmax\n      _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 797, in _apply_op_helper\n      op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 735, in _create_op_internal\n      return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3800, in _create_op_internal\n      ret = Operation(\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2108, in __init__\n      c_op = _create_c_op(g, node_def, inputs, control_input_ops, op_def=op_def)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1974, in _create_c_op\n      tf_stack.extract_stack_for_op(c_op, stacklevel=3)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\util\\tf_stack.py\", line 180, in extract_stack_for_op\n      _tf_stack.extract_stack_for_op(\nNode: 'Softmax_8'\nOOM when allocating tensor with shape[16,10,511,511] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node Softmax_8}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_step_30444]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (batch_train, batch_test) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(ds_train, ds_test))):\n\u001b[1;32m----> 3\u001b[0m     loss_train \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      4\u001b[0m     losses_train\u001b[38;5;241m.\u001b[39mappend(loss_train)\n\u001b[0;32m      6\u001b[0m     loss_test \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(batch_test)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'Softmax_8' defined at (most recent call last):\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\krist\\AppData\\Local\\Temp\\ipykernel_29908\\1332175022.py\", line 3, in <module>\n      loss_train = model.train_step(batch_train).numpy()\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 915, in __call__\n      result = self._call(*args, **kwds)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 980, in _call\n      return self._stateless_fn(*args, **kwds)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2495, in __call__\n      filtered_flat_args) = self._maybe_define_function(args, kwargs)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2760, in _maybe_define_function\n      graph_function = self._create_graph_function(args, kwargs)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2670, in _create_graph_function\n      func_graph_module.func_graph_from_py_func(\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1247, in func_graph_from_py_func\n      func_outputs = python_func(*func_args, **func_kwargs)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 677, in wrapped_fn\n      out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3317, in bound_method_wrapper\n      return wrapped_fn(*args, **kwargs)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1222, in autograph_handler\n      return autograph.converted_call(\n    File \"c:\\Users\\krist\\Documents\\llm-basics\\src\\transformer.py\", line 316, in train_step\n      loss = self.evaluate(tokens, training=True)\n    File \"c:\\Users\\krist\\Documents\\llm-basics\\src\\transformer.py\", line 336, in evaluate\n      logits = self.call(tokens[:, :-1], training)\n    File \"c:\\Users\\krist\\Documents\\llm-basics\\src\\transformer.py\", line 280, in call\n      for block in self.tf_blocks:\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 463, in for_stmt\n      _py_for_stmt(iter_, extra_test, body, None, None)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 512, in _py_for_stmt\n      body(target)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 478, in protected_body\n      original_body(protected_iter)\n    File \"c:\\Users\\krist\\Documents\\llm-basics\\src\\transformer.py\", line 281, in call\n      x = block.call(x, tokens, training)\n    File \"c:\\Users\\krist\\Documents\\llm-basics\\src\\transformer.py\", line 145, in call\n      x_embeds = self.attention(x_embeds, tokens, training)\n    File \"c:\\Users\\krist\\Documents\\llm-basics\\src\\transformer.py\", line 176, in attention\n      WA = tf.nn.softmax(inner_masked / dk, axis=-1)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 1176, in op_dispatch_handler\n      return dispatch_target(*args, **kwargs)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 3898, in softmax_v2\n      return _wrap_2d_function(logits, gen_nn_ops.softmax, axis, name)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 3816, in _wrap_2d_function\n      return compute_op(inputs, name=name)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 11127, in softmax\n      _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 797, in _apply_op_helper\n      op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 735, in _create_op_internal\n      return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3800, in _create_op_internal\n      ret = Operation(\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2108, in __init__\n      c_op = _create_c_op(g, node_def, inputs, control_input_ops, op_def=op_def)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1974, in _create_c_op\n      tf_stack.extract_stack_for_op(c_op, stacklevel=3)\n    File \"c:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\util\\tf_stack.py\", line 180, in extract_stack_for_op\n      _tf_stack.extract_stack_for_op(\nNode: 'Softmax_8'\nOOM when allocating tensor with shape[16,10,511,511] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node Softmax_8}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_step_30444]"
     ]
    }
   ],
   "source": [
    "for i, (batch_train, batch_test) in tqdm(enumerate(zip(ds_train, ds_test))):\n",
    "\n",
    "    loss_train = model.train_step(batch_train).numpy()\n",
    "    losses_train.append(loss_train)\n",
    "    \n",
    "    loss_test = model.evaluate(batch_test).numpy()\n",
    "    losses_test.append(loss_test)\n",
    "\n",
    "    if (i+1) % 1000 == 0:\n",
    "        ckpt_manager.save()\n",
    "        pkl.dump([losses_train, losses_test], open(\"checkpoints/losses_\" + name + \".pkl\", 'wb'))\n",
    "\n",
    "\n",
    "    lr = model.opt.inner_optimizer._decayed_lr(tf.float32).numpy()\n",
    "    \n",
    "    print(f\"Step {i+1}, Train Loss: {loss_train:.4f}, Test Loss: {loss_test:.4f}, Learning Rate: {lr:.2e}\")\n",
    "    \"\"\"\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # prepare x-axis for the last 400 steps\n",
    "    start = max(0, len(losses_train) - 1000)\n",
    "    x_zoom = np.arange(start, len(losses_train))\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(10, 8), sharex=False)\n",
    "\n",
    "    # Top subplot: zoom on last 400 steps\n",
    "    ax1 = axes[0]\n",
    "    ax1.plot(x_zoom, losses_test[-1000:], label=\"Test Loss\")\n",
    "    ax1.plot(x_zoom, losses_train[-1000:], label=\"Train Loss\")\n",
    "\n",
    "    _min = min(losses_train[-1000:] + losses_test[-1000:])\n",
    "    _max = max(losses_train[-1000:] + losses_test[-1000:])\n",
    "    delta = _max - _min\n",
    "    #ax1.set_ylim(_min - 0.1 * delta, _max + 0.1 * delta)\n",
    "\n",
    "    ax1.set_title(\"Training Loss (Last 1000 Steps)\")\n",
    "    ax1.set_xlabel(\"Step\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Bottom subplot: full series\n",
    "    ax2 = axes[1]\n",
    "    ax2.plot(losses_test[10:], label=\"Test Loss\")\n",
    "    ax2.plot(losses_train[10:], label=\"Train Loss, lr = {:.2e}\".format(lr))\n",
    "\n",
    "    ax2.set_title(\"Training Loss (Full Series)\")\n",
    "    ax2.set_xlabel(\"Step\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeef46d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(losses_test[\u001b[38;5;241m100\u001b[39m:], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(losses_train[\u001b[38;5;241m100\u001b[39m:], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss, lr = \u001b[39m\u001b[38;5;132;01m{:.2e}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mlr\u001b[49m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lr' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses_test[100:], label=\"Test Loss\")\n",
    "plt.plot(losses_train[100:], label=\"Train Loss, lr = {:.2e}\".format(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e216ce01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[16070     9   253    10     1    14    14     1 10094]], shape=(1, 9), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "text = \"(cnn) -- trump\"\n",
    "text = text.lower()\n",
    "SOS = tf.convert_to_tensor([[tokenizer.token_to_idx[\"<s>\"]]])\n",
    "indices = tf.cast(tokenizer.encode(text), tf.int32)\n",
    "indices = tf.concat([SOS, indices], axis=1)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74a017b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af20f44cf56d4238bae278d91ff04386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', disabled=True, layout=Layout(height='20em', width='80ch'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m display(ta)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m512\u001b[39m):\n\u001b[1;32m---> 18\u001b[0m     logits \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcall(\u001b[43mindices\u001b[49m)[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m     19\u001b[0m     idx \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(\n\u001b[0;32m     20\u001b[0m         tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mcategorical(logits \u001b[38;5;241m/\u001b[39m T, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     21\u001b[0m         tf\u001b[38;5;241m.\u001b[39mint32\n\u001b[0;32m     22\u001b[0m     )\n\u001b[0;32m     23\u001b[0m     indices \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat([indices, idx], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'indices' is not defined"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "T = 0.5\n",
    "tf.random.set_seed(42)\n",
    "wrapper = textwrap.TextWrapper(width=80)\n",
    "\n",
    "# create a read-only text area\n",
    "ta = widgets.Textarea(\n",
    "    value=\"\",\n",
    "    layout=widgets.Layout(width='80ch', height='20em'),\n",
    "    disabled=True\n",
    ")\n",
    "display(ta)\n",
    "\n",
    "for i in range(512):\n",
    "    logits = model.call(indices)[0, -1:]\n",
    "    idx = tf.cast(\n",
    "        tf.random.categorical(logits / T, num_samples=1),\n",
    "        tf.int32\n",
    "    )\n",
    "    indices = tf.concat([indices, idx], axis=1)\n",
    "\n",
    "    text_pred = (\n",
    "        tokenizer\n",
    "        .decode(indices)\n",
    "        .numpy()[0]\n",
    "        .decode('utf-8')\n",
    "        .replace(\"\\n\", \" \")\n",
    "    )\n",
    "    ta.value = wrapper.fill(text_pred)  # this updates in-place\n",
    "\n",
    "    if idx[0, 0] == tokenizer.token_to_idx[\"</s>\"]:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680d4eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[553]], shape=(1, 1), dtype=int32)\n",
      "obama are a of the the the of the a of the of the the of with the u by international the first\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5588\\3758968849.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m43\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtext_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krist\\Documents\\llm-basics\\src\\transformer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x, training, logits)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_blocks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munembed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krist\\Documents\\llm-basics\\src\\transformer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x_embeds, training)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_embeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mx_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_embeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mx_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mffnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_embeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx_embeds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krist\\Documents\\llm-basics\\src\\transformer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x_embeds, training)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_up\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_embeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_down\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdol3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mln2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx_embeds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 ):\n\u001b[1;32m-> 1097\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\layers\\normalization\\layer_normalization.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    283\u001b[0m                 \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"float32\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m             ):\n\u001b[0;32m    285\u001b[0m                 \u001b[1;31m# If mixed precision is used, cast inputs to float32 so that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m                 \u001b[1;31m# this is at least as numerically stable as the fused version.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"float32\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[1;31m# Calculate the moments on the last axis (layer activations).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, dtype, name)\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[1;31m# allows some conversions that cast() can't do, e.g. casting numbers to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m       \u001b[1;31m# strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1002\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1004\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Casting complex to real discards imaginary part.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, DstT, Truncate, name)\u001b[0m\n\u001b[0;32m   1997\u001b[0m         _ctx, \"Cast\", name, x, \"DstT\", DstT, \"Truncate\", Truncate)\n\u001b[0;32m   1998\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1999\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2000\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2001\u001b[1;33m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2002\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2003\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2004\u001b[0m       return cast_eager_fallback(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text = \"obama\"\n",
    "text = text.lower()\n",
    "\n",
    "indices = tf.cast(tokenizer.tokenize(text), tf.int32)\n",
    "print(indices)\n",
    "\n",
    "T = 0.5\n",
    "tf.random.set_seed(43)\n",
    "for i in range(128):\n",
    "    logits = model.call(indices)[0,-1:]\n",
    "    idx = tf.cast(tf.random.categorical(logits/T, num_samples=1), tf.int32)\n",
    "    indices = tf.concat([indices, idx], axis=1)\n",
    "    text_pred = tokenizer.detokenize(indices)\n",
    "    text_pred = text_pred.numpy()[0].decode('utf-8').replace(\"\\n\", \" \")\n",
    "    print(text_pred, end='\\r', flush=True)\n",
    "    #time.sleep(0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77fb01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def cosine_similarity(embed_a, embed_b):\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between two vectors.\n",
    "    \"\"\"\n",
    "    embed_b_T = tf.transpose(embed_b)\n",
    "    dot_product = embed_a@embed_b_T\n",
    "    \n",
    "    norm_a = tf.linalg.norm(embed_a, axis=1, keepdims=True)\n",
    "    norm_b = tf.linalg.norm(embed_b_T, axis=0, keepdims=True)\n",
    "\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "\n",
    "def cluster(X, n_clusters, normalize=True):\n",
    "    if normalize:\n",
    "        X = X/np.linalg.norm(X, axis=1, keepdims=True)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "    inertia = kmeans.inertia_\n",
    "    labels = kmeans.labels_\n",
    "    clusters = kmeans.cluster_centers_\n",
    "\n",
    "    return inertia, labels, clusters\n",
    "\n",
    "\n",
    "class EmbeddingClustering:\n",
    "    def __init__(self, tokenizer, n_clusters=10):\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.n_clusters = n_clusters\n",
    "\n",
    "    def fit(self, word_embed, normalize=True):\n",
    "        inertia, labels, clusters = cluster(word_embed, self.n_clusters, normalize)\n",
    "        self.word_embed = word_embed\n",
    "        self.inertia = inertia\n",
    "        self.labels = labels\n",
    "        self.clusters = tf.convert_to_tensor(clusters, dtype=tf.float32)\n",
    "\n",
    "        cos_sim = cosine_similarity(self.clusters, word_embed, normalize)\n",
    "        self.idx_list =  tf.argsort(cos_sim, axis=-1, direction='DESCENDING', stable=False, name=None)\n",
    "\n",
    "    def print_clusters(self, n_words=10):\n",
    "        for idx in self.idx_list:\n",
    "            for i in idx[:n_words]:\n",
    "                word = self.tokenizer.detokenize(tf.expand_dims(tf.cast(i, tf.int32), axis=0))\n",
    "                word = word.numpy().decode('utf-8')\n",
    "                print(word)\n",
    "            print(\"\\n\")\n",
    "\n",
    "\n",
    "def cosine_similarity(embed_a, embed_b, normalize=True):\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between two vectors.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        embed_a = tf.nn.l2_normalize(embed_a, axis=1)\n",
    "        embed_b = tf.nn.l2_normalize(embed_b, axis=1)\n",
    "    dot_product = embed_a@tf.transpose(embed_b)\n",
    "\n",
    "\n",
    "    return dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48583bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debbie\n",
      "denise\n",
      "katherine\n",
      "stephanie\n",
      "randy\n",
      "jason\n",
      "patricia\n",
      "kathy\n",
      "jesse\n",
      "sergio\n",
      "\n",
      "\n",
      "deficits\n",
      "revenues\n",
      "reductions\n",
      "subsidies\n",
      "incentives\n",
      "loans\n",
      "exports\n",
      "budgets\n",
      "salaries\n",
      "bonuses\n",
      "\n",
      "\n",
      "attem\n",
      "theless\n",
      "occas\n",
      "ieval\n",
      "theastern\n",
      "enthusia\n",
      "negot\n",
      "lesterol\n",
      "subsequ\n",
      "fahren\n",
      "\n",
      "\n",
      "occas\n",
      "afgh\n",
      "negot\n",
      "includ\n",
      "delaw\n",
      "glary\n",
      "ifics\n",
      "theast\n",
      "salad\n",
      "patro\n",
      "\n",
      "\n",
      "theastern\n",
      "experi\n",
      "delaw\n",
      "theast\n",
      "lesterol\n",
      "dort\n",
      "semif\n",
      "attem\n",
      "surpris\n",
      "compon\n",
      "\n",
      "\n",
      "ffed\n",
      "strugg\n",
      "portra\n",
      "athle\n",
      "massachu\n",
      "ifics\n",
      "pered\n",
      "experi\n",
      "arct\n",
      "thered\n",
      "\n",
      "\n",
      "subsequ\n",
      "theast\n",
      "prede\n",
      "occas\n",
      "theastern\n",
      "ieval\n",
      "lesterol\n",
      "experi\n",
      "arct\n",
      "ailand\n",
      "\n",
      "\n",
      "pretty\n",
      "fairly\n",
      "reasonably\n",
      "utterly\n",
      "remarkably\n",
      "substantially\n",
      "fundamentally\n",
      "relatively\n",
      "totally\n",
      "unusually\n",
      "\n",
      "\n",
      "deal\n",
      "challenge\n",
      "talk\n",
      "question\n",
      "move\n",
      "answer\n",
      "appeal\n",
      "attempt\n",
      "approach\n",
      "decision\n",
      "\n",
      "\n",
      "sending\n",
      "helping\n",
      "letting\n",
      "handing\n",
      "putting\n",
      "taking\n",
      "giving\n",
      "bringing\n",
      "pulling\n",
      "throwing\n",
      "\n",
      "\n",
      "tens\n",
      "hundreds\n",
      "thousands\n",
      "dozens\n",
      "millions\n",
      "billions\n",
      "plenty\n",
      "sort\n",
      "there\n",
      "none\n",
      "\n",
      "\n",
      "uguay\n",
      "theid\n",
      "lesterol\n",
      "negot\n",
      "theastern\n",
      "delaw\n",
      "ailand\n",
      "occas\n",
      "guate\n",
      "arct\n",
      "\n",
      "\n",
      "convince\n",
      "impose\n",
      "abide\n",
      "eliminate\n",
      "undermine\n",
      "prohibit\n",
      "tolerate\n",
      "educate\n",
      "satisfy\n",
      "violate\n",
      "\n",
      "\n",
      "two\n",
      "three\n",
      "four\n",
      "the\n",
      "six\n",
      "a\n",
      "several\n",
      "some\n",
      "no\n",
      "more\n",
      "\n",
      "\n",
      "christop\n",
      "djok\n",
      "berdy\n",
      "tember\n",
      "benjam\n",
      "whate\n",
      "aragu\n",
      "petrole\n",
      "dono\n",
      "bundes\n",
      "\n",
      "\n",
      "gives\n",
      "helps\n",
      "provides\n",
      "encourages\n",
      "relies\n",
      "deserves\n",
      "refuses\n",
      "enjoys\n",
      "seeks\n",
      "tends\n",
      "\n",
      "\n",
      "renewable\n",
      "greenhouse\n",
      "geological\n",
      "tropical\n",
      "mountainous\n",
      "carbon\n",
      "saharan\n",
      "rugged\n",
      "atomic\n",
      "fukushima\n",
      "\n",
      "\n",
      "encouraged\n",
      "instructed\n",
      "persuaded\n",
      "refused\n",
      "urged\n",
      "subjected\n",
      "managed\n",
      "referred\n",
      "helped\n",
      "unable\n",
      "\n",
      "\n",
      "glary\n",
      "gbag\n",
      "strugg\n",
      "espion\n",
      "risings\n",
      "beliefs\n",
      "guate\n",
      "transparen\n",
      "athle\n",
      "usalem\n",
      "\n",
      "\n",
      "behavioral\n",
      "psychiatric\n",
      "reproductive\n",
      "cognitive\n",
      "bodily\n",
      "preventive\n",
      "genetic\n",
      "spinal\n",
      "traumatic\n",
      "infectious\n",
      "\n",
      "\n",
      "1972\n",
      "2002\n",
      "1992\n",
      "2001\n",
      "1993\n",
      "2003\n",
      "1969\n",
      "1995\n",
      "1990\n",
      "2005\n",
      "\n",
      "\n",
      "glary\n",
      "burglary\n",
      "interrogation\n",
      "gbag\n",
      "portra\n",
      "prede\n",
      "afgh\n",
      "fahren\n",
      "environ\n",
      "lesterol\n",
      "\n",
      "\n",
      "bolivia\n",
      "tunisia\n",
      "belarus\n",
      "croatia\n",
      "kazakhstan\n",
      "portugal\n",
      "serbia\n",
      "uzbek\n",
      "paraguay\n",
      "algeria\n",
      "\n",
      "\n",
      "indicted\n",
      "accuses\n",
      "sentenced\n",
      "pleaded\n",
      "criticized\n",
      "denounced\n",
      "denied\n",
      "hailed\n",
      "dismissed\n",
      "acquitted\n",
      "\n",
      "\n",
      "delicious\n",
      "magical\n",
      "exciting\n",
      "fascinating\n",
      "vibrant\n",
      "formidable\n",
      "thoughtful\n",
      "lovely\n",
      "beneficial\n",
      "profound\n",
      "\n",
      "\n",
      "nostal\n",
      "norwe\n",
      "twel\n",
      "archite\n",
      "aero\n",
      "nove\n",
      "reci\n",
      "engul\n",
      "whate\n",
      "anthro\n",
      "\n",
      "\n",
      "oldest\n",
      "longest\n",
      "lowest\n",
      "fastest\n",
      "tallest\n",
      "busiest\n",
      "hottest\n",
      "12th\n",
      "youngest\n",
      "16th\n",
      "\n",
      "\n",
      "unsure\n",
      "wondering\n",
      "convinced\n",
      "insisting\n",
      "wondered\n",
      "reminded\n",
      "complaining\n",
      "excited\n",
      "arguing\n",
      "hoping\n",
      "\n",
      "\n",
      "ag\n",
      " \n",
      "\n",
      "\n",
      "leng\n",
      "scand\n",
      "ig\n",
      "uc\n",
      "em\n",
      "ud\n",
      "mar\n",
      "\n",
      "\n",
      "inno\n",
      "spon\n",
      "mber\n",
      "lene\n",
      "resu\n",
      "mediterran\n",
      "uke\n",
      "tember\n",
      "bam\n",
      "kyr\n",
      "\n",
      "\n",
      "mo\n",
      "lo\n",
      "con\n",
      "mu\n",
      "de\n",
      "sha\n",
      "du\n",
      "su\n",
      "tu\n",
      "hu\n",
      "\n",
      "\n",
      "ailand\n",
      "zimbab\n",
      "occas\n",
      "immen\n",
      "includ\n",
      "delaw\n",
      "athle\n",
      "experi\n",
      "negot\n",
      "hrir\n",
      "\n",
      "\n",
      "grandmother\n",
      "roommate\n",
      "boyfriend\n",
      "girlfriend\n",
      "fiance\n",
      "aunt\n",
      "cousin\n",
      "fiancee\n",
      "nephew\n",
      "counselor\n",
      "\n",
      "\n",
      "ised\n",
      "ipped\n",
      "aded\n",
      "ered\n",
      "uted\n",
      "ized\n",
      "ilized\n",
      "oned\n",
      "ished\n",
      "aled\n",
      "\n",
      "\n",
      "28\n",
      "15\n",
      "36\n",
      "29\n",
      "25\n",
      "23\n",
      "39\n",
      "40\n",
      "27\n",
      "38\n",
      "\n",
      "\n",
      "popu\n",
      "magist\n",
      "nove\n",
      "theat\n",
      "injun\n",
      "frust\n",
      "juris\n",
      "convin\n",
      "immig\n",
      "anthro\n",
      "\n",
      "\n",
      "spacecraft\n",
      "telescope\n",
      "airliner\n",
      "dreamliner\n",
      "tanker\n",
      "delaw\n",
      "submarine\n",
      "airbus\n",
      "occas\n",
      "plane's\n",
      "\n",
      "\n",
      "theless\n",
      "lesterol\n",
      "occas\n",
      "subsequ\n",
      "assage\n",
      "fahren\n",
      "ailand\n",
      "secutive\n",
      "luscon\n",
      "theid\n",
      "\n",
      "\n",
      "atp\n",
      "paralympic\n",
      "tennis\n",
      "wta\n",
      "basketball\n",
      "rugby\n",
      "athletics\n",
      "wimbledon\n",
      "jazz\n",
      "players'\n",
      "\n",
      "\n",
      "civil\n",
      "foreign\n",
      "political\n",
      "supreme\n",
      "financial\n",
      "constitutional\n",
      "legislative\n",
      "social\n",
      "economic\n",
      "immigration\n",
      "\n",
      "\n",
      "i'd\n",
      "we'd\n",
      "you'd\n",
      "we'll\n",
      "we've\n",
      "i'll\n",
      "you've\n",
      "i've\n",
      "hasn't\n",
      "they'd\n",
      "\n",
      "\n",
      "investigators\n",
      "officials\n",
      "residents\n",
      "doctors\n",
      "firefighters\n",
      "authorities\n",
      "students\n",
      "experts\n",
      "activists\n",
      "attorneys\n",
      "\n",
      "\n",
      "uguay\n",
      "negot\n",
      "rouhani\n",
      "maduro\n",
      "athle\n",
      "occas\n",
      "guate\n",
      "gbag\n",
      "afgh\n",
      "theastern\n",
      "\n",
      "\n",
      "injunction\n",
      "rulings\n",
      "athle\n",
      "experi\n",
      "tribunal\n",
      "guate\n",
      "arct\n",
      "theastern\n",
      "itored\n",
      "gbag\n",
      "\n",
      "\n",
      "scrut\n",
      "inflam\n",
      "nutr\n",
      "reim\n",
      "symp\n",
      "sophist\n",
      "inef\n",
      "frust\n",
      "erad\n",
      "scand\n",
      "\n",
      "\n",
      "enthusia\n",
      "immen\n",
      "usalem\n",
      "surpris\n",
      "fahren\n",
      "delaw\n",
      "assage\n",
      "theless\n",
      "subsequ\n",
      "theid\n",
      "\n",
      "\n",
      "strategist\n",
      "coordinator\n",
      "commentator\n",
      "columnist\n",
      "chairwoman\n",
      "mogul\n",
      "grapher\n",
      "adviser\n",
      "contributor\n",
      "historian\n",
      "\n",
      "\n",
      "hosni\n",
      "christiane\n",
      "jethro\n",
      "cristiano\n",
      "elise\n",
      "kanye\n",
      "saad\n",
      "udad\n",
      "rory\n",
      "charac\n",
      "\n",
      "\n",
      "concerns\n",
      "doubts\n",
      "commitment\n",
      "distinction\n",
      "sympathy\n",
      "concern\n",
      "efforts\n",
      "frustration\n",
      "connections\n",
      "questions\n",
      "\n",
      "\n",
      "teed\n",
      "descended\n",
      "poured\n",
      "climbed\n",
      "bounced\n",
      "slipped\n",
      "tossed\n",
      "wiped\n",
      "ripped\n",
      "edged\n",
      "\n",
      "\n",
      "fbi's\n",
      "singer's\n",
      "tour's\n",
      "organization's\n",
      "military's\n",
      "couple's\n",
      "agency's\n",
      "minister's\n",
      "army's\n",
      "show's\n",
      "\n",
      "\n",
      "175\n",
      "450\n",
      "550\n",
      "650\n",
      "120\n",
      "250\n",
      "750\n",
      "260\n",
      "270\n",
      "240\n",
      "\n",
      "\n",
      "hampered\n",
      "governed\n",
      "enriched\n",
      "administered\n",
      "transmitted\n",
      "traced\n",
      "regulated\n",
      "renewable\n",
      "populated\n",
      "resistant\n",
      "\n",
      "\n",
      "involuntary\n",
      "impending\n",
      "lucrative\n",
      "immediate\n",
      "deepwater\n",
      "prolonged\n",
      "unnamed\n",
      "extensive\n",
      "broader\n",
      "lengthy\n",
      "\n",
      "\n",
      "photograp\n",
      "moroc\n",
      "leng\n",
      "reim\n",
      "resur\n",
      "refres\n",
      "phis\n",
      "inflam\n",
      "detro\n",
      "resor\n",
      "\n",
      "\n",
      "generated\n",
      "influenced\n",
      "benefited\n",
      "initiated\n",
      "supported\n",
      "supplied\n",
      "aided\n",
      "attracted\n",
      "reviewed\n",
      "acquired\n",
      "\n",
      "\n",
      "theless\n",
      "negot\n",
      "compon\n",
      "ivid\n",
      "enthusia\n",
      "assage\n",
      "immen\n",
      "usalem\n",
      "dort\n",
      "itored\n",
      "\n",
      "\n",
      "scrut\n",
      "fict\n",
      "confis\n",
      "insurg\n",
      "proxim\n",
      "accompan\n",
      "obst\n",
      "o'ne\n",
      "itored\n",
      "dys\n",
      "\n",
      "\n",
      "profound\n",
      "dense\n",
      "immense\n",
      "substantial\n",
      "vague\n",
      "fierce\n",
      "fragile\n",
      "tremendous\n",
      "neat\n",
      "enormous\n",
      "\n",
      "\n",
      "kansas\n",
      "connecticut\n",
      "illinois\n",
      "pennsylvania\n",
      "arkansas\n",
      "louisiana\n",
      "maryland\n",
      "missouri\n",
      "tampa\n",
      "wisconsin\n",
      "\n",
      "\n",
      "ley's\n",
      "er's\n",
      "i's\n",
      "e's\n",
      "an's\n",
      "ton's\n",
      "on's\n",
      "ie's\n",
      "es'\n",
      "ler's\n",
      "\n",
      "\n",
      "espion\n",
      "explos\n",
      "unbeliev\n",
      "mclaugh\n",
      "inevit\n",
      "gbag\n",
      "ieval\n",
      "strugg\n",
      "itored\n",
      "glary\n",
      "\n",
      "\n",
      "athle\n",
      "drivers'\n",
      "quarterfinals\n",
      "standings\n",
      "occas\n",
      "espion\n",
      "liga\n",
      "couver\n",
      "glary\n",
      "bundesliga\n",
      "\n",
      "\n",
      "higher\n",
      "better\n",
      "harder\n",
      "faster\n",
      "bigger\n",
      "deeper\n",
      "worse\n",
      "greater\n",
      "cheaper\n",
      "stronger\n",
      "\n",
      "\n",
      "whate\n",
      "cuis\n",
      "manh\n",
      "accompan\n",
      "espion\n",
      "demp\n",
      "delaw\n",
      "o'ne\n",
      "enthusia\n",
      "theid\n",
      "\n",
      "\n",
      "anbar\n",
      "fallu\n",
      "occas\n",
      "homs\n",
      "environ\n",
      "mosul\n",
      "daraa\n",
      "lesterol\n",
      "ttp\n",
      "ifics\n",
      "\n",
      "\n",
      "confis\n",
      "dort\n",
      "compon\n",
      "attem\n",
      "ieval\n",
      "enrich\n",
      "incre\n",
      "surpris\n",
      "includ\n",
      "subsequ\n",
      "\n",
      "\n",
      "bullied\n",
      "depressed\n",
      "ashamed\n",
      "raped\n",
      "saddened\n",
      "gbag\n",
      "charac\n",
      "obese\n",
      "terrified\n",
      "ifics\n",
      "\n",
      "\n",
      "rehear\n",
      "engul\n",
      "resur\n",
      "eclip\n",
      "reim\n",
      "glimp\n",
      "moroc\n",
      "suc\n",
      "spear\n",
      "popu\n",
      "\n",
      "\n",
      "year\n",
      "friday\n",
      "week\n",
      "month\n",
      "sunday\n",
      "thursday\n",
      "monday\n",
      "saturday\n",
      "tuesday\n",
      "wednesday\n",
      "\n",
      "\n",
      "rampage\n",
      "bombings\n",
      "clashes\n",
      "shootings\n",
      "killings\n",
      "massacre\n",
      "slayings\n",
      "explosions\n",
      "altercation\n",
      "siege\n",
      "\n",
      "\n",
      "requiring\n",
      "letting\n",
      "violating\n",
      "distributing\n",
      "implementing\n",
      "introducing\n",
      "reducing\n",
      "ordering\n",
      "enforcing\n",
      "eliminating\n",
      "\n",
      "\n",
      "odox\n",
      "athle\n",
      "ifics\n",
      "massachu\n",
      "secutive\n",
      "charac\n",
      "mbley\n",
      "anmen\n",
      "tournam\n",
      "hrir\n",
      "\n",
      "\n",
      "museum\n",
      "institution\n",
      "facility\n",
      "library\n",
      "institute\n",
      "corporation\n",
      "organization\n",
      "council\n",
      "foundation\n",
      "ministry\n",
      "\n",
      "\n",
      "dys\n",
      "distr\n",
      "retr\n",
      "desc\n",
      "contr\n",
      "cont\n",
      "extr\n",
      "appreh\n",
      "videot\n",
      "transc\n",
      "\n",
      "\n",
      "insisted\n",
      "explained\n",
      "argued\n",
      "cautioned\n",
      "replied\n",
      "joked\n",
      "testified\n",
      "acknowledged\n",
      "wondered\n",
      "vowed\n",
      "\n",
      "\n",
      "independents\n",
      "hispanics\n",
      "colleges\n",
      "economists\n",
      "liberals\n",
      "households\n",
      "respondents\n",
      "entrepreneurs\n",
      "conservatives\n",
      "governors\n",
      "\n",
      "\n",
      "scand\n",
      "traged\n",
      "dort\n",
      "strug\n",
      "yose\n",
      "jere\n",
      "compon\n",
      "surpris\n",
      "califor\n",
      "theless\n",
      "\n",
      "\n",
      "detonated\n",
      "stormed\n",
      "grabbed\n",
      "engulfed\n",
      "transported\n",
      "raided\n",
      "chased\n",
      "entered\n",
      "collided\n",
      "invaded\n",
      "\n",
      "\n",
      "albums\n",
      "singers\n",
      "festivals\n",
      "musicians\n",
      "novels\n",
      "uguay\n",
      "espion\n",
      "glary\n",
      "strugg\n",
      "oscars\n",
      "\n",
      "\n",
      "in\n",
      "at\n",
      "from\n",
      "by\n",
      "when\n",
      "during\n",
      "after\n",
      "for\n",
      "on\n",
      "with\n",
      "\n",
      "\n",
      "certainly\n",
      "probably\n",
      "definitely\n",
      "never\n",
      "obviously\n",
      "hardly\n",
      "surely\n",
      "actually\n",
      "always\n",
      "usually\n",
      "\n",
      "\n",
      "suites\n",
      "floors\n",
      "shelters\n",
      "beaches\n",
      "trees\n",
      "pools\n",
      "bottles\n",
      "shops\n",
      "delaw\n",
      "glary\n",
      "\n",
      "\n",
      "boko\n",
      "yemeni\n",
      "somali\n",
      "somalia's\n",
      "saudi\n",
      "lebanese\n",
      "bosnian\n",
      "sri\n",
      "sudanese\n",
      "transitional\n",
      "\n",
      "\n",
      "responses\n",
      "attempts\n",
      "lawsuits\n",
      "decisions\n",
      "statements\n",
      "inquiries\n",
      "agreements\n",
      "proposals\n",
      "accusations\n",
      "discussions\n",
      "\n",
      "\n",
      "islamists\n",
      "militias\n",
      "shiites\n",
      "gunmen\n",
      "kurds\n",
      "militants\n",
      "egyptians\n",
      "insurgents\n",
      "houthis\n",
      "sunnis\n",
      "\n",
      "\n",
      "couver\n",
      "ailand\n",
      "inals\n",
      "glary\n",
      "ences\n",
      "ivid\n",
      "espion\n",
      "hrir\n",
      "theid\n",
      "negot\n",
      "\n",
      "\n",
      "mashable\n",
      "android\n",
      "verizon\n",
      "itunes\n",
      "playstation\n",
      "samsung\n",
      "nintend\n",
      "nintendo\n",
      "silicon\n",
      "netflix\n",
      "\n",
      "\n",
      "rainfall\n",
      "floods\n",
      "diarrhea\n",
      "devastation\n",
      "outages\n",
      "rains\n",
      "earthquakes\n",
      "vomiting\n",
      "espion\n",
      "snowfall\n",
      "\n",
      "\n",
      "scrut\n",
      "testim\n",
      "rele\n",
      "nutr\n",
      "proto\n",
      "leng\n",
      "scand\n",
      "obst\n",
      "accompan\n",
      "whate\n",
      "\n",
      "\n",
      "f\n",
      "l\n",
      "g\n",
      "d\n",
      "r\n",
      "t\n",
      " \n",
      "v\n",
      "b\n",
      "k\n",
      "\n",
      "\n",
      "lebanon's\n",
      "london's\n",
      "yemen's\n",
      "football's\n",
      "ukraine's\n",
      "egypt's\n",
      "afghanistan's\n",
      "libya's\n",
      "somalia's\n",
      "greece's\n",
      "\n",
      "\n",
      "sectors\n",
      "technologies\n",
      "sensors\n",
      "industries\n",
      "providers\n",
      "environments\n",
      "techniques\n",
      "entities\n",
      "installations\n",
      "tasks\n",
      "\n",
      "\n",
      "hrir\n",
      "lesterol\n",
      "glary\n",
      "icting\n",
      "charac\n",
      "fahren\n",
      "mbley\n",
      "negot\n",
      "couver\n",
      "oking\n",
      "\n",
      "\n",
      "assumption\n",
      "acknowled\n",
      "reminder\n",
      "notion\n",
      "mechanism\n",
      "incentive\n",
      "espion\n",
      "strugg\n",
      "obstacle\n",
      "inevit\n",
      "\n",
      "\n",
      "promptly\n",
      "swiftly\n",
      "safely\n",
      "adequately\n",
      "broadly\n",
      "properly\n",
      "readily\n",
      "thoroughly\n",
      "instantly\n",
      "voluntarily\n",
      "\n",
      "\n",
      "give\n",
      "make\n",
      "bring\n",
      "get\n",
      "want\n",
      "take\n",
      "tell\n",
      "subscribe\n",
      "learn\n",
      "keep\n",
      "\n",
      "\n",
      "assage\n",
      "enthusia\n",
      "theid\n",
      "uguay\n",
      "usalem\n",
      "ieval\n",
      "negot\n",
      "espion\n",
      "moil\n",
      "performan\n",
      "\n",
      "\n",
      "confis\n",
      "compon\n",
      "surpris\n",
      "notor\n",
      "dort\n",
      "attem\n",
      "scrut\n",
      "insurg\n",
      "refres\n",
      "accompan\n",
      "\n",
      "\n",
      "went\n",
      "took\n",
      "brought\n",
      "came\n",
      "pulled\n",
      "turned\n",
      "moved\n",
      "gave\n",
      "jumped\n",
      "walked\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_embed = model.word_embed\n",
    "embedding_clustering = EmbeddingClustering(tokenizer, n_clusters=100)\n",
    "embedding_clustering.fit(word_embed, normalize=True)\n",
    "embedding_clustering.print_clusters(n_words=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc968e2d",
   "metadata": {},
   "source": [
    "# Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de0e293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1602]], shape=(1, 1), dtype=int32)\n",
      "tf.Tensor([[3512]], shape=(1, 1), dtype=int32)\n",
      "tf.Tensor([[5393]], shape=(1, 1), dtype=int32)\n",
      "netanyahu\n",
      "russia\n",
      "israel\n",
      "hamas\n",
      "israelis\n",
      "jerusalem\n",
      "tehran\n",
      "kiev\n",
      "gaza\n",
      "palestinians\n",
      "democr\n",
      "beirut\n",
      "azer\n",
      "syria\n",
      "egypt\n",
      "idf\n",
      "iran\n",
      "britain\n",
      "palestinian\n",
      "abbas\n",
      "tunisia\n",
      "alger\n",
      "lebanon\n",
      "perpe\n",
      "israeli\n",
      "davos\n",
      "brahim\n",
      "controver\n",
      "hezbollah\n",
      "hagel\n",
      "jevich\n",
      "norway\n",
      "fah\n",
      "guinea\n",
      "khamenei\n",
      "cuba\n",
      "anbar\n",
      "utt\n",
      "khamene\n",
      "hezbol\n",
      "weren\n",
      "canada\n",
      "sunnis\n",
      "dipl\n",
      "stoke\n",
      "lavrov\n",
      "aviv\n",
      "karzai\n",
      "israel's\n",
      "arct\n",
      "cambodia\n",
      "zuckerberg\n",
      "yanukov\n",
      "yad\n",
      "ukraine\n",
      "pakistan\n",
      "carney\n",
      "netherlands\n",
      "cairo\n",
      "lieberman\n",
      "panetta\n",
      "homs\n",
      "zawah\n",
      "austria\n",
      "espion\n",
      "wawrink\n",
      "vinc\n",
      "libertar\n",
      "libya\n",
      "poland\n",
      "indonesia\n",
      "liby\n",
      "merkel\n",
      "pyongyang\n",
      "tik\n",
      "airstrikes\n",
      "ibrahimovic\n",
      "abe\n",
      "iran's\n",
      "yugo\n",
      "kass\n",
      "mosul\n",
      "galax\n",
      "yemen\n",
      "scotland\n",
      "settlements\n",
      "sudan\n",
      "nuri\n",
      "niger\n",
      "palestine\n",
      "tsvangira\n",
      "ieval\n",
      "iaea\n",
      "denmark\n",
      "hmer\n",
      "tahrir\n",
      "nusra\n",
      "sarkoz\n",
      "ukrain\n",
      "bolivia\n"
     ]
    }
   ],
   "source": [
    "word_embed = model.word_embed\n",
    "\n",
    "text = \"russia\"\n",
    "text = text.lower()\n",
    "\n",
    "idx = tf.cast(tokenizer.tokenizer.tokenize(text), tf.int32)\n",
    "idx = tokenize(idx, tokenizer.merge_list)\n",
    "print(idx)\n",
    "embed1 = tf.expand_dims(word_embed[idx[0][0]], axis=0)\n",
    "\n",
    "\n",
    "text = \"putin\"\n",
    "text = text.lower()\n",
    "\n",
    "idx = tf.cast(tokenizer.tokenizer.tokenize(text), tf.int32)\n",
    "idx = tokenize(idx, tokenizer.merge_list)\n",
    "print(idx)\n",
    "embed2 = tf.expand_dims(word_embed[idx[0][0]], axis=0)\n",
    "\n",
    "text = \"netanyahu\"\n",
    "text = text.lower()\n",
    "\n",
    "idx = tf.cast(tokenizer.tokenizer.tokenize(text), tf.int32)\n",
    "idx = tokenize(idx, tokenizer.merge_list)\n",
    "print(idx)\n",
    "embed3 = tf.expand_dims(word_embed[idx[0][0]], axis=0)\n",
    "\n",
    "embed = embed1 - embed2 + embed3\n",
    "\n",
    "cosine_sim = cosine_similarity(embed, word_embed, normalize=False)\n",
    "idx = tf.argsort(cosine_sim, axis=-1, \n",
    "                 direction='DESCENDING',\n",
    "                 #direction='ASCENDING', \n",
    "                 stable=False, name=None)[0]\n",
    "\n",
    "for i in idx[:100]:\n",
    "    i = tf.expand_dims(i, axis=0)\n",
    "    print(tokenizer.detokenize(i).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54734624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[553]], shape=(1, 1), dtype=int32)\n",
      "obama\n",
      "obama's\n",
      "clinton\n",
      "romney\n",
      "republicans\n",
      "bush\n",
      "boehner\n",
      "sen\n",
      "reagan\n",
      "democrats\n",
      "barack\n",
      "mccain\n",
      "congressional\n",
      "sarkozy\n",
      "pentagon\n",
      "putin\n",
      "u\n",
      "assad\n",
      "liberals\n",
      "afghans\n",
      "calderon\n",
      "washington\n",
      "bush's\n",
      "conservatives\n",
      "president\n",
      "obamacare\n",
      "iraqis\n",
      "panetta\n",
      "snowden\n",
      "mcconnell\n",
      "clinton's\n",
      "chavez\n",
      "gop\n",
      "palin\n",
      "americans\n",
      "senate\n",
      "christie\n",
      "isis\n",
      "veterans\n",
      "he\n",
      "voters\n",
      "petraeus\n",
      "pelosi\n",
      "secretary\n",
      "jindal\n",
      "george\n",
      "mandela\n",
      "republican\n",
      "kerry\n",
      "karzai\n",
      "biden\n",
      "gop's\n",
      "francis\n",
      "economists\n",
      "lawmakers\n",
      "jeb\n",
      "we've\n",
      "congressman\n",
      "rouhani\n",
      "navarrette\n",
      "congress\n",
      "netanyahu\n",
      "latinos\n",
      "nixon\n",
      "aides\n",
      "iraqi\n",
      "nra\n",
      "pelos\n",
      "richard\n",
      "white\n",
      "clint\n",
      "gov\n",
      "lincoln\n",
      "romney's\n",
      "gingrich\n",
      "taxpayers\n",
      "nato\n",
      "presidents\n",
      "vietnam\n",
      "nieto\n",
      "analysts\n",
      "president's\n",
      "ryan\n",
      "gupta\n",
      "senators\n",
      "cdc\n",
      "shinse\n",
      "brennan\n",
      "next\n",
      "capitol\n",
      "legislators\n",
      "ahmadinejad\n",
      "elect\n",
      "erdogan\n",
      "afghanistan\n",
      "iraq\n",
      "gadhafi\n",
      "roosevelt\n",
      "cheney\n",
      "santorum\n"
     ]
    }
   ],
   "source": [
    "word_embed = model.word_embed\n",
    "\n",
    "text = \"obama\"\n",
    "text = text.lower()\n",
    "\n",
    "idx = tf.cast(tokenizer.tokenize(text), tf.int32)\n",
    "print(idx)\n",
    "embed = tf.expand_dims(word_embed[idx[0][0]], axis=0)\n",
    "\n",
    "cosine_sim = embed@tf.transpose(word_embed)\n",
    "idx = tf.argsort(cosine_sim, axis=-1, \n",
    "                 direction='DESCENDING',\n",
    "                 #direction='ASCENDING', \n",
    "                 stable=False, name=None)[0]\n",
    "\n",
    "for i in idx[:100]:\n",
    "    i = tf.expand_dims(i, axis=0)\n",
    "    print(tokenizer.detokenize(i).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff23330f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[5393]], shape=(1, 1), dtype=int32)\n",
      "netanyahu\n",
      "abulary\n",
      "hagel\n",
      "maduro\n",
      "espion\n",
      "yingluck\n",
      "onsored\n",
      "nandez\n",
      "saleh\n",
      "natur\n",
      "ailand\n",
      "hezbol\n",
      "panetta\n",
      "biden\n",
      "shinse\n",
      "kerry\n",
      "gibbs\n",
      "sarkozy\n",
      "fundam\n",
      "hift\n",
      "patro\n",
      "signific\n",
      "anonymity\n",
      "putin\n",
      "mugabe\n",
      "lades\n",
      "boehner\n",
      "pelosi\n",
      "medvedev\n",
      "ahmadinejad\n",
      "warri\n",
      "thaksin\n",
      "landrieu\n",
      "shaba\n",
      "gbag\n",
      "accust\n",
      "charac\n",
      "fahren\n",
      "liby\n",
      "peninsu\n",
      "helicop\n",
      "zuma\n",
      "traged\n",
      "portugu\n",
      "morsy\n",
      "publ\n",
      "enjo\n",
      "ilight\n",
      "abbas\n",
      "erdogan\n",
      "ieval\n",
      "bachmann\n",
      "yanukovych\n",
      "leep\n",
      "confir\n",
      "rodrigue\n",
      "secutive\n",
      "provin\n",
      "mccain's\n",
      "moil\n",
      "subsequ\n",
      "abled\n",
      "juvent\n",
      "o'ne\n",
      "guardiola\n",
      "lieberman\n",
      "karzai\n",
      "catastro\n",
      "ouatt\n",
      "zardari\n",
      "possib\n",
      "toug\n",
      "theless\n",
      "burma\n",
      "carney\n",
      "ricul\n",
      "zhok\n",
      "barcelon\n",
      "dort\n",
      "sunnis\n",
      "lomb\n",
      "snowden\n",
      "avez\n",
      "diffic\n",
      "sess\n",
      "khamenei\n",
      "exer\n",
      "golese\n",
      "copen\n",
      "rouhani\n",
      "ipal\n",
      "transparen\n",
      "ultane\n",
      "mccain\n",
      "boeh\n",
      "diox\n",
      "citiz\n",
      "adjac\n",
      "nieto\n",
      "lavrov\n"
     ]
    }
   ],
   "source": [
    "word_embed = model.word_embed\n",
    "\n",
    "text = \"netanyahu\"\n",
    "text = text.lower()\n",
    "\n",
    "idx = tf.cast(tokenizer.tokenizer.tokenize(text), tf.int32)\n",
    "idx = tokenize(idx, tokenizer.merge_list)\n",
    "print(idx)\n",
    "embed = tf.expand_dims(word_embed[idx[0][0]], axis=0)\n",
    "\n",
    "cosine_sim = embed@tf.transpose(word_embed)\n",
    "idx = tf.argsort(cosine_sim, axis=-1, \n",
    "                 direction='DESCENDING',\n",
    "                 #direction='ASCENDING', \n",
    "                 stable=False, name=None)[0]\n",
    "\n",
    "for i in idx[:100]:\n",
    "    i = tf.expand_dims(i, axis=0)\n",
    "    print(tokenizer.detokenize(i).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ff28a5",
   "metadata": {},
   "source": [
    "## Mean Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71e4c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 62)\n",
      " \n",
      ".\n",
      "-\n",
      "\"\n",
      ",\n",
      "a\n",
      "in\n",
      "\n",
      "\n",
      "and\n",
      "the\n",
      "on\n",
      "to\n",
      "at\n",
      "'\n",
      "an\n",
      "or\n",
      "u\n",
      "by\n",
      "that\n",
      ":\n",
      "as\n",
      "'s\n",
      "s\n",
      "al\n",
      "of\n",
      "it\n",
      "he\n",
      "for\n",
      "un\n",
      "over\n",
      "e\n",
      "about\n",
      "is\n",
      "with\n",
      "after\n",
      "up\n",
      "not\n",
      "last\n",
      "more\n",
      "may\n",
      "?\n",
      "re\n",
      "from\n",
      "ad\n",
      "(\n",
      "state\n",
      "be\n",
      "just\n",
      "so\n",
      "was\n",
      "one\n",
      "/\n",
      "ed\n",
      "no\n",
      "war\n",
      "while\n",
      "security\n",
      ";\n",
      "but\n",
      "1\n",
      "en\n",
      "n\n",
      "man\n",
      "house\n",
      "i\n",
      "north\n",
      "m\n",
      "first\n",
      "ar\n",
      "l\n",
      "f\n",
      "c\n",
      "er\n",
      "there\n",
      "out\n",
      "o\n",
      "do\n",
      "two\n",
      "when\n",
      "less\n",
      "had\n",
      "air\n",
      "k\n",
      "v\n",
      "h\n",
      "near\n",
      "they\n",
      "2\n",
      "his\n",
      "some\n",
      "de\n",
      "back\n",
      "we\n",
      "field\n",
      "fire\n",
      "if\n",
      "this\n",
      "under\n",
      "p\n",
      "right\n"
     ]
    }
   ],
   "source": [
    "word_embed = model.word_embed\n",
    "\n",
    "text = \"Obama's remarks came shortly after U.N. inspectors left Syria, carrying evidence that will determine whether chemical weapons were used in an attack early last week in a Damascus suburb.\"\n",
    "text = text.lower()\n",
    "\n",
    "idx = tf.cast(tokenizer.tokenizer.tokenize(text), tf.int32)\n",
    "idx = tokenize(idx, tokenizer.merge_list)\n",
    "print(idx.shape)\n",
    "embed_final = model.call(idx, logits=False)\n",
    "#embed_mean = embed_final[:,-1,:]\n",
    "embed_mean = tf.reduce_mean(embed_final, axis=1)\n",
    "embed_mean = tf.cast(embed_mean, dtype=tf.float32) \n",
    "\n",
    "cosine_sim = cosine_similarity(embed_mean, word_embed, normalize=False)\n",
    "#cosine_sim = cosine_similarity(embed_mean, word_embed, normalize=True)\n",
    "\n",
    "idx = tf.argsort(cosine_sim, axis=-1, \n",
    "                 direction='DESCENDING',\n",
    "                 #direction='ASCENDING', \n",
    "                 stable=False, name=None)[0]\n",
    "\n",
    "for i in idx[:100]:\n",
    "    i = tf.expand_dims(i, axis=0)\n",
    "    print(tokenizer.detokenize(i).numpy().decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d6f1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[553]], shape=(1, 1), dtype=int32)\n",
      "tf.Tensor(0.08745351, shape=(), dtype=float32)\n",
      "tf.Tensor([[    1    13    15 ... 15466  9736 15505]], shape=(1, 16070), dtype=int32)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m i \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(i, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "word_embed = model.word_embed\n",
    "\n",
    "text = \"Obama\"\n",
    "text = text.lower()\n",
    "\n",
    "idx = tf.cast(tokenizer.tokenizer.tokenize(text), tf.int32)\n",
    "idx = tokenize(idx, tokenizer.merge_list)\n",
    "print(idx)\n",
    "b = model.unembed_b[idx[0][0]]\n",
    "print(b)\n",
    "logits = model.call(idx, logits=True) \n",
    "#embed_mean = embed_final[:,-1,:]\n",
    "embed_mean = tf.reduce_mean(embed_final, axis=1)\n",
    "embed_mean = tf.cast(embed_mean, dtype=tf.float32)\n",
    "\n",
    "cosine_sim = cosine_similarity(embed_mean, word_embed, normalize=False)\n",
    "#cosine_sim = cosine_similarity(embed_mean, word_embed, normalize=True)\n",
    "\n",
    "idx = tf.argsort(logits, axis=-1, \n",
    "                 direction='DESCENDING',\n",
    "                 #direction='ASCENDING', \n",
    "                 stable=False, name=None)[0]\n",
    "\n",
    "for i in idx[:100]:\n",
    "    i = tf.expand_dims(i, axis=0)\n",
    "    print(i)\n",
    "    print(tokenizer.detokenize(i).numpy().decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f09e0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis is a text to find out how to make a stop mask\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m----> 3\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mencode(text)\n\u001b[0;32m      4\u001b[0m tokens\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, tokenizer\u001b[38;5;241m.\u001b[39mtoken_to_idx[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<s>\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      5\u001b[0m tokens\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m10\u001b[39m, tokenizer\u001b[38;5;241m.\u001b[39mtoken_to_idx[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</s>\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "text = \"this is a text to find out how to make a stop mask\"\n",
    "text = text.lower()\n",
    "tokens = tokenizer.encode(text)\n",
    "tokens.insert(0, tokenizer.token_to_idx[\"<s>\"])\n",
    "tokens.insert(10, tokenizer.token_to_idx[\"</s>\"])\n",
    "tokens.insert(10, tokenizer.token_to_idx[\"<s>\"])\n",
    "tokens.insert(15, tokenizer.token_to_idx[\"</s>\"])\n",
    "tokens.insert(15, tokenizer.token_to_idx[\"<s>\"])\n",
    "tokens.append(tokenizer.token_to_idx[\"</s>\"])\n",
    "\n",
    "print(tokens)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a5f20b",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
