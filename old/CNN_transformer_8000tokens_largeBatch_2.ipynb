{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04010a08",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fa3d166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from src.tokenizer import TokenizerBPE, word_split, normalize_to_ascii\n",
    "\n",
    "import os\n",
    "import time\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from tqdm.notebook import tqdm\n",
    "from src.transformer import *\n",
    "from src.data_handling import read_first_n, sample_batch\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2b59898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 2080 SUPER, compute capability 7.5\n"
     ]
    }
   ],
   "source": [
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7afd4e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = pkl.load(open(\"tokenizers/tokenizer_CNN16000_lowercase.pkl\", 'rb'))\n",
    "tokenizer.create_hash()\n",
    "\n",
    "random.seed(42)\n",
    "corpus_indicies = pkl.load(open('corpus/CNN_tokenized16000_lowercase.pkl', 'rb'))\n",
    "random.shuffle(corpus_indicies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f830d881",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a564402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmUpThenDecay(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self,\n",
    "                 initial_learning_rate: float,\n",
    "                 warmup_steps: int,\n",
    "                 decay_schedule_fn: tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "        \"\"\"\n",
    "        initial_learning_rate: peak LR reached at end of warmup\n",
    "        warmup_steps:      # of steps to ramp from 0 â†’ initial_learning_rate\n",
    "        decay_schedule_fn: a tf.keras schedule to apply *after* warmup\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.initial_lr = initial_learning_rate\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.decay_schedule_fn = decay_schedule_fn\n",
    "\n",
    "    def __call__(self, step):\n",
    "        # Cast to float32 for safety in graph mode\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        warmup_steps = tf.cast(self.warmup_steps, tf.float32)\n",
    "\n",
    "        # compute linear warmup: lr = initial_lr * (step / warmup_steps)\n",
    "        warmup_lr = self.initial_lr * (step / warmup_steps)\n",
    "\n",
    "        # after warmup_steps, switch to decay schedule (shift step count)\n",
    "        decay_step = step - warmup_steps\n",
    "        decay_lr = self.decay_schedule_fn(decay_step)\n",
    "\n",
    "        # if step < warmup_steps, pick warmup_lr, else decay_lr\n",
    "        return tf.cond(step < warmup_steps,\n",
    "                       lambda: warmup_lr,\n",
    "                       lambda: decay_lr)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a5a33ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr = 1e-4\n",
    "decay_steps = 10000\n",
    "decay_rate = 0.5\n",
    "decay_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=initial_lr,\n",
    "    decay_steps=decay_steps,\n",
    "    decay_rate=decay_rate,\n",
    "    staircase=False)\n",
    "\n",
    "warmup_steps = 1000\n",
    "lr_schedule = WarmUpThenDecay(\n",
    "    initial_learning_rate=initial_lr,\n",
    "    warmup_steps=warmup_steps,\n",
    "    decay_schedule_fn=decay_schedule)\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "max_seq_len = 128\n",
    "embed_dim = 768\n",
    "tf_blocks = 6\n",
    "heads = 6\n",
    "ff_dim = 4*embed_dim\n",
    "weight_decay = 0.01\n",
    "dropout = 0.05\n",
    "\n",
    "unembed_dims = []\n",
    "\n",
    "model = Transformer(vocab_size=tokenizer.vocab_size,\n",
    "                    max_seq_len=max_seq_len,\n",
    "                    embed_dim=embed_dim,\n",
    "                    tf_blocks=tf_blocks,\n",
    "                    heads=heads,\n",
    "                    ff_dim = ff_dim,\n",
    "                    unembed_dims=unembed_dims,\n",
    "                    lr=lr_schedule,\n",
    "                    wd = weight_decay,\n",
    "                    dropout=dropout,\n",
    "                    )\n",
    "\n",
    "losses_train = []\n",
    "losses_test = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7970a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"model_16k_tokens_largeBatch_2\"\n",
    "\n",
    "\n",
    "ckpt = tf.train.Checkpoint(\n",
    "    optimizer=model.opt,\n",
    "    model=model\n",
    ")\n",
    "ckpt_manager = tf.train.CheckpointManager(\n",
    "    ckpt, \n",
    "    directory=\"checkpoints/\" + name,      # folder where ckpts are saved\n",
    "    max_to_keep=5                         # only keep 5 latest checkpoints\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "88b34765",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "losses_train, losses_test = pkl.load(open(\"checkpoints/losses_\" + name + \".pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a6527620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 54964934\n"
     ]
    }
   ],
   "source": [
    "total_params = 0\n",
    "for var in model.parameter_list:\n",
    "    shape = var.get_shape()\n",
    "    num_params = 1\n",
    "    for dim in shape:\n",
    "        num_params *= dim\n",
    "    total_params += num_params\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "93977cd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m ax2\u001b[38;5;241m.\u001b[39mgrid(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     66\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[1;32m---> 67\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\pyplot.py:614\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    613\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 614\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_backend_mod()\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib_inline\\backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m figure_manager \u001b[38;5;129;01min\u001b[39;00m Gcf\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[1;32m---> 90\u001b[0m         \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fetch_figure_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     show\u001b[38;5;241m.\u001b[39m_to_draw \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\formatters.py:238\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    236\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\formatters.py:282\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 282\u001b[0m     r \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\formatters.py:402\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    404\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\IPython\\core\\pylabtools.py:170\u001b[0m, in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[0;32m    168\u001b[0m     FigureCanvasBase(fig)\n\u001b[1;32m--> 170\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mprint_figure(bytes_io, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    171\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\backend_bases.py:2184\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2181\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[0;32m   2182\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[0;32m   2183\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m-> 2184\u001b[0m         result \u001b[38;5;241m=\u001b[39m print_method(\n\u001b[0;32m   2185\u001b[0m             filename,\n\u001b[0;32m   2186\u001b[0m             facecolor\u001b[38;5;241m=\u001b[39mfacecolor,\n\u001b[0;32m   2187\u001b[0m             edgecolor\u001b[38;5;241m=\u001b[39medgecolor,\n\u001b[0;32m   2188\u001b[0m             orientation\u001b[38;5;241m=\u001b[39morientation,\n\u001b[0;32m   2189\u001b[0m             bbox_inches_restore\u001b[38;5;241m=\u001b[39m_bbox_inches_restore,\n\u001b[0;32m   2190\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2191\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\backend_bases.py:2040\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2036\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[0;32m   2037\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2038\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m   2039\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[1;32m-> 2040\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: meth(\n\u001b[0;32m   2041\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m skip}))\n\u001b[0;32m   2042\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[0;32m   2043\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:481\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    435\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 481\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:429\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[1;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_print_pil\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;124;03m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 429\u001b[0m     \u001b[43mFigureCanvasAgg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m     mpl\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave(\n\u001b[0;32m    431\u001b[0m         filename_or_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_rgba(), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mfmt, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    432\u001b[0m         dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi, metadata\u001b[38;5;241m=\u001b[39mmetadata, pil_kwargs\u001b[38;5;241m=\u001b[39mpil_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:382\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\u001b[38;5;241m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\n\u001b[0;32m    381\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[1;32m--> 382\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdraw()\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\artist.py:94\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 94\u001b[0m     result \u001b[38;5;241m=\u001b[39m draw(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[0;32m     96\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\artist.py:71\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\figure.py:3257\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3254\u001b[0m             \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   3256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> 3257\u001b[0m     \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3260\u001b[0m     renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3261\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\image.py:134\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 134\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\artist.py:71\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\axes\\_base.py:3210\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[0;32m   3208\u001b[0m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_figure(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), artists_rasterized, renderer)\n\u001b[1;32m-> 3210\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3213\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\image.py:134\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 134\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\artist.py:71\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\axis.py:1412\u001b[0m, in \u001b[0;36mAxis.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;66;03m# Shift label away from axes to avoid overlapping ticklabels.\u001b[39;00m\n\u001b[0;32m   1411\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_label_position(renderer)\n\u001b[1;32m-> 1412\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_offset_text_position(tlb1, tlb2)\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffsetText\u001b[38;5;241m.\u001b[39mset_text(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmajor\u001b[38;5;241m.\u001b[39mformatter\u001b[38;5;241m.\u001b[39mget_offset())\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\artist.py:71\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\text.py:752\u001b[0m, in \u001b[0;36mText.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    749\u001b[0m renderer\u001b[38;5;241m.\u001b[39mopen_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_gid())\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cm_set(text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_wrapped_text()):\n\u001b[1;32m--> 752\u001b[0m     bbox, info, descent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    753\u001b[0m     trans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_transform()\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;66;03m# don't use self.get_position here, which refers to text\u001b[39;00m\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;66;03m# position in Text:\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\text.py:382\u001b[0m, in \u001b[0;36mText._get_layout\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    380\u001b[0m clean_line, ismath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_math(line)\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clean_line:\n\u001b[1;32m--> 382\u001b[0m     w, h, d \u001b[38;5;241m=\u001b[39m \u001b[43m_get_text_metrics_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_line\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fontproperties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mismath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mismath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    386\u001b[0m     w \u001b[38;5;241m=\u001b[39m h \u001b[38;5;241m=\u001b[39m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\text.py:69\u001b[0m, in \u001b[0;36m_get_text_metrics_with_cache\u001b[1;34m(renderer, text, fontprop, ismath, dpi)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call ``renderer.get_text_width_height_descent``, caching the results.\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Cached based on a copy of fontprop so that later in-place mutations of\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# the passed-in argument do not mess up the cache.\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_text_metrics_with_cache_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfontprop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mismath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\text.py:77\u001b[0m, in \u001b[0;36m_get_text_metrics_with_cache_impl\u001b[1;34m(renderer_ref, text, fontprop, ismath, dpi)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache(\u001b[38;5;241m4096\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_text_metrics_with_cache_impl\u001b[39m(\n\u001b[0;32m     75\u001b[0m         renderer_ref, text, fontprop, ismath, dpi):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# dpi is unused, but participates in cache invalidation (via the renderer).\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrenderer_ref\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_text_width_height_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfontprop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mismath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\krist\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:219\u001b[0m, in \u001b[0;36mRendererAgg.get_text_width_height_descent\u001b[1;34m(self, s, prop, ismath)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m width, height, descent\n\u001b[0;32m    218\u001b[0m font \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_font(prop)\n\u001b[1;32m--> 219\u001b[0m \u001b[43mfont\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_hinting_flag\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m w, h \u001b[38;5;241m=\u001b[39m font\u001b[38;5;241m.\u001b[39mget_width_height()  \u001b[38;5;66;03m# width and height of unrotated string\u001b[39;00m\n\u001b[0;32m    221\u001b[0m d \u001b[38;5;241m=\u001b[39m font\u001b[38;5;241m.\u001b[39mget_descent()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for i in tqdm(range(100000)):\n",
    "    indices, y_true = sample_batch(corpus_indicies[:80000], \n",
    "                                   batch_size, \n",
    "                                   tokenizer, \n",
    "                                   max_seq_len)\n",
    "    \n",
    "    weight_norm = model.get_weight_norm()\n",
    "    print(\"Weight Norm: \", weight_norm)\n",
    "    loss_train = model.train_step(indices, y_true).numpy()\n",
    "    losses_train.append(loss_train)\n",
    "    print(\"Step: \", i, \"Train Loss: \", loss_train)\n",
    "\n",
    "\n",
    "    indices, y_true = sample_batch(corpus_indicies[80000:], \n",
    "                                batch_size//4, \n",
    "                                tokenizer, \n",
    "                                max_seq_len)\n",
    "    \n",
    "    loss_test = model.evaluate(indices, y_true).numpy()\n",
    "        \n",
    "    losses_test.append(loss_test)\n",
    "\n",
    "    if (i+1) % 1000 == 0:\n",
    "        ckpt_manager.save()\n",
    "        pkl.dump([losses_train, losses_test], open(\"checkpoints/losses_\" + name + \".pkl\", 'wb'))\n",
    "\n",
    "\n",
    "    lr = model.opt.inner_optimizer._decayed_lr(tf.float32).numpy()\n",
    "    #\"\"\"\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # prepare x-axis for the last 400 steps\n",
    "    start = max(0, len(losses_train) - 1000)\n",
    "    x_zoom = np.arange(start, len(losses_train))\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(10, 8), sharex=False)\n",
    "\n",
    "    # Top subplot: zoom on last 400 steps\n",
    "    ax1 = axes[0]\n",
    "    ax1.plot(x_zoom, losses_test[-1000:], label=\"Test Loss\")\n",
    "    ax1.plot(x_zoom, losses_train[-1000:], label=\"Train Loss\")\n",
    "\n",
    "    _min = min(losses_train[-1000:] + losses_test[-1000:])\n",
    "    _max = max(losses_train[-1000:] + losses_test[-1000:])\n",
    "    delta = _max - _min\n",
    "    #ax1.set_ylim(_min - 0.1 * delta, _max + 0.1 * delta)\n",
    "\n",
    "    ax1.set_title(\"Training Loss (Last 1000 Steps)\")\n",
    "    ax1.set_xlabel(\"Step\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Bottom subplot: full series\n",
    "    ax2 = axes[1]\n",
    "    ax2.plot(losses_test[10:], label=\"Test Loss\")\n",
    "    ax2.plot(losses_train[10:], label=\"Train Loss, lr = {:.2e}\".format(lr))\n",
    "\n",
    "    ax2.set_title(\"Training Loss (Full Series)\")\n",
    "    ax2.set_xlabel(\"Step\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58649737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(indices, merge_list):\n",
    "    indices = np.array(indices)\n",
    "    for pair, new_idx in merge_list:\n",
    "        slice = np.where(np.logical_and(indices[:-1] == pair[0],  indices[1:] == pair[1]))\n",
    "        if len(slice[0]) > 0:\n",
    "            indices[:-1][slice] = new_idx\n",
    "            indices = np.delete(indices, (slice[0]+1))\n",
    "\n",
    "    return tf.expand_dims(tf.convert_to_tensor(indices, dtype=tf.int32), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e216ce01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[359   1 479  27]], shape=(1, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "text = \"it's official:\"\n",
    "text = text.lower()\n",
    "\n",
    "indices = tf.cast(tokenizer.tokenizer.tokenize(text), tf.int32)\n",
    "indices = tokenize(indices, tokenizer.merge_list)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "74a017b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it's official: \"i think it's a lot of people who are not going to be able to be able to be able to be able to be able to be able to be able to be able to be a good chance to be able to be able to be able to be able to be a good chance to be able to be able \r"
     ]
    }
   ],
   "source": [
    "T = 0.01\n",
    "tf.random.set_seed(43)\n",
    "for i in range(128):\n",
    "    logits = model.call(indices)[0,-1:]\n",
    "    idx = tf.cast(tf.random.categorical(logits/T, num_samples=1), tf.int32)\n",
    "    indices = tf.concat([indices, idx], axis=1)\n",
    "    text_pred = tokenizer.detokenize(indices)\n",
    "    text_pred = text_pred.numpy()[0].decode('utf-8').replace(\"\\n\", \" \")\n",
    "    print(text_pred, end='\\r', flush=True)\n",
    "    #time.sleep(0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e77fb01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def cosine_similarity(embed_a, embed_b):\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between two vectors.\n",
    "    \"\"\"\n",
    "    embed_b_T = tf.transpose(embed_b)\n",
    "    dot_product = embed_a@embed_b_T\n",
    "    \n",
    "    norm_a = tf.linalg.norm(embed_a, axis=1, keepdims=True)\n",
    "    norm_b = tf.linalg.norm(embed_b_T, axis=0, keepdims=True)\n",
    "\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "\n",
    "def cluster(X, n_clusters, normalize=True):\n",
    "    if normalize:\n",
    "        X = X/np.linalg.norm(X, axis=1, keepdims=True)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "    inertia = kmeans.inertia_\n",
    "    labels = kmeans.labels_\n",
    "    clusters = kmeans.cluster_centers_\n",
    "\n",
    "    return inertia, labels, clusters\n",
    "\n",
    "\n",
    "class EmbeddingClustering:\n",
    "    def __init__(self, tokenizer, n_clusters=10):\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.n_clusters = n_clusters\n",
    "\n",
    "    def fit(self, word_embed, normalize=True):\n",
    "        inertia, labels, clusters = cluster(word_embed, self.n_clusters, normalize)\n",
    "        self.word_embed = word_embed\n",
    "        self.inertia = inertia\n",
    "        self.labels = labels\n",
    "        self.clusters = tf.convert_to_tensor(clusters, dtype=tf.float32)\n",
    "\n",
    "        cos_sim = cosine_similarity(self.clusters, word_embed, normalize)\n",
    "        self.idx_list =  tf.argsort(cos_sim, axis=-1, direction='DESCENDING', stable=False, name=None)\n",
    "\n",
    "    def print_clusters(self, n_words=10):\n",
    "        for idx in self.idx_list:\n",
    "            for i in idx[:n_words]:\n",
    "                word = self.tokenizer.detokenize(tf.expand_dims(tf.cast(i, tf.int32), axis=0))\n",
    "                word = word.numpy().decode('utf-8')\n",
    "                print(word)\n",
    "            print(\"\\n\")\n",
    "\n",
    "\n",
    "def cosine_similarity(embed_a, embed_b, normalize=True):\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between two vectors.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        embed_a = tf.nn.l2_normalize(embed_a, axis=1)\n",
    "        embed_b = tf.nn.l2_normalize(embed_b, axis=1)\n",
    "    dot_product = embed_a@tf.transpose(embed_b)\n",
    "\n",
    "\n",
    "    return dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48583bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gadgets\n",
      "abulary\n",
      "pools\n",
      "dishes\n",
      "attractions\n",
      "experi\n",
      "foun\n",
      "shades\n",
      "includ\n",
      "planets\n",
      "\n",
      "\n",
      "breiv\n",
      "fahren\n",
      "atest\n",
      "catastro\n",
      "diox\n",
      "theastern\n",
      "ricul\n",
      "answ\n",
      "experi\n",
      "zimbab\n",
      "\n",
      "\n",
      "airstrike\n",
      "outskirts\n",
      "checkpoint\n",
      "manhunt\n",
      "diox\n",
      "barracks\n",
      "sched\n",
      "convoy\n",
      "drawal\n",
      "usalem\n",
      "\n",
      "\n",
      "experi\n",
      "diffic\n",
      "respe\n",
      "diox\n",
      "eday\n",
      "liby\n",
      "occas\n",
      "niel\n",
      "shaba\n",
      "patro\n",
      "\n",
      "\n",
      "invol\n",
      "breiv\n",
      "answ\n",
      "theastern\n",
      "ricul\n",
      "atest\n",
      "diox\n",
      "damasc\n",
      "travol\n",
      "luscon\n",
      "\n",
      "\n",
      "redu\n",
      "convin\n",
      "niel\n",
      "answ\n",
      "ricul\n",
      "overwhel\n",
      "invol\n",
      "atest\n",
      "includ\n",
      "lades\n",
      "\n",
      "\n",
      "niel\n",
      "diox\n",
      "atest\n",
      "travol\n",
      "convin\n",
      "answ\n",
      "rodrigue\n",
      "yose\n",
      "invol\n",
      "drun\n",
      "\n",
      "\n",
      "respond\n",
      "relate\n",
      "learn\n",
      "contribute\n",
      "compare\n",
      "take\n",
      "interact\n",
      "choose\n",
      "donate\n",
      "want\n",
      "\n",
      "\n",
      "involves\n",
      "reminds\n",
      "encourages\n",
      "focuses\n",
      "gives\n",
      "tends\n",
      "pays\n",
      "helps\n",
      "takes\n",
      "employs\n",
      "\n",
      "\n",
      "los\n",
      "federal\n",
      "south\n",
      "national\n",
      "north\n",
      "hong\n",
      "new\n",
      "county\n",
      "massachusetts\n",
      "washington\n",
      "\n",
      "\n",
      "shaba\n",
      "onsored\n",
      "palestin\n",
      "breiv\n",
      "diox\n",
      "occas\n",
      "catastro\n",
      "ricul\n",
      "consid\n",
      "theastern\n",
      "\n",
      "\n",
      "degre\n",
      "foun\n",
      "cigare\n",
      "uum\n",
      "eday\n",
      "volunt\n",
      "shaba\n",
      "territor\n",
      "breiv\n",
      "liby\n",
      "\n",
      "\n",
      "civilians\n",
      "militants\n",
      "insurgents\n",
      "kidnappings\n",
      "pakistanis\n",
      "peacekeepers\n",
      "casualties\n",
      "rebels\n",
      "gunmen\n",
      "palestinians\n",
      "\n",
      "\n",
      "prosecution\n",
      "manslaughter\n",
      "conviction\n",
      "extradition\n",
      "testimony\n",
      "murder\n",
      "plea\n",
      "judge's\n",
      "acquitted\n",
      "attorneys\n",
      "\n",
      "\n",
      "telling\n",
      "giving\n",
      "allowing\n",
      "providing\n",
      "causing\n",
      "forcing\n",
      "prompting\n",
      "putting\n",
      "gonna\n",
      "violating\n",
      "\n",
      "\n",
      "officials\n",
      "experts\n",
      "agencies\n",
      "customers\n",
      "groups\n",
      "organizations\n",
      "observers\n",
      "sources\n",
      "investigators\n",
      "families\n",
      "\n",
      "\n",
      " \n",
      "stru\n",
      "dis\n",
      "nul\n",
      "pul\n",
      "illust\n",
      "chry\n",
      "spr\n",
      "reim\n",
      "rele\n",
      "\n",
      "\n",
      "heit\n",
      "emerg\n",
      "breiv\n",
      "diox\n",
      "zimbab\n",
      "answ\n",
      "idency\n",
      "tournam\n",
      "theastern\n",
      "experi\n",
      "\n",
      "\n",
      "violating\n",
      "eliminating\n",
      "reviewing\n",
      "reducing\n",
      "restoring\n",
      "pursuing\n",
      "combating\n",
      "foun\n",
      "gonna\n",
      "strugg\n",
      "\n",
      "\n",
      "demp\n",
      "foun\n",
      "answ\n",
      "patro\n",
      "mingham\n",
      "lecito\n",
      "satell\n",
      "abulary\n",
      "palestin\n",
      "breiv\n",
      "\n",
      "\n",
      "melissa\n",
      "patricia\n",
      "deborah\n",
      "brian\n",
      "denise\n",
      "stephanie\n",
      "jennifer\n",
      "jane\n",
      "doug\n",
      "christine\n",
      "\n",
      "\n",
      "ard's\n",
      "berg's\n",
      "o's\n",
      "ia's\n",
      "i's\n",
      "as'\n",
      "z's\n",
      "ley's\n",
      "ner's\n",
      "u's\n",
      "\n",
      "\n",
      "breiv\n",
      "damasc\n",
      "invol\n",
      "eday\n",
      "answ\n",
      "arct\n",
      "experi\n",
      "abulary\n",
      "jevich\n",
      "dipl\n",
      "\n",
      "\n",
      "tells\n",
      "adds\n",
      "says\n",
      "told\n",
      "admits\n",
      "said\n",
      "explains\n",
      "explained\n",
      "writes\n",
      "replied\n",
      "\n",
      "\n",
      "unable\n",
      "trying\n",
      "supposed\n",
      "attempting\n",
      "failing\n",
      "willing\n",
      "refusing\n",
      "refusal\n",
      "unwilling\n",
      "wanting\n",
      "\n",
      "\n",
      "respe\n",
      "mingham\n",
      "demp\n",
      "foun\n",
      "abulary\n",
      "hezbol\n",
      "onsored\n",
      "answ\n",
      "includ\n",
      "anmar\n",
      "\n",
      "\n",
      "occas\n",
      "breiv\n",
      "massachu\n",
      "diox\n",
      "experi\n",
      "rodrigue\n",
      "mingham\n",
      "prene\n",
      "diffic\n",
      "liby\n",
      "\n",
      "\n",
      "boehner\n",
      "pelosi\n",
      "onsored\n",
      "ricul\n",
      "cantor\n",
      "netanyahu\n",
      "abulary\n",
      "secutive\n",
      "palestin\n",
      "carney\n",
      "\n",
      "\n",
      "if\n",
      "but\n",
      "that\n",
      "when\n",
      "what\n",
      "how\n",
      "and\n",
      "why\n",
      "because\n",
      "where\n",
      "\n",
      "\n",
      "sure\n",
      "know\n",
      "think\n",
      "understand\n",
      "realize\n",
      "wondering\n",
      "believe\n",
      "excited\n",
      "confident\n",
      "thinking\n",
      "\n",
      "\n",
      "according\n",
      "relating\n",
      "referring\n",
      "contributed\n",
      "attached\n",
      "belonged\n",
      "thanks\n",
      "belonging\n",
      "linked\n",
      "related\n",
      "\n",
      "\n",
      "answ\n",
      "diox\n",
      "theastern\n",
      "breiv\n",
      "invol\n",
      "includ\n",
      "fahren\n",
      "shaba\n",
      "ricul\n",
      "secutive\n",
      "\n",
      "\n",
      "28\n",
      "25\n",
      "29\n",
      "45\n",
      "46\n",
      "27\n",
      "6\n",
      "5\n",
      "8\n",
      "60\n",
      "\n",
      "\n",
      "injunction\n",
      "decree\n",
      "pact\n",
      "filibuster\n",
      "referendum\n",
      "candidacy\n",
      "legislature\n",
      "proposal\n",
      "crackdown\n",
      "subcommittee\n",
      "\n",
      "\n",
      " \n",
      "stru\n",
      "ou\n",
      "zz\n",
      "il\n",
      "ld\n",
      "ol\n",
      "ur\n",
      "ig\n",
      "iz\n",
      "\n",
      "\n",
      "stru\n",
      "scrut\n",
      "nul\n",
      "preh\n",
      "contam\n",
      "riculum\n",
      "dipl\n",
      "onsored\n",
      "drun\n",
      "fict\n",
      "\n",
      "\n",
      "onsored\n",
      "ricul\n",
      "o'ne\n",
      "eday\n",
      "ailand\n",
      "invol\n",
      "includ\n",
      "abulary\n",
      "answ\n",
      "patro\n",
      "\n",
      "\n",
      "hottest\n",
      "continent's\n",
      "strugg\n",
      "liby\n",
      "answ\n",
      "ricul\n",
      "uum\n",
      "acerb\n",
      "tournam\n",
      "portugu\n",
      "\n",
      "\n",
      "stormed\n",
      "foun\n",
      "bounced\n",
      "raced\n",
      "wiped\n",
      "collided\n",
      "netted\n",
      "teed\n",
      "hampered\n",
      "gunned\n",
      "\n",
      "\n",
      "1995\n",
      "2004\n",
      "1984\n",
      "1945\n",
      "1990\n",
      "1962\n",
      "1982\n",
      "1979\n",
      "1980\n",
      "1961\n",
      "\n",
      "\n",
      "answ\n",
      "riculum\n",
      "cigare\n",
      "wiscon\n",
      "includ\n",
      "onsored\n",
      "invol\n",
      "acerb\n",
      "eday\n",
      "anmar\n",
      "\n",
      "\n",
      "took\n",
      "brought\n",
      "went\n",
      "entered\n",
      "moved\n",
      "came\n",
      "gave\n",
      "was\n",
      "turned\n",
      "pulled\n",
      "\n",
      "\n",
      "southwestern\n",
      "southeastern\n",
      "northeastern\n",
      "deepwater\n",
      "populous\n",
      "kuala\n",
      "daiichi\n",
      "saharan\n",
      "busiest\n",
      "fukushima\n",
      "\n",
      "\n",
      "berdych\n",
      "potro\n",
      "wozniacki\n",
      "azarenka\n",
      "rosberg\n",
      "nadal\n",
      "mcilroy\n",
      "raikkon\n",
      "guardiola\n",
      "djokovic\n",
      "\n",
      "\n",
      "i'll\n",
      "you'll\n",
      "we'll\n",
      "they'll\n",
      "i'd\n",
      "you'd\n",
      "it'll\n",
      "she'll\n",
      "we'd\n",
      "he'll\n",
      "\n",
      "\n",
      "vessel\n",
      "rains\n",
      "landfall\n",
      "eruption\n",
      "airspace\n",
      "cockpit\n",
      "rainfall\n",
      "epicenter\n",
      "quake\n",
      "earthquake\n",
      "\n",
      "\n",
      "nul\n",
      "gior\n",
      "freel\n",
      "yose\n",
      "dono\n",
      "fitz\n",
      "syl\n",
      "charlot\n",
      "stru\n",
      "scrut\n",
      "\n",
      "\n",
      "breiv\n",
      "answ\n",
      "diox\n",
      "riculum\n",
      "rodrigue\n",
      "theastern\n",
      "onsored\n",
      "niel\n",
      "invol\n",
      "ricul\n",
      "\n",
      "\n",
      "foun\n",
      "demp\n",
      "catastro\n",
      "respe\n",
      "mented\n",
      "ually\n",
      "ulate\n",
      "ultane\n",
      "cigare\n",
      "theless\n",
      "\n",
      "\n",
      "appeal\n",
      "deal\n",
      "message\n",
      "interview\n",
      "response\n",
      "announcement\n",
      "relationship\n",
      "question\n",
      "case\n",
      "decision\n",
      "\n",
      "\n",
      "diox\n",
      "answ\n",
      "respe\n",
      "o'ne\n",
      "demp\n",
      "uum\n",
      "breiv\n",
      "volunt\n",
      "foun\n",
      "includ\n",
      "\n",
      "\n",
      "roommate\n",
      "boyfriend\n",
      "daughters\n",
      "wife\n",
      "mother\n",
      "husband\n",
      "daughter\n",
      "girlfriend\n",
      "grandmother\n",
      "cousin\n",
      "\n",
      "\n",
      "a\n",
      "one\n",
      "the\n",
      "two\n",
      "an\n",
      "three\n",
      "first\n",
      "some\n",
      "four\n",
      "another\n",
      "\n",
      "\n",
      "somalia's\n",
      "lebanon's\n",
      "iraq's\n",
      "egypt's\n",
      "yemen's\n",
      "transitional\n",
      "sudan's\n",
      "myanmar's\n",
      "mubarak's\n",
      "libya's\n",
      "\n",
      "\n",
      "haven't\n",
      "we'd\n",
      "they'll\n",
      "they'd\n",
      "you'd\n",
      "he'd\n",
      "genuinely\n",
      "necessarily\n",
      "gonna\n",
      "i'd\n",
      "\n",
      "\n",
      "onsored\n",
      "patro\n",
      "hezbol\n",
      "foun\n",
      "includ\n",
      "abulary\n",
      "riculum\n",
      "espion\n",
      "entreprene\n",
      "occas\n",
      "\n",
      "\n",
      "adequate\n",
      "strugg\n",
      "ricul\n",
      "insufficient\n",
      "heinous\n",
      "foun\n",
      "liby\n",
      "tournam\n",
      "assage\n",
      "o'ne\n",
      "\n",
      "\n",
      "peninsula\n",
      "countryside\n",
      "outskirts\n",
      "hemisphere\n",
      "slopes\n",
      "riculum\n",
      "anmar\n",
      "onsored\n",
      "publ\n",
      "abulary\n",
      "\n",
      "\n",
      "reiterated\n",
      "cautioned\n",
      "considers\n",
      "asserted\n",
      "emphasized\n",
      "contends\n",
      "acknowledged\n",
      "denounced\n",
      "foun\n",
      "urged\n",
      "\n",
      "\n",
      "breiv\n",
      "palestin\n",
      "shaba\n",
      "rodrigue\n",
      "astern\n",
      "catastro\n",
      "answ\n",
      "theless\n",
      "portugu\n",
      "perpe\n",
      "\n",
      "\n",
      "mathem\n",
      "scrut\n",
      "phenomen\n",
      "contam\n",
      "fict\n",
      "convin\n",
      "snor\n",
      "trau\n",
      "atest\n",
      "riculum\n",
      "\n",
      "\n",
      "deficits\n",
      "impover\n",
      "answ\n",
      "economies\n",
      "usalem\n",
      "invol\n",
      "downturn\n",
      "revenues\n",
      "gdp\n",
      "theastern\n",
      "\n",
      "\n",
      "philipp\n",
      "jorge\n",
      "nico\n",
      "ricul\n",
      "javier\n",
      "sergio\n",
      "borussia\n",
      "felipe\n",
      "roberto\n",
      "sebastian\n",
      "\n",
      "\n",
      "ouster\n",
      "entreprene\n",
      "caliphate\n",
      "ricul\n",
      "includ\n",
      "abulary\n",
      "mingham\n",
      "palestin\n",
      "niel\n",
      "secutive\n",
      "\n",
      "\n",
      "apped\n",
      "aded\n",
      "acked\n",
      "thered\n",
      "ipped\n",
      "ounced\n",
      "dled\n",
      "pped\n",
      "ished\n",
      "aked\n",
      "\n",
      "\n",
      "kuala\n",
      "memphis\n",
      "diox\n",
      "louisville\n",
      "impover\n",
      "theless\n",
      "invol\n",
      "strugg\n",
      "drawal\n",
      "arlington\n",
      "\n",
      "\n",
      "pleaded\n",
      "surrendered\n",
      "listened\n",
      "wondered\n",
      "answered\n",
      "yelled\n",
      "apologized\n",
      "slept\n",
      "walked\n",
      "testified\n",
      "\n",
      "\n",
      "wonderful\n",
      "tremendous\n",
      "fantastic\n",
      "compelling\n",
      "gonna\n",
      "awesome\n",
      "incredible\n",
      "scary\n",
      "interesting\n",
      "decent\n",
      "\n",
      "\n",
      "dre\n",
      "freel\n",
      "toug\n",
      "rodrigue\n",
      "osop\n",
      "daugh\n",
      "yout\n",
      "_\n",
      "dono\n",
      "twel\n",
      "\n",
      "\n",
      "reven\n",
      "diox\n",
      "onsored\n",
      "fahren\n",
      "ceed\n",
      "includ\n",
      "shaba\n",
      "ricul\n",
      "palestin\n",
      "propof\n",
      "\n",
      "\n",
      "in\n",
      "from\n",
      "at\n",
      "into\n",
      "to\n",
      "on\n",
      "for\n",
      "by\n",
      "during\n",
      "through\n",
      "\n",
      "\n",
      "mitig\n",
      "exacerb\n",
      "stru\n",
      "nul\n",
      "crip\n",
      "negle\n",
      "exagger\n",
      "frust\n",
      "prolifer\n",
      "foc\n",
      "\n",
      "\n",
      "kinds\n",
      "plenty\n",
      "lots\n",
      "you've\n",
      "regardless\n",
      "we've\n",
      "hundreds\n",
      "sorts\n",
      "sort\n",
      "types\n",
      "\n",
      "\n",
      "volatile\n",
      "significant\n",
      "widespread\n",
      "deadly\n",
      "predominantly\n",
      "serious\n",
      "catastrophic\n",
      "remote\n",
      "severe\n",
      "immediate\n",
      "\n",
      "\n",
      "world's\n",
      "country's\n",
      "prestigious\n",
      "america's\n",
      "sport's\n",
      "party's\n",
      "prominent\n",
      "city's\n",
      "europe's\n",
      "nation's\n",
      "\n",
      "\n",
      "diox\n",
      "strugg\n",
      "vintage\n",
      "massachu\n",
      "gorgeous\n",
      "answ\n",
      "damasc\n",
      "liby\n",
      "shaba\n",
      "pean\n",
      "\n",
      "\n",
      "entreprene\n",
      "palestin\n",
      "atest\n",
      "anwar\n",
      "uum\n",
      "espion\n",
      "ricul\n",
      "niel\n",
      "lades\n",
      "subsequ\n",
      "\n",
      "\n",
      "onsored\n",
      "alternatives\n",
      "foun\n",
      "riculum\n",
      "invol\n",
      "publ\n",
      "theastern\n",
      "answ\n",
      "respe\n",
      "includ\n",
      "\n",
      "\n",
      "scrut\n",
      "contem\n",
      "frust\n",
      "distr\n",
      "disap\n",
      "illust\n",
      "transc\n",
      "nul\n",
      "recomm\n",
      "exerc\n",
      "\n",
      "\n",
      "08\n",
      "220\n",
      "http\n",
      "240\n",
      "270\n",
      "135\n",
      "thurs\n",
      "196\n",
      "550\n",
      "197\n",
      "\n",
      "\n",
      "fahren\n",
      "tournam\n",
      "ricul\n",
      "shaba\n",
      "breiv\n",
      "foun\n",
      "guaran\n",
      "transparen\n",
      "ceed\n",
      "acerb\n",
      "\n",
      "\n",
      "anbar\n",
      "peshawar\n",
      "homs\n",
      "misrata\n",
      "crimea\n",
      "helmand\n",
      "yemen\n",
      "waziristan\n",
      "mogadishu\n",
      "somalia\n",
      "\n",
      "\n",
      "minutes\n",
      "seconds\n",
      "meters\n",
      "seasons\n",
      "laps\n",
      "pounds\n",
      "inches\n",
      "feet\n",
      "degrees\n",
      "kilometers\n",
      "\n",
      "\n",
      "traced\n",
      "transferred\n",
      "transported\n",
      "raided\n",
      "shipped\n",
      "attracted\n",
      "investigated\n",
      "plunged\n",
      "sparked\n",
      "boosted\n",
      "\n",
      "\n",
      "customs\n",
      "transportation\n",
      "coordination\n",
      "inspector\n",
      "enforcement\n",
      "marshals\n",
      "pentagon\n",
      "corrections\n",
      "treasury\n",
      "consulate\n",
      "\n",
      "\n",
      "economic\n",
      "political\n",
      "social\n",
      "financial\n",
      "civil\n",
      "cultural\n",
      "foreign\n",
      "health\n",
      "global\n",
      "humanitarian\n",
      "\n",
      "\n",
      "drivers'\n",
      "wta\n",
      "bundesliga\n",
      "reigning\n",
      "atp\n",
      "semifinal\n",
      "europa\n",
      "motogp\n",
      "quarterfinal\n",
      "side's\n",
      "\n",
      "\n",
      "spokesman\n",
      "editor\n",
      "spokeswoman\n",
      "spokesperson\n",
      "commissioner\n",
      "analyst\n",
      "director\n",
      "adviser\n",
      "professor\n",
      "lawyer\n",
      "\n",
      "\n",
      "fbi's\n",
      "examiner's\n",
      "couple's\n",
      "girl's\n",
      "school's\n",
      "minister's\n",
      "tour's\n",
      "court's\n",
      "band's\n",
      "army's\n",
      "\n",
      "\n",
      " \n",
      "nul\n",
      "o'\n",
      "mc\n",
      "sh\n",
      "gr\n",
      "stru\n",
      "mag\n",
      "fitz\n",
      "cm\n",
      "\n",
      "\n",
      " \n",
      "k\n",
      "l\n",
      "re\n",
      "d\n",
      "g\n",
      "z\n",
      "t\n",
      "j\n",
      "b\n",
      "\n",
      "\n",
      "more\n",
      "the\n",
      "very\n",
      "their\n",
      "a\n",
      "no\n",
      "most\n",
      "many\n",
      "other\n",
      "several\n",
      "\n",
      "\n",
      "assaulted\n",
      "assaulting\n",
      "possessing\n",
      "stabbed\n",
      "indicted\n",
      "tortured\n",
      "injuring\n",
      "abducted\n",
      "detonated\n",
      "assisting\n",
      "\n",
      "\n",
      "sitcom\n",
      "sequel\n",
      "emmy\n",
      "grammy\n",
      "album\n",
      "globes\n",
      "comedy\n",
      "memoir\n",
      "oscars\n",
      "hbo\n",
      "\n",
      "\n",
      "anthro\n",
      "teles\n",
      "reim\n",
      "scrut\n",
      "proto\n",
      "chry\n",
      "cof\n",
      "fict\n",
      "philanthro\n",
      "neuro\n",
      "\n",
      "\n",
      "infections\n",
      "diseases\n",
      "cancers\n",
      "illnesses\n",
      "diarrhea\n",
      "foun\n",
      "massachu\n",
      "emerg\n",
      "respe\n",
      "invol\n",
      "\n",
      "\n",
      "drop\n",
      "break\n",
      "boost\n",
      "draw\n",
      "buy\n",
      "tie\n",
      "kick\n",
      "catch\n",
      "pave\n",
      "walk\n",
      "\n",
      "\n",
      "tember\n",
      "nul\n",
      "toug\n",
      "espe\n",
      "breiv\n",
      "taw\n",
      "atest\n",
      "hawa\n",
      "hmer\n",
      "laim\n",
      "\n",
      "\n",
      "foun\n",
      "astern\n",
      "usalem\n",
      "naev\n",
      "onsored\n",
      "theless\n",
      "tournam\n",
      "dependent\n",
      "prone\n",
      "abulary\n",
      "\n",
      "\n",
      "violate\n",
      "satisfy\n",
      "undermine\n",
      "uphold\n",
      "censor\n",
      "tolerate\n",
      "implement\n",
      "abide\n",
      "oversee\n",
      "eliminate\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_embed = model.word_embed\n",
    "embedding_clustering = EmbeddingClustering(tokenizer, n_clusters=100)\n",
    "embedding_clustering.fit(word_embed, normalize=True)\n",
    "embedding_clustering.print_clusters(n_words=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc968e2d",
   "metadata": {},
   "source": [
    "# Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0de0e293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1602]], shape=(1, 1), dtype=int32)\n",
      "tf.Tensor([[3512]], shape=(1, 1), dtype=int32)\n",
      "tf.Tensor([[5393]], shape=(1, 1), dtype=int32)\n",
      "netanyahu\n",
      "russia\n",
      "delhi\n",
      "2017\n",
      "gbagbo\n",
      "disproportion\n",
      "abe\n",
      "landrieu\n",
      "mugabe\n",
      "kerry\n",
      "espion\n",
      "ikh\n",
      "erdogan\n",
      "toug\n",
      "saleh\n",
      "hinckley\n",
      "keny\n",
      "195\n",
      "israel\n",
      "adjac\n",
      "persecut\n",
      "obes\n",
      "qatar\n",
      "erad\n",
      "israeli\n",
      "natur\n",
      "aspir\n",
      "novosti\n",
      "hagel\n",
      "maduro\n",
      "spite\n",
      "sanctions\n",
      "novo\n",
      "gov\n",
      "subscribe\n",
      "compromise\n",
      "assad's\n",
      "zuma\n",
      "acare\n",
      "honduras\n",
      "geological\n",
      "syria\n",
      "chall\n",
      "sele\n",
      "hond\n",
      "occas\n",
      "ouatt\n",
      "hezbol\n",
      "petrole\n",
      "charlot\n",
      "yanukov\n",
      "commemor\n",
      "confir\n",
      "lavrov\n",
      "jef\n",
      "cra\n",
      "ailand\n",
      "resour\n",
      "sein\n",
      "mourning\n",
      "azaren\n",
      "ultane\n",
      "azarenka\n",
      "slovak\n",
      "gaza\n",
      "sudan\n",
      "provin\n",
      "enjo\n",
      "tao\n",
      "seoul\n",
      "khar\n",
      "adelph\n",
      "supp\n",
      "namib\n",
      "indonesia's\n",
      "hussein\n",
      "maur\n",
      "fernandez\n",
      "santiago\n",
      "biden\n",
      "ria\n",
      "crowley\n",
      "isons\n",
      "adm\n",
      "hurrican\n",
      "armen\n",
      "tayy\n",
      "aleppo\n",
      "tik\n",
      "burma\n",
      "ayatollah\n",
      "erupted\n",
      "nandez\n",
      "kad\n",
      "warri\n",
      "86\n",
      "talks\n",
      "reconciliation\n",
      "encouraged\n",
      "europeans\n"
     ]
    }
   ],
   "source": [
    "word_embed = model.word_embed\n",
    "\n",
    "text = \"russia\"\n",
    "text = text.lower()\n",
    "\n",
    "idx = tf.cast(tokenizer.tokenizer.tokenize(text), tf.int32)\n",
    "idx = tokenize(idx, tokenizer.merge_list)\n",
    "print(idx)\n",
    "embed1 = tf.expand_dims(word_embed[idx[0][0]], axis=0)\n",
    "\n",
    "\n",
    "text = \"putin\"\n",
    "text = text.lower()\n",
    "\n",
    "idx = tf.cast(tokenizer.tokenizer.tokenize(text), tf.int32)\n",
    "idx = tokenize(idx, tokenizer.merge_list)\n",
    "print(idx)\n",
    "embed2 = tf.expand_dims(word_embed[idx[0][0]], axis=0)\n",
    "\n",
    "text = \"netanyahu\"\n",
    "text = text.lower()\n",
    "\n",
    "idx = tf.cast(tokenizer.tokenizer.tokenize(text), tf.int32)\n",
    "idx = tokenize(idx, tokenizer.merge_list)\n",
    "print(idx)\n",
    "embed3 = tf.expand_dims(word_embed[idx[0][0]], axis=0)\n",
    "\n",
    "embed = embed1 - embed2 + embed3\n",
    "\n",
    "cosine_sim = cosine_similarity(embed, word_embed, normalize=False)\n",
    "idx = tf.argsort(cosine_sim, axis=-1, \n",
    "                 direction='DESCENDING',\n",
    "                 #direction='ASCENDING', \n",
    "                 stable=False, name=None)[0]\n",
    "\n",
    "for i in idx[:100]:\n",
    "    i = tf.expand_dims(i, axis=0)\n",
    "    print(tokenizer.detokenize(i).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54734624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1617]], shape=(1, 1), dtype=int32)\n",
      "israel\n",
      "iran\n",
      "afghanistan\n",
      "hamas\n",
      "crimea\n",
      "adm\n",
      "israeli\n",
      "israel's\n",
      "qatar\n",
      "mosul\n",
      "pakistan\n",
      "putin's\n",
      "syria\n",
      "abbas\n",
      "diplomacy\n",
      "kobani\n",
      "netanyahu\n",
      "airstrikes\n",
      "beirut\n",
      "russia\n",
      "peshawar\n",
      "gaza\n",
      "isis'\n",
      "hong\n",
      "israelis\n",
      "cooperating\n",
      "khamenei\n",
      "iran's\n",
      "ethiopian\n",
      "tehran\n",
      "iraq\n",
      "analysts\n",
      "egypt\n",
      "kerry\n",
      "ukraine\n",
      "bhutto\n",
      "compliance\n",
      "isis\n",
      "stability\n",
      "iranians\n",
      "afghanistan's\n",
      "pakistani\n",
      "morsy\n",
      "kandahar\n",
      "tuesday's\n",
      "u\n",
      "angola\n",
      "medvedev\n",
      "sanctions\n",
      "damascus\n",
      "ambassador\n",
      "bashar\n",
      "territorial\n",
      "envoy\n",
      "malala\n",
      "assad\n",
      "syrian\n",
      "jonathan\n",
      "mali\n",
      "reconstruction\n",
      "gadhafi's\n",
      "nato's\n",
      "kirby\n",
      "idf\n",
      "tribal\n",
      "hezbollah\n",
      "bahrain\n",
      "islamabad\n",
      "islamic\n",
      "guantanamo\n",
      "allah\n",
      "sudan's\n",
      "misrata\n",
      "libyan\n",
      "nuclear\n",
      "refugees\n",
      "japan\n",
      "bases\n",
      "borders\n",
      "burma\n",
      "north\n",
      "unrest\n",
      "detainees\n",
      "uyghurs\n",
      "venezuela\n",
      "arabic\n",
      "missile\n",
      "imminent\n",
      "magnitude\n",
      "palestinian\n",
      "waziristan\n",
      "mccain\n",
      "farc\n",
      "indonesia\n",
      "pyongyang\n",
      "china\n",
      "somalia\n",
      "saleh\n",
      "libya\n",
      "talks\n"
     ]
    }
   ],
   "source": [
    "word_embed = model.word_embed\n",
    "\n",
    "text = \"israel\"\n",
    "text = text.lower()\n",
    "\n",
    "idx = tf.cast(tokenizer.tokenizer.tokenize(text), tf.int32)\n",
    "idx = tokenize(idx, tokenizer.merge_list)\n",
    "print(idx)\n",
    "embed = tf.expand_dims(word_embed[idx[0][0]], axis=0)\n",
    "\n",
    "cosine_sim = embed@tf.transpose(word_embed)\n",
    "idx = tf.argsort(cosine_sim, axis=-1, \n",
    "                 direction='DESCENDING',\n",
    "                 #direction='ASCENDING', \n",
    "                 stable=False, name=None)[0]\n",
    "\n",
    "for i in idx[:100]:\n",
    "    i = tf.expand_dims(i, axis=0)\n",
    "    print(tokenizer.detokenize(i).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff23330f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[5393]], shape=(1, 1), dtype=int32)\n",
      "netanyahu\n",
      "abulary\n",
      "hagel\n",
      "maduro\n",
      "espion\n",
      "yingluck\n",
      "onsored\n",
      "nandez\n",
      "saleh\n",
      "natur\n",
      "ailand\n",
      "hezbol\n",
      "panetta\n",
      "biden\n",
      "shinse\n",
      "kerry\n",
      "gibbs\n",
      "sarkozy\n",
      "fundam\n",
      "hift\n",
      "patro\n",
      "signific\n",
      "anonymity\n",
      "putin\n",
      "mugabe\n",
      "lades\n",
      "boehner\n",
      "pelosi\n",
      "medvedev\n",
      "ahmadinejad\n",
      "warri\n",
      "thaksin\n",
      "landrieu\n",
      "shaba\n",
      "gbag\n",
      "accust\n",
      "charac\n",
      "fahren\n",
      "liby\n",
      "peninsu\n",
      "helicop\n",
      "zuma\n",
      "traged\n",
      "portugu\n",
      "morsy\n",
      "publ\n",
      "enjo\n",
      "ilight\n",
      "abbas\n",
      "erdogan\n",
      "ieval\n",
      "bachmann\n",
      "yanukovych\n",
      "leep\n",
      "confir\n",
      "rodrigue\n",
      "secutive\n",
      "provin\n",
      "mccain's\n",
      "moil\n",
      "subsequ\n",
      "abled\n",
      "juvent\n",
      "o'ne\n",
      "guardiola\n",
      "lieberman\n",
      "karzai\n",
      "catastro\n",
      "ouatt\n",
      "zardari\n",
      "possib\n",
      "toug\n",
      "theless\n",
      "burma\n",
      "carney\n",
      "ricul\n",
      "zhok\n",
      "barcelon\n",
      "dort\n",
      "sunnis\n",
      "lomb\n",
      "snowden\n",
      "avez\n",
      "diffic\n",
      "sess\n",
      "khamenei\n",
      "exer\n",
      "golese\n",
      "copen\n",
      "rouhani\n",
      "ipal\n",
      "transparen\n",
      "ultane\n",
      "mccain\n",
      "boeh\n",
      "diox\n",
      "citiz\n",
      "adjac\n",
      "nieto\n",
      "lavrov\n"
     ]
    }
   ],
   "source": [
    "word_embed = model.word_embed\n",
    "\n",
    "text = \"netanyahu\"\n",
    "text = text.lower()\n",
    "\n",
    "idx = tf.cast(tokenizer.tokenizer.tokenize(text), tf.int32)\n",
    "idx = tokenize(idx, tokenizer.merge_list)\n",
    "print(idx)\n",
    "embed = tf.expand_dims(word_embed[idx[0][0]], axis=0)\n",
    "\n",
    "cosine_sim = embed@tf.transpose(word_embed)\n",
    "idx = tf.argsort(cosine_sim, axis=-1, \n",
    "                 direction='DESCENDING',\n",
    "                 #direction='ASCENDING', \n",
    "                 stable=False, name=None)[0]\n",
    "\n",
    "for i in idx[:100]:\n",
    "    i = tf.expand_dims(i, axis=0)\n",
    "    print(tokenizer.detokenize(i).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a5f20b",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
